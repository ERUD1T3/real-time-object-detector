{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSE 5320 Neural Networks Project 2\n",
    "#### Report (with Code)\n",
    "Josias Moukpe\\\n",
    "11/29/2022\n",
    "\n",
    "#### Introduction\n",
    "Object detection is an advanced form of image classification where a neural network predicts objects in an image and points them out in bounding boxes. Object detection thus refers to the detection and localization of objects in an image that belongs to a predefined set of classes. Tasks like detection, recognition, or localization find widespread applicability in real-world scenarios such as autonomous driving, robotics, product quality assurance, etc., making object detection (also referred to as object recognition) a very important subdomain of Computer Vision. [2] We call Real-Time object detection when the objects in images can be recognized in mere milliseconds allowing for in-time reactions based on the detection. Our project will aim to build a real-time object detector to find and track objects of defined classes in images or video feeds.\n",
    "\n",
    "#### Problem\n",
    "This objective combines object classificationn and localization (bounding box regression task). To process images and capture the features, we will leverage convolutional neural networks and capture local pixel structures. We will comment on how our model performs in real-time object detection. To train our model, we will use the MS COCO dataset [1]. This dataset contains more than 200,000 labeled color images of 1.5 million object instances and 80 object categories. Each image is 640 x 480 pixels and includes various forms of annotations such as key points, captions, segmentations, and bounding boxes (which interest us). The model will take an image or batch of images and outputs the classes and bounding boxes of all objects detected in that image.\n",
    "\n",
    "#### Methodology\n",
    "To prepare the data, we downloaded the COCO 2017 from the official website, unzip the files training and validation files in a data folder. We then downloaded the annotations json  files which contain the bounding box coordinates for the objects in the image. We utilized the pycocotools library to help us load the images and the bounding box annotations in memory.Those images are then fed into the network with the bounding boxes as labels. To improve accuracy, we augment some images with random transforms such as rotation and translations. The bounding box labels are also transformed accordingly. The training dataset is used in its entirety but the 50% of the validation set was used for training validation and the other 50% was used for testing.\n",
    "\n",
    "#### Benchmarking\n",
    "To measure training performance, we use validation loss and the mean Average Precision (mAP) to measure the performance on the validation set. Finally, we measure the mAP on test set for final benchmarking.\n",
    "\n",
    "#### Conclusion\n",
    "Unfortunately, we cannot conclude on the project yet as it is not complete. However, it is coming soon.\n",
    "\n",
    "\n",
    "References\\\n",
    "[1] https://cocodataset.org/#home \\\n",
    "[2] https://arxiv.org/abs/1804.02767 \\\n",
    "[3] https://arxiv.org/abs/1506.02640 \\\n",
    "[4] https://arxiv.org/abs/2207.02696 \\\n",
    "[5] https://arxiv.org/abs/1904.04620 \\\n",
    "[6] https://www.v7labs.com/blog/yolo-object-detection \\\n",
    "[7] https://github.com/xuannianz/keras-GaussianYOLOv3 \\\n",
    "[8] https://www.kaggle.com/code/aruchomu/yolo-v3-object-detection-in-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining the COCO 2017 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md  augmentor  config  data  eval  generators  logs  models  utils\n",
      "annotations  coco.names  test2017  train2017  val2017  yolo_anchors.txt\n"
     ]
    }
   ],
   "source": [
    "# list the contents of the current \n",
    "# directory on my remote server\n",
    "!ls\n",
    "!ls \"/notebooks/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to the data directory\n",
    "# and list the contents\n",
    "# %cd \"/notebooks/data\"\n",
    "# !ls\n",
    "\n",
    "# # downloading coco (2017) dataset\n",
    "# !wget http://images.cocodataset.org/zips/train2017.zip\n",
    "# !wget http://images.cocodataset.org/zips/val2017.zip\n",
    "# !wget http://images.cocodataset.org/zips/test2017.zip\n",
    "# !wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "# !wget http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip\n",
    "# !wget http://images.cocodataset.org/annotations/image_info_test2017.zip\n",
    "\n",
    "# # unzip the files\n",
    "# !unzip train2017.zip\n",
    "# !unzip val2017.zip\n",
    "# !unzip test2017.zip\n",
    "# !unzip annotations_trainval2017.zip\n",
    "# !unzip stuff_annotations_trainval2017.zip\n",
    "# !unzip image_info_test2017.zip\n",
    "\n",
    "# # remove the zip files\n",
    "# !rm train2017.zip\n",
    "# !rm val2017.zip\n",
    "# !rm test2017.zip\n",
    "# !rm annotations_trainval2017.zip\n",
    "# !rm stuff_annotations_trainval2017.zip\n",
    "# !rm image_info_test2017.zip\n",
    "\n",
    "# navigate out of the data directory\n",
    "# and list the contents\n",
    "# %cd \"/notebooks\"\n",
    "# !ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a config directory\n",
    "# %cd \"/notebooks\"\n",
    "# %mkdir config\n",
    "# %cd config\n",
    "# !wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
    "# %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a models directory\n",
    "# %cd \"/notebooks\"\n",
    "# %mkdir models\n",
    "# %cd models\n",
    "# !wget -O yolov3.weights https://pjreddie.com/media/files/yolov3.weights\n",
    "# %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # install gluoncv to help with the dataset\n",
    "# %pip install gluoncv\n",
    "# %pip install mxnet\n",
    "# %pip install opencv-python\n",
    "# %pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "# imports \n",
    "import cv2\n",
    "import glob\n",
    "import io\n",
    "import configparser\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from random import randint, choice\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import ZeroPadding2D\n",
    "from tensorflow.keras.layers import Add\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.utils.vis_utils import plot_model as plot\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import TerminateOnNaN\n",
    "import tensorflow.keras.preprocessing.image\n",
    "from functools import reduce\n",
    "from augmentor.color import VisualEffect\n",
    "from augmentor.misc import MiscEffect\n",
    "from generators.coco import CocoGenerator\n",
    "\n",
    "\n",
    "# read coco dataset\n",
    "# from gluoncv import data, utils\n",
    "# print the version of tensorflow\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# check if gpu is available and what type\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(tf.test.gpu_device_name())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset\n",
    "MS COCO 2017 is our dataset. Link to loaded dataset in our remote development compute node\n",
    "https://console.paperspace.com/erud1t3/notebook/r92lxtvwhlbkhcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the coco dataset\n",
    "# train_ds = data.COCODetection('./data/', splits=['instances_train2017'])\n",
    "# val_ds = data.COCODetection('./data/', splits=['instances_val2017'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # print the length of the dataset\n",
    "# print('Length of training dataset:', len(train_ds))\n",
    "# print('Length of validation dataset:', len(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a random image from coco dataset\n",
    "# def plot_image(image, label):\n",
    "#     '''\n",
    "#     Plots an image and its bounding boxes\n",
    "#     '''\n",
    "#     print('Image size (height, width, RGB):', image.shape)\n",
    "#     # print('Label:', label)\n",
    "#     print('shape of label:', label.shape)\n",
    "#     # plot the image\n",
    "#     bounding_boxes = label[:, :4]\n",
    "#     class_ids = label[:, 4:5]\n",
    "#     print('number of objects in the image:', bounding_boxes.shape[0])\n",
    "#     print('bounding boxes (# boxes, min x, min y, max x, max y): \\n', bounding_boxes)\n",
    "#     print('class ids (# boxes, class id): \\n', class_ids)\n",
    "#     ax = utils.viz.plot_bbox(\n",
    "#         image.asnumpy(), \n",
    "#         bounding_boxes, \n",
    "#         scores=None, \n",
    "#         labels=class_ids, \n",
    "#         class_names=train_ds.classes\n",
    "#     )\n",
    "#     plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a random image from validation dataset\n",
    "# image, label = val_ds[randint(0, len(val_ds))]\n",
    "# plot_image(image, label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working the model\n",
    "We will be building Gaussian YoloV3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the config file containing the model architecture\n",
    "def unique_config_sections(config_file):\n",
    "    '''\n",
    "    Reads the config file and returns a list of layers\n",
    "    '''\n",
    "    # open the config file\n",
    "    section_counters = defaultdict(int)\n",
    "    output_stream = io.StringIO()\n",
    "\n",
    "    with open(config_file) as fin:\n",
    "        for line in fin:\n",
    "            if line.startswith('['):\n",
    "                section = line.strip().strip('[]')\n",
    "                _section = section + '_' + str(section_counters[section])\n",
    "                section_counters[section] += 1\n",
    "                line = line.replace(section, _section)\n",
    "            output_stream.write(line)\n",
    "    output_stream.seek(0)\n",
    "\n",
    "    return output_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (608, 608, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_config(config_path, output_path, weights_path, weights_only=False):\n",
    "    '''\n",
    "    Parses the config file and returns a model\n",
    "    '''\n",
    "\n",
    "    # config_path = os.path.expanduser(args.config_path)\n",
    "    # weights_path = os.path.expanduser(args.weights_path)\n",
    "    # output_path = os.path.expanduser(args.output_path)\n",
    "    # assert config_path.endswith('.cfg'), 'config path {} is not a .cfg file'.format(config_path)\n",
    "    # assert weights_path.endswith('.weights'), 'weights path {} is not a .weights file'.format(weights_path)\n",
    "    # assert output_path.endswith('.h5'), 'output path {} is not a .h5 file'.format(output_path)\n",
    "\n",
    "    # Load weights and config.\n",
    "    print('Loading weights.')\n",
    "    weights_file = open(weights_path, 'rb')\n",
    "    major, minor, revision = np.ndarray(shape=(3,), dtype='int32', buffer=weights_file.read(12))\n",
    "    if (major * 10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
    "        seen = np.ndarray(shape=(1,), dtype='int64', buffer=weights_file.read(8))\n",
    "    else:\n",
    "        seen = np.ndarray(shape=(1,), dtype='int32', buffer=weights_file.read(4))\n",
    "    print('Weights Header: ', major, minor, revision, seen)\n",
    "\n",
    "    print('Parsing Darknet config.')\n",
    "    unique_config_file = unique_config_sections(config_path)\n",
    "    cfg_parser = configparser.ConfigParser()\n",
    "    cfg_parser.read_file(unique_config_file)\n",
    "\n",
    "    print('Creating Keras model.')\n",
    "    input_layer = Input(shape=INPUT_SHAPE)\n",
    "    prev_layer = input_layer\n",
    "    all_layers = []\n",
    "\n",
    "    weight_decay = float(cfg_parser['net_0']['decay']) if 'net_0' in cfg_parser.sections() else 5e-4\n",
    "    four_bytes_consumed_count = 0\n",
    "    out_index = []\n",
    "    for section in cfg_parser.sections():\n",
    "        print('Parsing section {}'.format(section))\n",
    "        if section.startswith('convolutional'):\n",
    "            filters = int(cfg_parser[section]['filters'])\n",
    "            size = int(cfg_parser[section]['size'])\n",
    "            stride = int(cfg_parser[section]['stride'])\n",
    "            pad = int(cfg_parser[section]['pad'])\n",
    "            activation = cfg_parser[section]['activation']\n",
    "            batch_normalize = 'batch_normalize' in cfg_parser[section]\n",
    "\n",
    "            padding = 'same' if pad == 1 and stride == 1 else 'valid'\n",
    "\n",
    "            # Setting weights.\n",
    "            # Darknet serializes convolutional weights as:\n",
    "            # [bias/beta, [gamma, mean, variance], conv_weights]\n",
    "            prev_layer_shape = K.int_shape(prev_layer)\n",
    "            # Note 每一个 filter 的 shape 为 (size, size, pre_layer_shape[-1])\n",
    "            # (outdim, indim, height, width)\n",
    "            weights_shape = (filters, prev_layer_shape[-1], size, size)\n",
    "\n",
    "            weights_size = np.product(weights_shape)\n",
    "            print('conv2d', 'bn' if batch_normalize else '  ', activation, weights_shape)\n",
    "\n",
    "            conv_bias = np.ndarray(\n",
    "                shape=(filters,),\n",
    "                dtype='float32',\n",
    "                buffer=weights_file.read(filters * 4))\n",
    "            four_bytes_consumed_count += filters\n",
    "            if batch_normalize:\n",
    "                bn_weights = np.ndarray(\n",
    "                    shape=(3, filters),\n",
    "                    dtype='float32',\n",
    "                    buffer=weights_file.read(filters * 12))\n",
    "                four_bytes_consumed_count += 3 * filters\n",
    "\n",
    "                bn_weight_list = [\n",
    "                    # scale gamma\n",
    "                    bn_weights[0],\n",
    "                    # shift beta\n",
    "                    conv_bias,\n",
    "                    # running mean\n",
    "                    bn_weights[1],\n",
    "                    # running var\n",
    "                    bn_weights[2]\n",
    "                ]\n",
    "            conv_weights = np.ndarray(\n",
    "                shape=weights_shape,\n",
    "                dtype='float32',\n",
    "                buffer=weights_file.read(weights_size * 4))\n",
    "            four_bytes_consumed_count += weights_size\n",
    "\n",
    "            # DarkNet conv_weights are serialized Caffe-style:\n",
    "            # (out_dim, in_dim, height, width)\n",
    "            # We would like to set these to Tensorflow order:\n",
    "            # (height, width, in_dim, out_dim)\n",
    "            conv_weights = np.transpose(conv_weights, [2, 3, 1, 0])\n",
    "            conv_weights = [conv_weights] if batch_normalize else [conv_weights, conv_bias]\n",
    "\n",
    "            # Handle activation.\n",
    "            if activation not in ('leaky', 'linear'):\n",
    "                raise ValueError('Unknown activation function `{}` in section {}'.format(activation, section))\n",
    "\n",
    "            # Create Conv2D layer\n",
    "            if stride > 1:\n",
    "                # Darknet uses left and top padding instead of 'same' mode when stride > 1\n",
    "                prev_layer = ZeroPadding2D(((1, 0), (1, 0)))(prev_layer)\n",
    "                \n",
    "            conv_layer = Conv2D(\n",
    "                filters, (size, size),\n",
    "                strides=(stride, stride),\n",
    "                kernel_regularizer=l2(weight_decay),\n",
    "                use_bias=not batch_normalize,\n",
    "                weights=conv_weights,\n",
    "                padding=padding)(prev_layer)\n",
    "\n",
    "            if batch_normalize:\n",
    "                conv_layer = (BatchNormalization(weights=bn_weight_list))(conv_layer)\n",
    "            prev_layer = conv_layer\n",
    "\n",
    "            if activation == 'linear':\n",
    "                all_layers.append(prev_layer)\n",
    "            elif activation == 'leaky':\n",
    "                act_layer = LeakyReLU(alpha=0.1)(prev_layer)\n",
    "                prev_layer = act_layer\n",
    "                all_layers.append(act_layer)\n",
    "\n",
    "        elif section.startswith('route'):\n",
    "            # concatenate layers\n",
    "            ids = [int(i) for i in cfg_parser[section]['layers'].split(',')]\n",
    "            layers = [all_layers[i] for i in ids]\n",
    "            if len(layers) > 1:\n",
    "                print('Concatenating route layers:', layers)\n",
    "                concatenate_layer = Concatenate()(layers)\n",
    "                all_layers.append(concatenate_layer)\n",
    "                prev_layer = concatenate_layer\n",
    "            else:\n",
    "                # only one layer to route\n",
    "                skip_layer = layers[0]\n",
    "                all_layers.append(skip_layer)\n",
    "                prev_layer = skip_layer\n",
    "\n",
    "        elif section.startswith('maxpool'):\n",
    "            size = int(cfg_parser[section]['size'])\n",
    "            stride = int(cfg_parser[section]['stride'])\n",
    "            all_layers.append(\n",
    "                MaxPooling2D(\n",
    "                    pool_size=(size, size),\n",
    "                    strides=(stride, stride),\n",
    "                    padding='same')(prev_layer))\n",
    "            prev_layer = all_layers[-1]\n",
    "\n",
    "        elif section.startswith('shortcut'):\n",
    "            index = int(cfg_parser[section]['from'])\n",
    "            activation = cfg_parser[section]['activation']\n",
    "            assert activation == 'linear', 'Only linear activation supported.'\n",
    "            all_layers.append(Add()([all_layers[index], prev_layer]))\n",
    "            prev_layer = all_layers[-1]\n",
    "\n",
    "        elif section.startswith('upsample'):\n",
    "            stride = int(cfg_parser[section]['stride'])\n",
    "            assert stride == 2, 'Only stride=2 supported.'\n",
    "            all_layers.append(UpSampling2D(stride)(prev_layer))\n",
    "            prev_layer = all_layers[-1]\n",
    "\n",
    "        elif section.startswith('yolo'):\n",
    "            out_index.append(len(all_layers) - 1)\n",
    "            all_layers.append(None)\n",
    "            prev_layer = all_layers[-1]\n",
    "\n",
    "        elif section.startswith('net'):\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Unsupported section header type: {}'.format(section))\n",
    "\n",
    "    # Create and save model.\n",
    "    if len(out_index) == 0:\n",
    "        out_index.append(len(all_layers) - 1)\n",
    "    model = Model(inputs=input_layer, outputs=[all_layers[i] for i in out_index])\n",
    "\n",
    "    if weights_only:\n",
    "        model.save_weights('{}'.format(output_path))\n",
    "        print('Saved Keras weights to {}'.format(output_path))\n",
    "    else:\n",
    "        model.save('{}'.format(output_path))\n",
    "        print('Saved Keras model to {}'.format(output_path))\n",
    "\n",
    "    # Check to see if all weights have been read.\n",
    "    remaining_weights = len(weights_file.read()) // 4\n",
    "    weights_file.close()\n",
    "    print('Read {} of {} from Darknet weights.'.format(four_bytes_consumed_count,\n",
    "                                                       four_bytes_consumed_count + remaining_weights))\n",
    "    if remaining_weights > 0:\n",
    "        print('Warning: {} unused weights'.format(remaining_weights))\n",
    "        output_root = \"/notebooks/models/\"\n",
    "        plot(model, to_file='{}.png'.format(output_root), show_shapes=True)\n",
    "        print('Saved model plot to {}.png'.format(output_root))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights.\n",
      "Weights Header:  0 2 0 [32013312]\n",
      "Parsing Darknet config.\n",
      "Creating Keras model.\n",
      "Parsing section net_0\n",
      "Parsing section convolutional_0\n",
      "conv2d bn leaky (32, 3, 3, 3)\n",
      "Parsing section convolutional_1\n",
      "conv2d bn leaky (64, 32, 3, 3)\n",
      "Parsing section convolutional_2\n",
      "conv2d bn leaky (32, 64, 1, 1)\n",
      "Parsing section convolutional_3\n",
      "conv2d bn leaky (64, 32, 3, 3)\n",
      "Parsing section shortcut_0\n",
      "Parsing section convolutional_4\n",
      "conv2d bn leaky (128, 64, 3, 3)\n",
      "Parsing section convolutional_5\n",
      "conv2d bn leaky (64, 128, 1, 1)\n",
      "Parsing section convolutional_6\n",
      "conv2d bn leaky (128, 64, 3, 3)\n",
      "Parsing section shortcut_1\n",
      "Parsing section convolutional_7\n",
      "conv2d bn leaky (64, 128, 1, 1)\n",
      "Parsing section convolutional_8\n",
      "conv2d bn leaky (128, 64, 3, 3)\n",
      "Parsing section shortcut_2\n",
      "Parsing section convolutional_9\n",
      "conv2d bn leaky (256, 128, 3, 3)\n",
      "Parsing section convolutional_10\n",
      "conv2d bn leaky (128, 256, 1, 1)\n",
      "Parsing section convolutional_11\n",
      "conv2d bn leaky (256, 128, 3, 3)\n",
      "Parsing section shortcut_3\n",
      "Parsing section convolutional_12\n",
      "conv2d bn leaky (128, 256, 1, 1)\n",
      "Parsing section convolutional_13\n",
      "conv2d bn leaky (256, 128, 3, 3)\n",
      "Parsing section shortcut_4\n",
      "Parsing section convolutional_14\n",
      "conv2d bn leaky (128, 256, 1, 1)\n",
      "Parsing section convolutional_15\n",
      "conv2d bn leaky (256, 128, 3, 3)\n",
      "Parsing section shortcut_5\n",
      "Parsing section convolutional_16\n",
      "conv2d bn leaky (128, 256, 1, 1)\n",
      "Parsing section convolutional_17\n",
      "conv2d bn leaky (256, 128, 3, 3)\n",
      "Parsing section shortcut_6\n",
      "Parsing section convolutional_18\n",
      "conv2d bn leaky (128, 256, 1, 1)\n",
      "Parsing section convolutional_19\n",
      "conv2d bn leaky (256, 128, 3, 3)\n",
      "Parsing section shortcut_7\n",
      "Parsing section convolutional_20\n",
      "conv2d bn leaky (128, 256, 1, 1)\n",
      "Parsing section convolutional_21\n",
      "conv2d bn leaky (256, 128, 3, 3)\n",
      "Parsing section shortcut_8\n",
      "Parsing section convolutional_22\n",
      "conv2d bn leaky (128, 256, 1, 1)\n",
      "Parsing section convolutional_23\n",
      "conv2d bn leaky (256, 128, 3, 3)\n",
      "Parsing section shortcut_9\n",
      "Parsing section convolutional_24\n",
      "conv2d bn leaky (128, 256, 1, 1)\n",
      "Parsing section convolutional_25\n",
      "conv2d bn leaky (256, 128, 3, 3)\n",
      "Parsing section shortcut_10\n",
      "Parsing section convolutional_26\n",
      "conv2d bn leaky (512, 256, 3, 3)\n",
      "Parsing section convolutional_27\n",
      "conv2d bn leaky (256, 512, 1, 1)\n",
      "Parsing section convolutional_28\n",
      "conv2d bn leaky (512, 256, 3, 3)\n",
      "Parsing section shortcut_11\n",
      "Parsing section convolutional_29\n",
      "conv2d bn leaky (256, 512, 1, 1)\n",
      "Parsing section convolutional_30\n",
      "conv2d bn leaky (512, 256, 3, 3)\n",
      "Parsing section shortcut_12\n",
      "Parsing section convolutional_31\n",
      "conv2d bn leaky (256, 512, 1, 1)\n",
      "Parsing section convolutional_32\n",
      "conv2d bn leaky (512, 256, 3, 3)\n",
      "Parsing section shortcut_13\n",
      "Parsing section convolutional_33\n",
      "conv2d bn leaky (256, 512, 1, 1)\n",
      "Parsing section convolutional_34\n",
      "conv2d bn leaky (512, 256, 3, 3)\n",
      "Parsing section shortcut_14\n",
      "Parsing section convolutional_35\n",
      "conv2d bn leaky (256, 512, 1, 1)\n",
      "Parsing section convolutional_36\n",
      "conv2d bn leaky (512, 256, 3, 3)\n",
      "Parsing section shortcut_15\n",
      "Parsing section convolutional_37\n",
      "conv2d bn leaky (256, 512, 1, 1)\n",
      "Parsing section convolutional_38\n",
      "conv2d bn leaky (512, 256, 3, 3)\n",
      "Parsing section shortcut_16\n",
      "Parsing section convolutional_39\n",
      "conv2d bn leaky (256, 512, 1, 1)\n",
      "Parsing section convolutional_40\n",
      "conv2d bn leaky (512, 256, 3, 3)\n",
      "Parsing section shortcut_17\n",
      "Parsing section convolutional_41\n",
      "conv2d bn leaky (256, 512, 1, 1)\n",
      "Parsing section convolutional_42\n",
      "conv2d bn leaky (512, 256, 3, 3)\n",
      "Parsing section shortcut_18\n",
      "Parsing section convolutional_43\n",
      "conv2d bn leaky (1024, 512, 3, 3)\n",
      "Parsing section convolutional_44\n",
      "conv2d bn leaky (512, 1024, 1, 1)\n",
      "Parsing section convolutional_45\n",
      "conv2d bn leaky (1024, 512, 3, 3)\n",
      "Parsing section shortcut_19\n",
      "Parsing section convolutional_46\n",
      "conv2d bn leaky (512, 1024, 1, 1)\n",
      "Parsing section convolutional_47\n",
      "conv2d bn leaky (1024, 512, 3, 3)\n",
      "Parsing section shortcut_20\n",
      "Parsing section convolutional_48\n",
      "conv2d bn leaky (512, 1024, 1, 1)\n",
      "Parsing section convolutional_49\n",
      "conv2d bn leaky (1024, 512, 3, 3)\n",
      "Parsing section shortcut_21\n",
      "Parsing section convolutional_50\n",
      "conv2d bn leaky (512, 1024, 1, 1)\n",
      "Parsing section convolutional_51\n",
      "conv2d bn leaky (1024, 512, 3, 3)\n",
      "Parsing section shortcut_22\n",
      "Parsing section convolutional_52\n",
      "conv2d bn leaky (512, 1024, 1, 1)\n",
      "Parsing section convolutional_53\n",
      "conv2d bn leaky (1024, 512, 3, 3)\n",
      "Parsing section convolutional_54\n",
      "conv2d bn leaky (512, 1024, 1, 1)\n",
      "Parsing section convolutional_55\n",
      "conv2d bn leaky (1024, 512, 3, 3)\n",
      "Parsing section convolutional_56\n",
      "conv2d bn leaky (512, 1024, 1, 1)\n",
      "Parsing section convolutional_57\n",
      "conv2d bn leaky (1024, 512, 3, 3)\n",
      "Parsing section convolutional_58\n",
      "conv2d    linear (255, 1024, 1, 1)\n",
      "Parsing section yolo_0\n",
      "Parsing section route_0\n",
      "Parsing section convolutional_59\n",
      "conv2d bn leaky (256, 512, 1, 1)\n",
      "Parsing section upsample_0\n",
      "Parsing section route_1\n",
      "Concatenating route layers: [<KerasTensor: shape=(None, 38, 38, 256) dtype=float32 (created by layer 'up_sampling2d')>, <KerasTensor: shape=(None, 38, 38, 512) dtype=float32 (created by layer 'add_18')>]\n",
      "Parsing section convolutional_60\n",
      "conv2d bn leaky (256, 768, 1, 1)\n",
      "Parsing section convolutional_61\n",
      "conv2d bn leaky (512, 256, 3, 3)\n",
      "Parsing section convolutional_62\n",
      "conv2d bn leaky (256, 512, 1, 1)\n",
      "Parsing section convolutional_63\n",
      "conv2d bn leaky (512, 256, 3, 3)\n",
      "Parsing section convolutional_64\n",
      "conv2d bn leaky (256, 512, 1, 1)\n",
      "Parsing section convolutional_65\n",
      "conv2d bn leaky (512, 256, 3, 3)\n",
      "Parsing section convolutional_66\n",
      "conv2d    linear (255, 512, 1, 1)\n",
      "Parsing section yolo_1\n",
      "Parsing section route_2\n",
      "Parsing section convolutional_67\n",
      "conv2d bn leaky (128, 256, 1, 1)\n",
      "Parsing section upsample_1\n",
      "Parsing section route_3\n",
      "Concatenating route layers: [<KerasTensor: shape=(None, 76, 76, 128) dtype=float32 (created by layer 'up_sampling2d_1')>, <KerasTensor: shape=(None, 76, 76, 256) dtype=float32 (created by layer 'add_10')>]\n",
      "Parsing section convolutional_68\n",
      "conv2d bn leaky (128, 384, 1, 1)\n",
      "Parsing section convolutional_69\n",
      "conv2d bn leaky (256, 128, 3, 3)\n",
      "Parsing section convolutional_70\n",
      "conv2d bn leaky (128, 256, 1, 1)\n",
      "Parsing section convolutional_71\n",
      "conv2d bn leaky (256, 128, 3, 3)\n",
      "Parsing section convolutional_72\n",
      "conv2d bn leaky (128, 256, 1, 1)\n",
      "Parsing section convolutional_73\n",
      "conv2d bn leaky (256, 128, 3, 3)\n",
      "Parsing section convolutional_74\n",
      "conv2d    linear (255, 256, 1, 1)\n",
      "Parsing section yolo_2\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Saved Keras model to /notebooks/models/yologv3.h5\n",
      "Read 62001757 of 62001757 from Darknet weights.\n"
     ]
    }
   ],
   "source": [
    "# read the model from the config file\n",
    "config_path = '/notebooks/config/yolov3.cfg'\n",
    "weights_path = '/notebooks/models/yolov3g.weights'\n",
    "output_path = '/notebooks/models/yologv3'\n",
    "partial_model = parse_config(config_path, output_path=output_path, weights_path=weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_boxes_graph(y_pred_xy, y_pred_wh, input_shape, image_shape):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        y_pred_xy: (b, fh, fw, num_anchors_this_layer, 2)\n",
    "        y_pred_wh: (b, fh, fw, num_anchors_this_layer, 2)\n",
    "        input_shape: (b, 2), hw\n",
    "        image_shape: (b, 2), hw\n",
    "\n",
    "    Returns:\n",
    "        boxes: (b, fh, fw, num_anchors_this_layer, 4), (y_min, x_min, y_max, x_max)\n",
    "\n",
    "    \"\"\"\n",
    "    box_yx = y_pred_xy[..., ::-1]\n",
    "    box_hw = y_pred_wh[..., ::-1]\n",
    "    input_shape = K.cast(input_shape, K.dtype(box_yx))\n",
    "    image_shape = K.cast(image_shape, K.dtype(box_yx))\n",
    "    new_shape = K.round(image_shape * K.min(input_shape / image_shape))\n",
    "    offset = (input_shape - new_shape) / 2. / input_shape\n",
    "    scale = input_shape / new_shape\n",
    "    box_yx = (box_yx - offset) * scale\n",
    "    box_hw *= scale\n",
    "    box_mins = box_yx - (box_hw / 2.)\n",
    "    box_maxes = box_yx + (box_hw / 2.)\n",
    "    boxes = K.concatenate([\n",
    "        # y_min\n",
    "        box_mins[..., 0:1],\n",
    "        # x_min\n",
    "        box_mins[..., 1:2],\n",
    "        # y_max\n",
    "        box_maxes[..., 0:1],\n",
    "        # x_max\n",
    "        box_maxes[..., 1:2]\n",
    "    ])\n",
    "\n",
    "    # Scale boxes back to original image shape.\n",
    "    boxes *= K.concatenate([image_shape, image_shape])\n",
    "    \n",
    "    return boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_boxes_and_scores_graph(raw_y_pred, anchors, num_classes, input_shape, image_shape):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        raw_y_pred:\n",
    "        anchors: (num_anchors_this_layer, 2)\n",
    "        num_classes:\n",
    "        input_shape: (2, ) hw\n",
    "        image_shape: (batch_size, 2)\n",
    "\n",
    "    Returns:\n",
    "        boxes: (b, total_num_anchors_this_layer, 4), (y_min, x_min, y_max, x_max)\n",
    "        boxes_scores: (b, total_num_anchors_this_layer, num_classes)\n",
    "\n",
    "    \"\"\"\n",
    "    _, y_pred_box, _, _, y_pred_sigma, y_pred_confidence, y_pred_class_probs = y_pred_graph(raw_y_pred, anchors, input_shape)\n",
    "    y_pred_xy = y_pred_box[..., :2]\n",
    "    y_pred_wh = y_pred_box[..., 2:]\n",
    "    # for batch predictions\n",
    "    batch_size = K.shape(image_shape)[0]\n",
    "    input_shape = K.expand_dims(input_shape, axis=0)\n",
    "    input_shape = K.tile(input_shape, (batch_size, 1))\n",
    "    elems = (y_pred_xy, y_pred_wh, input_shape, image_shape)\n",
    "    boxes = tf.map_fn(lambda x: correct_boxes_graph(x[0], x[1], x[2], x[3]), elems=elems, dtype=tf.float32)\n",
    "    box_scores = y_pred_confidence * y_pred_class_probs * (1 - tf.reduce_mean(y_pred_sigma, axis=-1, keepdims=True))\n",
    "    boxes = tf.reshape(boxes, [batch_size, -1, 4])\n",
    "    box_scores = tf.reshape(box_scores, [batch_size, -1, num_classes])\n",
    "    \n",
    "    return boxes, box_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_iou_graph(b1, b2):\n",
    "    \"\"\"\n",
    "    Return iou tensor\n",
    "\n",
    "    Args:\n",
    "        b1 (tensor): (fh, fw, num_anchors_this_layer, 4)\n",
    "        b2 (tensor): (num_gt_boxes, 4)\n",
    "\n",
    "    Returns:\n",
    "        iou (tensor): shape=(num_b1_boxes, num_b2_boxes)\n",
    "    \"\"\"\n",
    "    # Expand dim to apply broadcasting.\n",
    "    # (fh, fw, num_anchors_this_layer, 1, 4)\n",
    "    b1 = K.expand_dims(b1, -2)\n",
    "    b1_xy = b1[..., :2]\n",
    "    b1_wh = b1[..., 2:4]\n",
    "    b1_wh_half = b1_wh / 2.\n",
    "    b1_mins = b1_xy - b1_wh_half\n",
    "    b1_maxes = b1_xy + b1_wh_half\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    # (1, num_gt_boxes, 4)\n",
    "    b2 = K.expand_dims(b2, 0)\n",
    "    b2_xy = b2[..., :2]\n",
    "    b2_wh = b2[..., 2:4]\n",
    "    b2_wh_half = b2_wh / 2.\n",
    "    b2_mins = b2_xy - b2_wh_half\n",
    "    b2_maxes = b2_xy + b2_wh_half\n",
    "\n",
    "    # (fh, fw, num_anchors_this_layer, num_b2_boxes, 2)\n",
    "    intersect_mins = K.maximum(b1_mins, b2_mins)\n",
    "    intersect_maxes = K.minimum(b1_maxes, b2_maxes)\n",
    "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    # (fh, fw, num_anchors_this_layer, num_b2_boxes)\n",
    "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    # (fh, fw, num_anchors_this_layer, 1)\n",
    "    b1_area = b1_wh[..., 0] * b1_wh[..., 1]\n",
    "    # (1, num_gt_boxes)\n",
    "    b2_area = b2_wh[..., 0] * b2_wh[..., 1]\n",
    "    iou = intersect_area / (b1_area + b2_area - intersect_area)\n",
    "    \n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_pred_graph(raw_y_pred, anchors, input_shape):\n",
    "    \"\"\"\n",
    "    Convert final layer features to bounding box parameters.\n",
    "\n",
    "    Args:\n",
    "        raw_y_pred: (b, fh, fw, num_anchors_per_layer, 2 + 2 + 1 + num_classes)\n",
    "        anchors:\n",
    "        input_shape:\n",
    "\n",
    "    Returns:\n",
    "        grid: (fh, fw, 1, 2)\n",
    "        y_pred_box: (b, fh, fw, num_anchors_this_layer, 2 + 2)\n",
    "        y_pred_delta_xy:\n",
    "        y_pred_log_wh:\n",
    "        y_pred_confidence: (b, fh, fw, num_anchors_this_layer, 1)\n",
    "        y_pred_class_probs: (b, fh, fw, num_anchors_this_layer, num_classes)\n",
    "    \"\"\"\n",
    "    num_anchors_this_layer = len(anchors)\n",
    "    # Reshape to (batch, height, width, num_anchors, box_params)\n",
    "    anchors_tensor = K.reshape(K.constant(anchors), [1, 1, 1, num_anchors_this_layer, 2])\n",
    "    grid_shape = K.shape(raw_y_pred)[1:3]\n",
    "    grid_y = K.tile(K.reshape(K.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1]), [1, grid_shape[1], 1, 1])\n",
    "    grid_x = K.tile(K.reshape(K.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]), [grid_shape[0], 1, 1, 1])\n",
    "    grid = K.concatenate([grid_x, grid_y], axis=-1)\n",
    "    grid = K.cast(grid, K.dtype(raw_y_pred))\n",
    "    y_pred_xy = (K.sigmoid(raw_y_pred[..., :2]) + grid) / K.cast(grid_shape[::-1], K.dtype(raw_y_pred))\n",
    "    y_pred_wh = K.exp(raw_y_pred[..., 2:4]) * (anchors_tensor / K.cast(input_shape[::-1], K.dtype(raw_y_pred)))\n",
    "    # (batch_size, grid_height, grid_width, num_anchors_this_layer, 4)\n",
    "    y_pred_box = K.concatenate([y_pred_xy, y_pred_wh])\n",
    "    y_pred_delta_xy = K.sigmoid(raw_y_pred[..., :2])\n",
    "    y_pred_log_wh = raw_y_pred[..., 2:4]\n",
    "    y_pred_sigma = K.sigmoid(raw_y_pred[..., 4:8])\n",
    "    y_pred_confidence = K.sigmoid(raw_y_pred[..., 8:9])\n",
    "    y_pred_class_probs = K.sigmoid(raw_y_pred[..., 9:])\n",
    "\n",
    "    return grid, y_pred_box, y_pred_delta_xy, y_pred_log_wh, y_pred_sigma, y_pred_confidence, y_pred_class_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the detection layer to the model\n",
    "class DetectionLayer(Layer):\n",
    "    def __init__(self,\n",
    "                 anchors,\n",
    "                 num_classes=20,\n",
    "                 max_boxes_per_class_per_image=20,\n",
    "                 score_threshold=.2,\n",
    "                 iou_threshold=.5,\n",
    "                 max_boxes_per_image=400,\n",
    "                 **kwargs\n",
    "                 ):\n",
    "        super(DetectionLayer, self).__init__(**kwargs)\n",
    "        self.anchors = anchors\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.max_boxes_per_class_per_image = max_boxes_per_class_per_image\n",
    "        self.max_boxes_per_image = max_boxes_per_image\n",
    "        self.num_classes = num_classes\n",
    "        self.score_threshold = score_threshold\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        yolo_outputs = inputs[:-1]\n",
    "        batch_image_shape = inputs[-1]\n",
    "        num_output_layers = len(yolo_outputs)\n",
    "        num_anchors_per_layer = len(self.anchors) // num_output_layers\n",
    "        anchor_mask = [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n",
    "        # tensor, (2, )\n",
    "        input_shape = K.shape(yolo_outputs[0])[1:3] * 32\n",
    "        grid_shapes = [K.shape(yolo_outputs[l])[1:3]\n",
    "                       for l in range(num_output_layers)]\n",
    "        boxes_all_layers = []\n",
    "        scores_all_layers = []\n",
    "        for l in range(num_output_layers):\n",
    "            yolo_output = yolo_outputs[l]\n",
    "            grid_shape = grid_shapes[l]\n",
    "            raw_y_pred = K.reshape(yolo_output,\n",
    "            [-1, grid_shape[0], grid_shape[1], num_anchors_per_layer, self.num_classes + 9])\n",
    "            boxes_this_layer, scores_this_layer = correct_boxes_and_scores_graph(raw_y_pred,\n",
    "                self.anchors[anchor_mask[l]],\n",
    "                self.num_classes,\n",
    "                input_shape,\n",
    "                batch_image_shape,\n",
    "                )\n",
    "            boxes_all_layers.append(boxes_this_layer)\n",
    "            scores_all_layers.append(scores_this_layer)\n",
    "\n",
    "        # (b, total_num_anchors_all_layers, 4)\n",
    "        boxes = K.concatenate(boxes_all_layers, axis=1)\n",
    "        # (b, total_num_anchors_all_layers, num_classes)\n",
    "        scores = K.concatenate(scores_all_layers, axis=1)\n",
    "        mask = scores >= self.score_threshold\n",
    "        max_boxes_per_class_per_image_tensor = K.constant(\n",
    "            self.max_boxes_per_class_per_image, dtype='int32')\n",
    "        max_boxes_per_image_tensor = K.constant(\n",
    "            self.max_boxes_per_image, dtype='int32')\n",
    "\n",
    "        def evaluate_batch_item(batch_item_boxes, batch_item_scores, batch_item_mask):\n",
    "            boxes_per_class = []\n",
    "            scores_per_class = []\n",
    "            class_ids_per_class = []\n",
    "            for c in range(self.num_classes):\n",
    "                class_boxes = tf.boolean_mask(\n",
    "                    batch_item_boxes, batch_item_mask[:, c])\n",
    "                # (num_keep_this_class_boxes, )\n",
    "                class_scores = tf.boolean_mask(\n",
    "                    batch_item_scores[:, c], batch_item_mask[:, c])\n",
    "                nms_keep_indices = tf.image.non_max_suppression(class_boxes,\n",
    "                                                                class_scores,\n",
    "                                                                max_boxes_per_class_per_image_tensor,\n",
    "                                                                iou_threshold=self.iou_threshold)\n",
    "                class_boxes = K.gather(class_boxes, nms_keep_indices)\n",
    "                class_scores = K.gather(class_scores, nms_keep_indices)\n",
    "                # (num_keep_this_class_boxes, )\n",
    "                class_class_ids = K.ones_like(class_scores, 'float32') * c\n",
    "                boxes_per_class.append(class_boxes)\n",
    "                scores_per_class.append(class_scores)\n",
    "                class_ids_per_class.append(class_class_ids)\n",
    "\n",
    "            batch_item_boxes = K.concatenate(boxes_per_class, axis=0)\n",
    "            batch_item_scores = K.concatenate(scores_per_class, axis=0)\n",
    "            batch_item_scores = K.expand_dims(batch_item_scores, axis=-1)\n",
    "            batch_item_class_ids = K.concatenate(class_ids_per_class, axis=0)\n",
    "            batch_item_class_ids = K.expand_dims(batch_item_class_ids, axis=-1)\n",
    "            # (num_keep_all_class_boxes, 6)\n",
    "            batch_item_predictions = K.concatenate([batch_item_boxes,\n",
    "                                                    batch_item_scores,\n",
    "                                                    batch_item_class_ids], axis=-1)\n",
    "            batch_item_num_predictions = tf.shape(batch_item_boxes)[0]\n",
    "            tf.print(batch_item_num_predictions, [batch_item_num_predictions], '\\nbatch_item_num_predictions', summarize=1000)\n",
    "            batch_item_num_pad = tf.maximum(\n",
    "                max_boxes_per_image_tensor - batch_item_num_predictions, 0)\n",
    "            padded_batch_item_predictions = tf.pad(tensor=batch_item_predictions,\n",
    "                                                   paddings=[\n",
    "                                                       [0, batch_item_num_pad],\n",
    "                                                       [0, 0]],\n",
    "                                                   mode='CONSTANT',\n",
    "                                                   constant_values=0.0)\n",
    "            return padded_batch_item_predictions\n",
    "\n",
    "        predictions = tf.map_fn(lambda x: evaluate_batch_item(x[0], x[1], x[2]),\n",
    "                                elems=(boxes, scores, mask),\n",
    "                                dtype=tf.float32)\n",
    "\n",
    "        predictions = tf.reshape(\n",
    "            predictions, (-1, self.max_boxes_per_image, 6))\n",
    "        return predictions\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return None, self.max_boxes_per_image, 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_loss(x, mu, sigma, sigma_const=0.3):\n",
    "    pi = tf.constant(np.pi)\n",
    "    Z = (2 * pi * (sigma + sigma_const) ** 2) ** 0.5\n",
    "    probability_density = tf.exp(-0.5 * (x - mu) ** 2 / ((sigma + sigma_const) ** 2)) / Z\n",
    "    nll = -tf.math.log(probability_density + 1e-7)\n",
    "    return nll\n",
    "\n",
    "\n",
    "def yolo_loss(args, anchors, num_anchors_per_layer, num_classes, ignore_thresh=.5, print_loss=True):\n",
    "    \"\"\"\n",
    "    Return yolo_loss tensor\n",
    "\n",
    "    Args:\n",
    "        args (list): args[:num_output_layers] the output of yolo_body or tiny_yolo_body\n",
    "            args[num_output_layers:] raw_y_true\n",
    "        anchors (np.array): shape=(N, 2), wh\n",
    "        num_anchors_per_layer (int):\n",
    "        num_classes (int):\n",
    "        ignore_thresh (float): the iou threshold whether to ignore object confidence loss\n",
    "        print_loss:\n",
    "\n",
    "    Returns:\n",
    "        loss: tensor, shape=(1,)\n",
    "\n",
    "    \"\"\"\n",
    "    num_output_layers = len(anchors) // num_anchors_per_layer\n",
    "    yolo_outputs = args[:num_output_layers]\n",
    "    raw_y_trues = args[num_output_layers:]\n",
    "    anchor_masks = [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n",
    "    input_shape = K.cast(K.shape(yolo_outputs[0])[1:3] * 32, K.dtype(raw_y_trues[0]))\n",
    "    grid_shapes = [K.cast(K.shape(yolo_outputs[l])[1:3], K.dtype(raw_y_trues[0])) for l in range(num_output_layers)]\n",
    "    loss = 0\n",
    "    batch_size = K.shape(yolo_outputs[0])[0]\n",
    "    batch_size_f = K.cast(batch_size, K.dtype(yolo_outputs[0]))\n",
    "\n",
    "    # with tqdm(, total=STEPS_PER_EPOCH) as pbar:\n",
    "    for l in range(num_output_layers):\n",
    "        grid_shape = grid_shapes[l]\n",
    "        yolo_output = yolo_outputs[l]\n",
    "        raw_y_pred = K.reshape(yolo_output, [-1, grid_shape[0], grid_shape[1], num_anchors_per_layer, num_classes + 9])\n",
    "        raw_y_true = raw_y_trues[l]\n",
    "        anchor_mask = anchor_masks[l]\n",
    "        # (batch_size, grid_height, grid_width, num_anchors_this_layer, 1)\n",
    "        object_mask = raw_y_true[..., 4:5]\n",
    "        # (batch_size, grid_height, grid_width, num_anchors_this_layer, num_classes)\n",
    "        y_true_class_probs = raw_y_true[..., 5:]\n",
    "        grid, y_pred_box, y_pred_delta_xy, y_pred_log_wh, y_pred_sigma, y_pred_confidence, y_pred_class_probs = \\\n",
    "            y_pred_graph(raw_y_pred, anchors[anchor_mask], input_shape)\n",
    "        y_true_delta_xy = raw_y_true[..., :2] * grid_shapes[l][::-1] - grid\n",
    "        y_true_log_wh = K.log(raw_y_true[..., 2:4] * input_shape[::-1] / anchors[anchor_mask])\n",
    "        y_true_log_wh = K.switch(object_mask, y_true_log_wh, K.zeros_like(y_true_log_wh))\n",
    "        box_loss_scale = 2 - raw_y_true[..., 2:3] * raw_y_true[..., 3:4]\n",
    "        ignore_mask = tf.TensorArray(K.dtype(raw_y_trues[0]), size=1, dynamic_size=True)\n",
    "        object_mask_bool = K.cast(object_mask, 'bool')\n",
    "\n",
    "        def loop_body(b, ignore_mask_):\n",
    "            # (num_gt_boxes, 4)\n",
    "            gt_box = tf.boolean_mask(raw_y_true[b, ..., 0:4], object_mask_bool[b, ..., 0])\n",
    "            # (grid_height, grid_width, num_anchors_this_layer, num_gt_boxes)\n",
    "            iou = box_iou_graph(y_pred_box[b], gt_box)\n",
    "            # (grid_height, grid_width, num_anchors_this_layer)\n",
    "            best_iou = K.max(iou, axis=-1)\n",
    "            ignore_mask_ = ignore_mask_.write(b, K.cast(best_iou < ignore_thresh, K.dtype(gt_box)))\n",
    "            return b + 1, ignore_mask_\n",
    "\n",
    "        _, ignore_mask = tf.while_loop(lambda b, *largs: b < batch_size, loop_body, [0, ignore_mask])\n",
    "        # (batch_size, grid_height, grid_width, num_anchors_this_layer)\n",
    "        ignore_mask = ignore_mask.stack()\n",
    "        # (batch_size, grid_height, grid_width, num_anchors_this_layer, 1)\n",
    "        ignore_mask = K.expand_dims(ignore_mask, -1)\n",
    "\n",
    "        y_true = tf.concat([y_true_delta_xy, y_true_log_wh], axis=-1)\n",
    "        y_pred_mu = tf.concat([y_pred_delta_xy, y_pred_log_wh], axis=-1)\n",
    "        x_loss = nll_loss(y_true[..., 0:1], y_pred_mu[..., 0:1], y_pred_sigma[..., 0:1])\n",
    "        x_loss = object_mask * box_loss_scale * x_loss\n",
    "        y_loss = nll_loss(y_true[..., 1:2], y_pred_mu[..., 1:2], y_pred_sigma[..., 1:2])\n",
    "        y_loss = object_mask * box_loss_scale * y_loss\n",
    "        w_loss = nll_loss(y_true[..., 2:3], y_pred_mu[..., 2:3], y_pred_sigma[..., 2:3])\n",
    "        w_loss = object_mask * box_loss_scale * w_loss\n",
    "        h_loss = nll_loss(y_true[..., 3:4], y_pred_mu[..., 3:4], y_pred_sigma[..., 3:4])\n",
    "        h_loss = object_mask * box_loss_scale * h_loss\n",
    "        confidence_loss = object_mask * K.binary_crossentropy(object_mask, y_pred_confidence) + \\\n",
    "                        (1 - object_mask) * K.binary_crossentropy(object_mask, y_pred_confidence) * ignore_mask\n",
    "        class_loss = object_mask * K.binary_crossentropy(y_true_class_probs, y_pred_class_probs)\n",
    "        x_loss = K.sum(x_loss) / batch_size_f\n",
    "        y_loss = K.sum(y_loss) / batch_size_f\n",
    "        w_loss = K.sum(w_loss) / batch_size_f\n",
    "        h_loss = K.sum(h_loss) / batch_size_f\n",
    "        confidence_loss = K.sum(confidence_loss) / batch_size_f\n",
    "        class_loss = K.sum(class_loss) / batch_size_f\n",
    "        loss += x_loss + y_loss + w_loss + h_loss + confidence_loss + class_loss\n",
    "\n",
    "        # print the loss for debugging\n",
    "\n",
    "\n",
    "        # if print_loss:\n",
    "        #     tf.print('\\nloss: ', loss, [loss, x_loss, y_loss, w_loss, h_loss, confidence_loss, class_loss],)\n",
    "            \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose(*funcs):\n",
    "    \"\"\"\n",
    "    Compose arbitrarily many functions, evaluated left to right.\n",
    "\n",
    "    Reference: https://mathieularose.com/function-composition-in-python/\n",
    "    \"\"\"\n",
    "    # return lambda x: reduce(lambda v, f: f(v), funcs, x)\n",
    "    if funcs:\n",
    "        return reduce(lambda f, g: lambda *args, **kwargs: g(f(*args, **kwargs)), funcs)\n",
    "    else:\n",
    "        raise ValueError('Composition of empty sequence not supported.')\n",
    "\n",
    "\n",
    "def darknet_conv2d(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    Wrapper to set Darknet parameters for Convolution2D.\n",
    "    \"\"\"\n",
    "    darknet_conv_kwargs = dict({'kernel_regularizer': l2(5e-4)})\n",
    "    darknet_conv_kwargs['padding'] = 'valid' if kwargs.get('strides') == (2, 2) else 'same'\n",
    "    darknet_conv_kwargs.update(kwargs)\n",
    "    return Conv2D(*args, **darknet_conv_kwargs)\n",
    "\n",
    "\n",
    "def darknet_conv2d_bn_leaky(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    Darknet Convolution2D followed by BatchNormalization and LeakyReLU.\n",
    "    \"\"\"\n",
    "    no_bias_kwargs = {'use_bias': False}\n",
    "    no_bias_kwargs.update(kwargs)\n",
    "    return compose(\n",
    "        darknet_conv2d(*args, **no_bias_kwargs),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1))\n",
    "\n",
    "\n",
    "def resblock_body(x, num_filters, num_blocks):\n",
    "    \"\"\"\n",
    "    A series of resblocks starting with a downsampling Convolution2D\n",
    "    \"\"\"\n",
    "    # Darknet uses left and top padding instead of 'same' mode\n",
    "    x = ZeroPadding2D(((1, 0), (1, 0)))(x)\n",
    "    x = darknet_conv2d_bn_leaky(num_filters, (3, 3), strides=(2, 2))(x)\n",
    "    for i in range(num_blocks):\n",
    "        y = compose(\n",
    "            darknet_conv2d_bn_leaky(num_filters // 2, (1, 1)),\n",
    "            darknet_conv2d_bn_leaky(num_filters, (3, 3)))(x)\n",
    "        x = Add()([x, y])\n",
    "    return x\n",
    "\n",
    "\n",
    "def darknet_body(x):\n",
    "    \"\"\"\n",
    "    Darknet body having 52 Convolution2D layers\n",
    "    1 + (1 + 1 * 2) + (1 + 2 * 2) + (1 + 8 * 2) + (1 + 8 * 2) + (1 + 4 * 2) = 1 + 3 + 5 + 17 + 17 + 9 = 52\n",
    "    \"\"\"\n",
    "    # (416, 416)\n",
    "    x = darknet_conv2d_bn_leaky(32, (3, 3))(x)\n",
    "    # (208, 208)\n",
    "    x = resblock_body(x, 64, 1)\n",
    "    # (104, 104)\n",
    "    x = resblock_body(x, 128, 2)\n",
    "    # (52, 52)\n",
    "    x = resblock_body(x, 256, 8)\n",
    "    # (26, 26)\n",
    "    x = resblock_body(x, 512, 8)\n",
    "    # (13, 13)\n",
    "    x = resblock_body(x, 1024, 4)\n",
    "    return x\n",
    "\n",
    "\n",
    "def make_last_layers(x, num_filters, out_filters):\n",
    "    \"\"\"\n",
    "    6 conv2d_bn_leaky layers followed by a conv2d layer\n",
    "    \"\"\"\n",
    "    x = compose(darknet_conv2d_bn_leaky(num_filters, (1, 1)),\n",
    "                darknet_conv2d_bn_leaky(num_filters * 2, (3, 3)),\n",
    "                darknet_conv2d_bn_leaky(num_filters, (1, 1)),\n",
    "                darknet_conv2d_bn_leaky(num_filters * 2, (3, 3)),\n",
    "                darknet_conv2d_bn_leaky(num_filters, (1, 1)))(x)\n",
    "    y = compose(darknet_conv2d_bn_leaky(num_filters * 2, (3, 3)),\n",
    "                darknet_conv2d(out_filters, (1, 1)))(x)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def yolo_body(anchors, num_classes=20, score_threshold=0.01):\n",
    "    \"\"\"\n",
    "    Create YOLO_V3 model CNN body in Keras.\n",
    "\n",
    "    Args:\n",
    "        anchors:\n",
    "        num_classes:\n",
    "        score_threshold:\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    num_anchors = len(anchors)\n",
    "    num_anchors_per_layer = num_anchors // 3\n",
    "    image_input = Input(shape=(None, None, 3), name='image_input')\n",
    "    fm_13_input = Input(shape=(None, None, num_anchors_per_layer, num_classes + 5), name='fm_13_input')\n",
    "    fm_26_input = Input(shape=(None, None, num_anchors_per_layer, num_classes + 5), name='fm_26_input')\n",
    "    fm_52_input = Input(shape=(None, None, num_anchors_per_layer, num_classes + 5), name='fm_52_input')\n",
    "    image_shape_input = Input(shape=(2,), name='image_shape_input')\n",
    "\n",
    "    darknet = Model([image_input], darknet_body(image_input))\n",
    "    \n",
    "    x, y1 = make_last_layers(darknet.output, 512, num_anchors_per_layer * (num_classes + 9))\n",
    "    x = compose(darknet_conv2d_bn_leaky(256, (1, 1)), UpSampling2D(2))(x)\n",
    "    x = Concatenate()([x, darknet.layers[152].output])\n",
    "    x, y2 = make_last_layers(x, 256, num_anchors_per_layer * (num_classes + 9))\n",
    "    x = compose(darknet_conv2d_bn_leaky(128, (1, 1)), UpSampling2D(2))(x)\n",
    "    x = Concatenate()([x, darknet.layers[92].output])\n",
    "    x, y3 = make_last_layers(x, 128, num_anchors_per_layer * (num_classes + 9))\n",
    "\n",
    "    loss = Lambda(\n",
    "        yolo_loss,\n",
    "        output_shape=(1,),\n",
    "        name='yolo_loss',\n",
    "        arguments={'anchors': anchors,\n",
    "            'num_anchors_per_layer': num_anchors_per_layer,\n",
    "            'num_classes': num_classes,\n",
    "            'ignore_thresh': 0.5})(\n",
    "        [y1, y2, y3, fm_13_input, fm_26_input, fm_52_input])\n",
    "    training_model = Model([image_input, fm_13_input, fm_26_input, fm_52_input], loss, name='yolo')\n",
    "    detections = DetectionLayer(anchors, num_classes=num_classes, score_threshold=score_threshold, name='yolo_detection')(\n",
    "        [y1, y2, y3, image_shape_input])\n",
    "    prediction_model = Model([image_input, image_shape_input], detections, name='yolo')\n",
    "\n",
    "    return training_model, prediction_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyprameters\n",
    "BATCH_SIZE = 8\n",
    "CONFIDENCE = 0.5\n",
    "NMS_CONF = 0.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=13.49s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.38s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "misc_effect = MiscEffect()\n",
    "visual_effect = VisualEffect()\n",
    "\n",
    "\n",
    "train_generator = CocoGenerator(\n",
    "    data_dir='/notebooks/data',\n",
    "    set_name='train2017',\n",
    "    # misc_effect=misc_effect,\n",
    "    # visual_effect=visual_effect,\n",
    "    anchors_path='/notebooks/data/yolo_anchors.txt',\n",
    "    multi_scale=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=608,\n",
    ")\n",
    "\n",
    "val_generator = CocoGenerator(\n",
    "    data_dir='/notebooks/data',\n",
    "    set_name='val2017',\n",
    "    shuffle_groups=False,\n",
    "    anchors_path='/notebooks/data/yolo_anchors.txt',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=608,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_classes(namesfile):\n",
    "    fp = open(namesfile, \"r\")\n",
    "    names = fp.read().split(\"\\n\")[:-1]\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "num_classes = 80\n",
    "classes = load_classes(\"./data/coco.names\")\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_anchors():\n",
    "#         \"\"\"\n",
    "#         loads the anchors from a txt file\n",
    "#         \"\"\"\n",
    "#         anchors = \"10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\"\n",
    "#         anchors = [float(x) for x in anchors.split(',')]\n",
    "#         # (N, 2), wh\n",
    "#         return np.array(anchors).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchors:  [[ 10.  13.]\n",
      " [ 16.  30.]\n",
      " [ 33.  23.]\n",
      " [ 30.  61.]\n",
      " [ 62.  45.]\n",
      " [ 59. 119.]\n",
      " [116.  90.]\n",
      " [156. 198.]\n",
      " [373. 326.]]\n"
     ]
    }
   ],
   "source": [
    "input_shape = (608, 608)\n",
    "anchors = train_generator.anchors\n",
    "num_classes = train_generator.num_classes()\n",
    "print(\"anchors: \", anchors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model, prediction_model = yolo_body(anchors, num_classes=num_classes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model, this may take a second...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "    # create the model\n",
    "print('Loading model, this may take a second...')\n",
    "model.load_weights(\"/notebooks/models/yologv3.h5\", by_name=True, skip_mismatch=True)\n",
    "\n",
    "# freeze_body = 'none'\n",
    "\n",
    "# if freeze_body == 'darknet':\n",
    "#     for i in range(185):\n",
    "#         model.layers[i].trainable = False\n",
    "# elif freeze_body == 'yolo':\n",
    "#     for i in range(len(model.layers) - 7):\n",
    "#         model.layers[i].trainable = False\n",
    "# else:\n",
    "#     pass\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer=Adam(lr=1e-3), loss={'yolo_loss': lambda y_true, y_pred: y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"yolo\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image_input (InputLayer)       [(None, None, None,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, None, None,   864         ['image_input[0][0]']            \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, None, None,   128        ['conv2d_75[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_72 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_72[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_5 (ZeroPadding2  (None, None, None,   0          ['leaky_re_lu_72[0][0]']         \n",
      " D)                             32)                                                               \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, None, None,   18432       ['zero_padding2d_5[0][0]']       \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, None, None,   256        ['conv2d_76[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_73 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_73[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, None, None,   2048        ['leaky_re_lu_73[0][0]']         \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, None, None,   128        ['conv2d_77[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_74 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_74[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, None, None,   18432       ['leaky_re_lu_74[0][0]']         \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, None, None,   256        ['conv2d_78[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_75 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_75[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, None, None,   0           ['leaky_re_lu_73[0][0]',         \n",
      "                                64)                               'leaky_re_lu_75[0][0]']         \n",
      "                                                                                                  \n",
      " zero_padding2d_6 (ZeroPadding2  (None, None, None,   0          ['add_23[0][0]']                 \n",
      " D)                             64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, None, None,   73728       ['zero_padding2d_6[0][0]']       \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, None, None,   512        ['conv2d_79[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_76 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_76[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, None, None,   8192        ['leaky_re_lu_76[0][0]']         \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, None, None,   256        ['conv2d_80[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_77 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_77[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, None, None,   73728       ['leaky_re_lu_77[0][0]']         \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, None, None,   512        ['conv2d_81[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_78 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_78[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, None, None,   0           ['leaky_re_lu_76[0][0]',         \n",
      "                                128)                              'leaky_re_lu_78[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, None, None,   8192        ['add_24[0][0]']                 \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, None, None,   256        ['conv2d_82[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_79 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_79[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, None, None,   73728       ['leaky_re_lu_79[0][0]']         \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, None, None,   512        ['conv2d_83[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_80 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_80[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, None, None,   0           ['add_24[0][0]',                 \n",
      "                                128)                              'leaky_re_lu_80[0][0]']         \n",
      "                                                                                                  \n",
      " zero_padding2d_7 (ZeroPadding2  (None, None, None,   0          ['add_25[0][0]']                 \n",
      " D)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, None, None,   294912      ['zero_padding2d_7[0][0]']       \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, None, None,   1024       ['conv2d_84[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_81 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_81[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, None, None,   32768       ['leaky_re_lu_81[0][0]']         \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, None, None,   512        ['conv2d_85[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_82 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_82[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, None, None,   294912      ['leaky_re_lu_82[0][0]']         \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, None, None,   1024       ['conv2d_86[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_83 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_83[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, None, None,   0           ['leaky_re_lu_81[0][0]',         \n",
      "                                256)                              'leaky_re_lu_83[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, None, None,   32768       ['add_26[0][0]']                 \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, None, None,   512        ['conv2d_87[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_84 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_84[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, None, None,   294912      ['leaky_re_lu_84[0][0]']         \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, None, None,   1024       ['conv2d_88[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_85 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_85[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " add_27 (Add)                   (None, None, None,   0           ['add_26[0][0]',                 \n",
      "                                256)                              'leaky_re_lu_85[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, None, None,   32768       ['add_27[0][0]']                 \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, None, None,   512        ['conv2d_89[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_86 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_86[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, None, None,   294912      ['leaky_re_lu_86[0][0]']         \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, None, None,   1024       ['conv2d_90[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_87 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_87[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " add_28 (Add)                   (None, None, None,   0           ['add_27[0][0]',                 \n",
      "                                256)                              'leaky_re_lu_87[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, None, None,   32768       ['add_28[0][0]']                 \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, None, None,   512        ['conv2d_91[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_88 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_88[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, None, None,   294912      ['leaky_re_lu_88[0][0]']         \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, None, None,   1024       ['conv2d_92[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_89 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_89[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " add_29 (Add)                   (None, None, None,   0           ['add_28[0][0]',                 \n",
      "                                256)                              'leaky_re_lu_89[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, None, None,   32768       ['add_29[0][0]']                 \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, None, None,   512        ['conv2d_93[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_90 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_90[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)             (None, None, None,   294912      ['leaky_re_lu_90[0][0]']         \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, None, None,   1024       ['conv2d_94[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_91 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_91[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " add_30 (Add)                   (None, None, None,   0           ['add_29[0][0]',                 \n",
      "                                256)                              'leaky_re_lu_91[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)             (None, None, None,   32768       ['add_30[0][0]']                 \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, None, None,   512        ['conv2d_95[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_92 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_92[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_96 (Conv2D)             (None, None, None,   294912      ['leaky_re_lu_92[0][0]']         \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, None, None,   1024       ['conv2d_96[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_93 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_93[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " add_31 (Add)                   (None, None, None,   0           ['add_30[0][0]',                 \n",
      "                                256)                              'leaky_re_lu_93[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)             (None, None, None,   32768       ['add_31[0][0]']                 \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_94 (BatchN  (None, None, None,   512        ['conv2d_97[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_94 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_94[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)             (None, None, None,   294912      ['leaky_re_lu_94[0][0]']         \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_95 (BatchN  (None, None, None,   1024       ['conv2d_98[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_95 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_95[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " add_32 (Add)                   (None, None, None,   0           ['add_31[0][0]',                 \n",
      "                                256)                              'leaky_re_lu_95[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_99 (Conv2D)             (None, None, None,   32768       ['add_32[0][0]']                 \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_96 (BatchN  (None, None, None,   512        ['conv2d_99[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_96 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_96[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_100 (Conv2D)            (None, None, None,   294912      ['leaky_re_lu_96[0][0]']         \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_97 (BatchN  (None, None, None,   1024       ['conv2d_100[0][0]']             \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_97 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_97[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " add_33 (Add)                   (None, None, None,   0           ['add_32[0][0]',                 \n",
      "                                256)                              'leaky_re_lu_97[0][0]']         \n",
      "                                                                                                  \n",
      " zero_padding2d_8 (ZeroPadding2  (None, None, None,   0          ['add_33[0][0]']                 \n",
      " D)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_101 (Conv2D)            (None, None, None,   1179648     ['zero_padding2d_8[0][0]']       \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_98 (BatchN  (None, None, None,   2048       ['conv2d_101[0][0]']             \n",
      " ormalization)                  512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_98 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_98[0][0]'] \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_102 (Conv2D)            (None, None, None,   131072      ['leaky_re_lu_98[0][0]']         \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_99 (BatchN  (None, None, None,   1024       ['conv2d_102[0][0]']             \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_99 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_99[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_103 (Conv2D)            (None, None, None,   1179648     ['leaky_re_lu_99[0][0]']         \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_100 (Batch  (None, None, None,   2048       ['conv2d_103[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_100 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_100[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " add_34 (Add)                   (None, None, None,   0           ['leaky_re_lu_98[0][0]',         \n",
      "                                512)                              'leaky_re_lu_100[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_104 (Conv2D)            (None, None, None,   131072      ['add_34[0][0]']                 \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_101 (Batch  (None, None, None,   1024       ['conv2d_104[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_101 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_101[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_105 (Conv2D)            (None, None, None,   1179648     ['leaky_re_lu_101[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_102 (Batch  (None, None, None,   2048       ['conv2d_105[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_102 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_102[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " add_35 (Add)                   (None, None, None,   0           ['add_34[0][0]',                 \n",
      "                                512)                              'leaky_re_lu_102[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_106 (Conv2D)            (None, None, None,   131072      ['add_35[0][0]']                 \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_103 (Batch  (None, None, None,   1024       ['conv2d_106[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_103 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_103[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_107 (Conv2D)            (None, None, None,   1179648     ['leaky_re_lu_103[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_104 (Batch  (None, None, None,   2048       ['conv2d_107[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_104 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_104[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " add_36 (Add)                   (None, None, None,   0           ['add_35[0][0]',                 \n",
      "                                512)                              'leaky_re_lu_104[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_108 (Conv2D)            (None, None, None,   131072      ['add_36[0][0]']                 \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_105 (Batch  (None, None, None,   1024       ['conv2d_108[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_105 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_105[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_109 (Conv2D)            (None, None, None,   1179648     ['leaky_re_lu_105[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_106 (Batch  (None, None, None,   2048       ['conv2d_109[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_106 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_106[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " add_37 (Add)                   (None, None, None,   0           ['add_36[0][0]',                 \n",
      "                                512)                              'leaky_re_lu_106[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_110 (Conv2D)            (None, None, None,   131072      ['add_37[0][0]']                 \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_107 (Batch  (None, None, None,   1024       ['conv2d_110[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_107 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_107[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_111 (Conv2D)            (None, None, None,   1179648     ['leaky_re_lu_107[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_108 (Batch  (None, None, None,   2048       ['conv2d_111[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_108 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_108[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " add_38 (Add)                   (None, None, None,   0           ['add_37[0][0]',                 \n",
      "                                512)                              'leaky_re_lu_108[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_112 (Conv2D)            (None, None, None,   131072      ['add_38[0][0]']                 \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_109 (Batch  (None, None, None,   1024       ['conv2d_112[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_109 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_109[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_113 (Conv2D)            (None, None, None,   1179648     ['leaky_re_lu_109[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_110 (Batch  (None, None, None,   2048       ['conv2d_113[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_110 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_110[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " add_39 (Add)                   (None, None, None,   0           ['add_38[0][0]',                 \n",
      "                                512)                              'leaky_re_lu_110[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_114 (Conv2D)            (None, None, None,   131072      ['add_39[0][0]']                 \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_111 (Batch  (None, None, None,   1024       ['conv2d_114[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_111 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_111[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_115 (Conv2D)            (None, None, None,   1179648     ['leaky_re_lu_111[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_112 (Batch  (None, None, None,   2048       ['conv2d_115[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_112 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_112[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " add_40 (Add)                   (None, None, None,   0           ['add_39[0][0]',                 \n",
      "                                512)                              'leaky_re_lu_112[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_116 (Conv2D)            (None, None, None,   131072      ['add_40[0][0]']                 \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_113 (Batch  (None, None, None,   1024       ['conv2d_116[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_113 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_113[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_117 (Conv2D)            (None, None, None,   1179648     ['leaky_re_lu_113[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_114 (Batch  (None, None, None,   2048       ['conv2d_117[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_114 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_114[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " add_41 (Add)                   (None, None, None,   0           ['add_40[0][0]',                 \n",
      "                                512)                              'leaky_re_lu_114[0][0]']        \n",
      "                                                                                                  \n",
      " zero_padding2d_9 (ZeroPadding2  (None, None, None,   0          ['add_41[0][0]']                 \n",
      " D)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_118 (Conv2D)            (None, None, None,   4718592     ['zero_padding2d_9[0][0]']       \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_115 (Batch  (None, None, None,   4096       ['conv2d_118[0][0]']             \n",
      " Normalization)                 1024)                                                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_115 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_115[0][0]']\n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv2d_119 (Conv2D)            (None, None, None,   524288      ['leaky_re_lu_115[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_116 (Batch  (None, None, None,   2048       ['conv2d_119[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_116 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_116[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_120 (Conv2D)            (None, None, None,   4718592     ['leaky_re_lu_116[0][0]']        \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_117 (Batch  (None, None, None,   4096       ['conv2d_120[0][0]']             \n",
      " Normalization)                 1024)                                                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_117 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_117[0][0]']\n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " add_42 (Add)                   (None, None, None,   0           ['leaky_re_lu_115[0][0]',        \n",
      "                                1024)                             'leaky_re_lu_117[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_121 (Conv2D)            (None, None, None,   524288      ['add_42[0][0]']                 \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_118 (Batch  (None, None, None,   2048       ['conv2d_121[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_118 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_118[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_122 (Conv2D)            (None, None, None,   4718592     ['leaky_re_lu_118[0][0]']        \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_119 (Batch  (None, None, None,   4096       ['conv2d_122[0][0]']             \n",
      " Normalization)                 1024)                                                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_119 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_119[0][0]']\n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " add_43 (Add)                   (None, None, None,   0           ['add_42[0][0]',                 \n",
      "                                1024)                             'leaky_re_lu_119[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_123 (Conv2D)            (None, None, None,   524288      ['add_43[0][0]']                 \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_120 (Batch  (None, None, None,   2048       ['conv2d_123[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_120 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_120[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_124 (Conv2D)            (None, None, None,   4718592     ['leaky_re_lu_120[0][0]']        \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_121 (Batch  (None, None, None,   4096       ['conv2d_124[0][0]']             \n",
      " Normalization)                 1024)                                                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_121 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_121[0][0]']\n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " add_44 (Add)                   (None, None, None,   0           ['add_43[0][0]',                 \n",
      "                                1024)                             'leaky_re_lu_121[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_125 (Conv2D)            (None, None, None,   524288      ['add_44[0][0]']                 \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_122 (Batch  (None, None, None,   2048       ['conv2d_125[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_122 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_122[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_126 (Conv2D)            (None, None, None,   4718592     ['leaky_re_lu_122[0][0]']        \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_123 (Batch  (None, None, None,   4096       ['conv2d_126[0][0]']             \n",
      " Normalization)                 1024)                                                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_123 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_123[0][0]']\n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " add_45 (Add)                   (None, None, None,   0           ['add_44[0][0]',                 \n",
      "                                1024)                             'leaky_re_lu_123[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)            (None, None, None,   524288      ['add_45[0][0]']                 \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_124 (Batch  (None, None, None,   2048       ['conv2d_127[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_124 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_124[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)            (None, None, None,   4718592     ['leaky_re_lu_124[0][0]']        \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_125 (Batch  (None, None, None,   4096       ['conv2d_128[0][0]']             \n",
      " Normalization)                 1024)                                                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_125 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_125[0][0]']\n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv2d_129 (Conv2D)            (None, None, None,   524288      ['leaky_re_lu_125[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_126 (Batch  (None, None, None,   2048       ['conv2d_129[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_126 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_126[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_130 (Conv2D)            (None, None, None,   4718592     ['leaky_re_lu_126[0][0]']        \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_127 (Batch  (None, None, None,   4096       ['conv2d_130[0][0]']             \n",
      " Normalization)                 1024)                                                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_127 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_127[0][0]']\n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv2d_131 (Conv2D)            (None, None, None,   524288      ['leaky_re_lu_127[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_128 (Batch  (None, None, None,   2048       ['conv2d_131[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_128 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_128[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_134 (Conv2D)            (None, None, None,   131072      ['leaky_re_lu_128[0][0]']        \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_130 (Batch  (None, None, None,   1024       ['conv2d_134[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_130 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_130[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, None, None,   0          ['leaky_re_lu_130[0][0]']        \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, None, None,   0           ['up_sampling2d_2[0][0]',        \n",
      "                                768)                              'add_41[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_135 (Conv2D)            (None, None, None,   196608      ['concatenate_2[0][0]']          \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_131 (Batch  (None, None, None,   1024       ['conv2d_135[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_131 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_131[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_136 (Conv2D)            (None, None, None,   1179648     ['leaky_re_lu_131[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_132 (Batch  (None, None, None,   2048       ['conv2d_136[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_132 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_132[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_137 (Conv2D)            (None, None, None,   131072      ['leaky_re_lu_132[0][0]']        \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_133 (Batch  (None, None, None,   1024       ['conv2d_137[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_133 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_133[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_138 (Conv2D)            (None, None, None,   1179648     ['leaky_re_lu_133[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_134 (Batch  (None, None, None,   2048       ['conv2d_138[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_134 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_134[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_139 (Conv2D)            (None, None, None,   131072      ['leaky_re_lu_134[0][0]']        \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_135 (Batch  (None, None, None,   1024       ['conv2d_139[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_135 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_135[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_142 (Conv2D)            (None, None, None,   32768       ['leaky_re_lu_135[0][0]']        \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_137 (Batch  (None, None, None,   512        ['conv2d_142[0][0]']             \n",
      " Normalization)                 128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_137 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_137[0][0]']\n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, None, None,   0          ['leaky_re_lu_137[0][0]']        \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, None, None,   0           ['up_sampling2d_3[0][0]',        \n",
      "                                384)                              'add_33[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_143 (Conv2D)            (None, None, None,   49152       ['concatenate_3[0][0]']          \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_138 (Batch  (None, None, None,   512        ['conv2d_143[0][0]']             \n",
      " Normalization)                 128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_138 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_138[0][0]']\n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_144 (Conv2D)            (None, None, None,   294912      ['leaky_re_lu_138[0][0]']        \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_139 (Batch  (None, None, None,   1024       ['conv2d_144[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_139 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_139[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_145 (Conv2D)            (None, None, None,   32768       ['leaky_re_lu_139[0][0]']        \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_140 (Batch  (None, None, None,   512        ['conv2d_145[0][0]']             \n",
      " Normalization)                 128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_140 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_140[0][0]']\n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_146 (Conv2D)            (None, None, None,   294912      ['leaky_re_lu_140[0][0]']        \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_141 (Batch  (None, None, None,   1024       ['conv2d_146[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_141 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_141[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_147 (Conv2D)            (None, None, None,   32768       ['leaky_re_lu_141[0][0]']        \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_142 (Batch  (None, None, None,   512        ['conv2d_147[0][0]']             \n",
      " Normalization)                 128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_142 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_142[0][0]']\n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_132 (Conv2D)            (None, None, None,   4718592     ['leaky_re_lu_128[0][0]']        \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv2d_140 (Conv2D)            (None, None, None,   1179648     ['leaky_re_lu_135[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_148 (Conv2D)            (None, None, None,   294912      ['leaky_re_lu_142[0][0]']        \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_129 (Batch  (None, None, None,   4096       ['conv2d_132[0][0]']             \n",
      " Normalization)                 1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_136 (Batch  (None, None, None,   2048       ['conv2d_140[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_143 (Batch  (None, None, None,   1024       ['conv2d_148[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_129 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_129[0][0]']\n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_136 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_136[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_143 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_143[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_133 (Conv2D)            (None, None, None,   273675      ['leaky_re_lu_129[0][0]']        \n",
      "                                267)                                                              \n",
      "                                                                                                  \n",
      " conv2d_141 (Conv2D)            (None, None, None,   136971      ['leaky_re_lu_136[0][0]']        \n",
      "                                267)                                                              \n",
      "                                                                                                  \n",
      " conv2d_149 (Conv2D)            (None, None, None,   68619       ['leaky_re_lu_143[0][0]']        \n",
      "                                267)                                                              \n",
      "                                                                                                  \n",
      " fm_13_input (InputLayer)       [(None, None, None,  0           []                               \n",
      "                                 3, 85)]                                                          \n",
      "                                                                                                  \n",
      " fm_26_input (InputLayer)       [(None, None, None,  0           []                               \n",
      "                                 3, 85)]                                                          \n",
      "                                                                                                  \n",
      " fm_52_input (InputLayer)       [(None, None, None,  0           []                               \n",
      "                                 3, 85)]                                                          \n",
      "                                                                                                  \n",
      " yolo_loss (Lambda)             ()                   0           ['conv2d_133[0][0]',             \n",
      "                                                                  'conv2d_141[0][0]',             \n",
      "                                                                  'conv2d_149[0][0]',             \n",
      "                                                                  'fm_13_input[0][0]',            \n",
      "                                                                  'fm_26_input[0][0]',            \n",
      "                                                                  'fm_52_input[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 62,023,297\n",
      "Trainable params: 61,970,689\n",
      "Non-trainable params: 52,608\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the callbacks\n",
    "logging = TensorBoard(log_dir='/notebooks/logs')\n",
    "checkpoint = ModelCheckpoint('/notebooks/models/yologv3', monitor='val_loss', verbose=1, save_best_only=True, mode='min', save_freq='epoch')\n",
    "reduce_on_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, mode='min', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=6, verbose=1, mode='min')\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    checkpoint,\n",
    "    reduce_on_plateau,\n",
    "    # early_stopping\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEPS_PER_EPOCH = len(train_generator)\n",
    "# STEPS_PER_EPOCH = 500   \n",
    "EPOCHS = 100\n",
    "WORKERS = 1\n",
    "MULTI_PROCESSING = False\n",
    "MAX_QUEUE_SIZE = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(image, boxes, classes=classes):\n",
    "    '''Draws bounding boxes on the image'''\n",
    "    labels = boxes['labels']\n",
    "    boxes = boxes['bboxes']\n",
    "    for i in range(len(boxes)):\n",
    "        box = boxes[i]\n",
    "        label = labels[i]\n",
    "        cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), (255, 0, 0), 2)\n",
    "        cv2.putText(image, classes[label], (box[0], box[1]), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display first image in training set with bounding boxes\n",
    "image = train_generator.load_image(0)\n",
    "boxes = train_generator.load_annotations(0)\n",
    "# print(boxes)\n",
    "# draw_boxes(image, boxes, classes=classes)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_1211/3826567391.py:9: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_session():\n",
    "    \"\"\"\n",
    "    Construct a modified tf session.\n",
    "    \"\"\"\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.compat.v1.Session(config=config)\n",
    "\n",
    "tf.compat.v1.keras.backend.set_session(get_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 21:14:52.870516: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] layout failed: INVALID_ARGUMENT: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13/128 [==>...........................] - ETA: 57s - loss: 10322.8789"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 66505 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 66505 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 48/128 [==========>...................] - ETA: 40s - loss: 3983.5654"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 98885 (shape (500, 375, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 98885 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 51/128 [==========>...................] - ETA: 38s - loss: 3795.6868"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 68212 (shape (487, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 68212 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 62/128 [=============>................] - ETA: 33s - loss: 3231.1401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 63393 (shape (640, 480, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 63435 (shape (640, 480, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 63393 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 63435 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70/128 [===============>..............] - ETA: 29s - loss: 2917.7014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 17318 (shape (478, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 17318 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 71/128 [===============>..............] - ETA: 28s - loss: 2883.0679"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 106470 (shape (640, 458, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 106470 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 77/128 [=================>............] - ETA: 25s - loss: 2695.2402"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 14540 (shape (427, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 14540 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 98/128 [=====================>........] - ETA: 14s - loss: 2201.2559"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 27113 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 27123 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 27113 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 27123 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - ETA: 0s - loss: 1752.8420"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 21:16:03.720851: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] layout failed: INVALID_ARGUMENT: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
      "2022-12-11 21:16:03.739025: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] remapper failed: INVALID_ARGUMENT: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
      "2022-12-11 21:16:03.938759: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] remapper failed: INVALID_ARGUMENT: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 2078 (shape (640, 418, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 2078 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 2191 (shape (640, 426, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 2191 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 2326 (shape (640, 427, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 2326 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 3616 (shape (640, 429, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 3616 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 4089 (shape (500, 336, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 4089 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 2532 (shape (640, 479, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 2532 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 25 (shape (640, 480, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 25 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 2285 (shape (640, 480, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 2285 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 2525 (shape (640, 480, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 2525 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 2833 (shape (640, 480, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 2833 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 3361 (shape (500, 375, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 3361 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 3740 (shape (640, 480, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 3740 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 3858 (shape (500, 375, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 3858 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 4576 (shape (640, 480, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 4576 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 4098 (shape (640, 523, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 4098 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 29 (shape (640, 634, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 29 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 3958 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 160 (shape (375, 500, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 160 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 403 (shape (375, 500, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 403 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 438 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 438 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 1041 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 1041 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 1171 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 1556 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 1562 (shape (375, 500, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 1556 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 1562 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 1563 (shape (375, 500, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 1563 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 1675 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 1675 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 1906 (shape (375, 500, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 1906 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 2837 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 2837 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 2973 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 2973 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 3746 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 4099 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 4099 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 4460 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 4460 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 3488 (shape (374, 500, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 3488 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 2839 (shape (338, 500, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 2839 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 278 (shape (335, 500, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 278 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 1300 (shape (428, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 1300 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 4459 (shape (428, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 4459 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 1558 (shape (427, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 1558 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 1680 (shape (427, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 1680 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 3748 (shape (427, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 3748 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 4091 (shape (427, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 4091 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 4824 (shape (427, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 4824 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 3246 (shape (333, 500, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 3246 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 2319 (shape (426, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 2319 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 3619 (shape (426, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 3619 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 3212 (shape (175, 263, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 3212 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 4340 (shape (332, 500, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 4340 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 757 (shape (424, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 757 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 2574 (shape (404, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 2574 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 3615 (shape (369, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 3615 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 4201 (shape (269, 500, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 4201 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 250s 2s/step - loss: 1752.8420 - val_loss: 723.6340\n",
      "Epoch 2/100\n",
      "  1/128 [..............................] - ETA: 1:50 - loss: 255.1209"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 21085 (shape (249, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 21085 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8/128 [>.............................] - ETA: 59s - loss: 247.5466"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 65436 (shape (500, 333, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 65436 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 55/128 [===========>..................] - ETA: 36s - loss: 215.0024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 34745 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 34745 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 62/128 [=============>................] - ETA: 33s - loss: 211.9902"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 1768 (shape (640, 426, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 1768 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70/128 [===============>..............] - ETA: 29s - loss: 206.2656"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 56720 (shape (437, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 56720 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/128 [=======================>......] - ETA: 11s - loss: 188.4767"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 31532 (shape (640, 480, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 31532 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/128 [========================>.....] - ETA: 9s - loss: 185.6739 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 43989 (shape (426, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 44031 (shape (426, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 43989 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 44031 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/128 [===========================>..] - ETA: 2s - loss: 182.0356"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 9226 (shape (612, 612, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 9226 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 169s 1s/step - loss: 179.9548 - val_loss: 185.8162\n",
      "Epoch 3/100\n",
      "  7/128 [>.............................] - ETA: 1:08 - loss: 119.3743"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 101530 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 101530 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 55/128 [===========>..................] - ETA: 36s - loss: 141.1286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 7435 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 7435 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 56/128 [============>.................] - ETA: 36s - loss: 141.5387"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 11840 (shape (555, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 11840 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 57/128 [============>.................] - ETA: 35s - loss: 141.0483"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 28981 (shape (240, 320, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 28982 (shape (240, 320, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 28981 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 28982 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84/128 [==================>...........] - ETA: 22s - loss: 138.9451"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 67519 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 67519 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/128 [======================>.......] - ETA: 14s - loss: 137.6774"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 13763 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 13763 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/128 [===========================>..] - ETA: 3s - loss: 136.2216"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 29876 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 29876 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 169s 1s/step - loss: 134.3685 - val_loss: 134.0791\n",
      "Epoch 4/100\n",
      " 37/128 [=======>......................] - ETA: 45s - loss: 124.3888"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 7580 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 7580 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 71/128 [===============>..............] - ETA: 28s - loss: 119.6864"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 68542 (shape (427, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 68542 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/128 [========================>.....] - ETA: 9s - loss: 117.7454 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 62408 (shape (640, 428, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 62408 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/128 [=========================>....] - ETA: 6s - loss: 117.5277"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 66501 (shape (427, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 66501 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 167s 1s/step - loss: 116.5755 - val_loss: 114.8849\n",
      "Epoch 5/100\n",
      " 37/128 [=======>......................] - ETA: 49s - loss: 111.7307"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 32589 (shape (241, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 32589 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 39/128 [========>.....................] - ETA: 47s - loss: 112.2054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 41898 (shape (427, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 41898 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66/128 [==============>...............] - ETA: 32s - loss: 113.8644"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 1151 (shape (427, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 1151 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/128 [======================>.......] - ETA: 14s - loss: 112.9300"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 80887 (shape (640, 480, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 80891 (shape (640, 480, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 80887 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 80891 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/128 [=======================>......] - ETA: 12s - loss: 112.2716"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 37651 (shape (427, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 37651 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/128 [========================>.....] - ETA: 9s - loss: 111.6470 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 101881 (shape (333, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 101881 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 169s 1s/step - loss: 109.9648 - val_loss: 114.9607\n",
      "Epoch 6/100\n",
      " 19/128 [===>..........................] - ETA: 54s - loss: 116.8218"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 114674 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 114674 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 29/128 [=====>........................] - ETA: 49s - loss: 115.4809"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 10174 (shape (425, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 10174 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 46/128 [=========>....................] - ETA: 40s - loss: 113.0670"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 62108 (shape (640, 427, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 62108 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 47/128 [==========>...................] - ETA: 40s - loss: 112.5971"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 105434 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 105436 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 105434 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 105436 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 57/128 [============>.................] - ETA: 35s - loss: 110.7329"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 99249 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 99259 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 99249 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 99259 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 72/128 [===============>..............] - ETA: 27s - loss: 110.5507"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 87014 (shape (640, 480, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 87014 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 74/128 [================>.............] - ETA: 26s - loss: 109.3442"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 98214 (shape (640, 427, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 98214 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 77/128 [=================>............] - ETA: 25s - loss: 109.8982"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 93443 (shape (640, 480, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 93443 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/128 [========================>.....] - ETA: 9s - loss: 106.7174"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 49130 (shape (426, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 49130 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/128 [=========================>....] - ETA: 7s - loss: 107.2527"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 81905 (shape (224, 372, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 81905 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 171s 1s/step - loss: 107.1498 - val_loss: 106.1173\n",
      "Epoch 7/100\n",
      "  4/128 [..............................] - ETA: 1:01 - loss: 129.2575"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 84923 (shape (602, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 84923 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7/128 [>.............................] - ETA: 59s - loss: 113.2309 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 48399 (shape (640, 480, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 48399 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30/128 [======>.......................] - ETA: 47s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 30746 (shape (343, 500, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 30746 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35/128 [=======>......................] - ETA: 44s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:230: UserWarning: Image with id 113404 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 45/128 [=========>....................] - ETA: 39s - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\the_3\\OneDrive\\Desktop\\school\\fall 2022\\neural networks class\\projects\\real-time-object-detector\\src\\yolog.ipynb Cell 44\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X60sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# start training\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X60sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m H \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X60sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_generator, y \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X60sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m steps_per_epoch\u001b[39m=\u001b[39;49mSTEPS_PER_EPOCH,\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X60sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m epochs\u001b[39m=\u001b[39;49mEPOCHS,\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X60sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X60sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X60sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# callbacks=callbacks,\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X60sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# workers=WORKERS,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X60sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# use_multiprocessing=MULTI_PROCESSING,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X60sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# max_queue_size=MAX_QUEUE_SIZE,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X60sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m validation_data\u001b[39m=\u001b[39;49mval_generator,\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X60sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m validation_steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(val_generator),\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X60sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X60sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X60sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    # start training\n",
    "H = model.fit(\n",
    "    train_generator, y = None,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "\n",
    "    # callbacks=callbacks,\n",
    "    # workers=WORKERS,\n",
    "    # use_multiprocessing=MULTI_PROCESSING,\n",
    "    # max_queue_size=MAX_QUEUE_SIZE,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator),\n",
    "    shuffle=True,\n",
    "    initial_epoch=0\n",
    ")\n",
    "\n",
    "# H = model.fit(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=STEPS_PER_EPOCH,\n",
    "#     initial_epoch=0,\n",
    "#     epochs=EPOCHS,\n",
    "#     verbose=1,\n",
    "#     callbacks=callbacks,\n",
    "#     workers=WORKERS,\n",
    "#     use_multiprocessing=MULTI_PROCESSING,\n",
    "#     max_queue_size=MAX_QUEUE_SIZE,\n",
    "#     validation_data=val_generator\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training history\n",
    "def plot_results(history, epochs=EPOCHS):\n",
    "    '''\n",
    "        This function plots the training history\n",
    "        input:\n",
    "            - history: the training history\n",
    "        output:\n",
    "            - None\n",
    "    '''\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, epochs), history['loss'], label = 'train_loss')\n",
    "    plt.plot(np.arange(0, epochs), history['val_loss'], label = 'val_loss')\n",
    "    plt.plot(np.arange(0, epochs), history['accuracy'], label = 'train_acc')\n",
    "    plt.plot(np.arange(0, epochs), history['val_accuracy'], label = 'val_acc')\n",
    "        \n",
    "    # add labels and legend\n",
    "    plt.title('Training Loss and Accuracy')\n",
    "    plt.xlabel('Epoch #')\n",
    "    plt.ylabel('Loss/Accuracy')\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training history\n",
    "plot_results(H.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import glob\n",
    "from utils import get_anchors, get_classes, preprocess_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, name, contours=None):\n",
    "    image = image.astype(np.uint8)\n",
    "    cv2.namedWindow(name, cv2.WINDOW_NORMAL)\n",
    "    if contours is not None:\n",
    "        if isinstance(contours, list):\n",
    "            cv2.drawContours(image, contours, -1, (0, 0, 255), 2)\n",
    "        else:\n",
    "            cv2.drawContours(image, [contours], -1, (0, 0, 255), 2)\n",
    "    cv2.imshow(name, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 40670\n"
     ]
    }
   ],
   "source": [
    "# inference\n",
    "BATCH_SIZE = 1\n",
    "image_paths = glob.glob('/notebooks/data/test2017/*.jpg')\n",
    "num_images = len(image_paths)\n",
    "print('Number of images: {}'.format(num_images))\n",
    "colors = [np.random.randint(0, 256, 3).tolist() for i in range(num_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot assign value to variable ' conv2d_133/kernel:0': Shape mismatch.The variable shape (1, 1, 1024, 267), and the assigned value shape (255, 1024, 1, 1) are incompatible.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\the_3\\OneDrive\\Desktop\\school\\fall 2022\\neural networks class\\projects\\real-time-object-detector\\src\\yolog.ipynb Cell 50\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#Y103sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# load best weights\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#Y103sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mload_weights(\u001b[39m'\u001b[39;49m\u001b[39m/notebooks/models/yologv3.h5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/backend.py:4028\u001b[0m, in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   4026\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[1;32m   4027\u001b[0m   \u001b[39mfor\u001b[39;00m x, value \u001b[39min\u001b[39;00m tuples:\n\u001b[0;32m-> 4028\u001b[0m     x\u001b[39m.\u001b[39;49massign(np\u001b[39m.\u001b[39;49masarray(value, dtype\u001b[39m=\u001b[39;49mdtype_numpy(x)))\n\u001b[1;32m   4029\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4030\u001b[0m   \u001b[39mwith\u001b[39;00m get_graph()\u001b[39m.\u001b[39mas_default():\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot assign value to variable ' conv2d_133/kernel:0': Shape mismatch.The variable shape (1, 1, 1024, 267), and the assigned value shape (255, 1024, 1, 1) are incompatible."
     ]
    }
   ],
   "source": [
    "# load best weights\n",
    "model.load_weights('/notebooks/models/yologv3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, num_images, BATCH_SIZE):\n",
    "    if i + BATCH_SIZE > num_images:\n",
    "        batch_image_paths = image_paths[i:]\n",
    "    else:\n",
    "        batch_image_paths = image_paths[i:i + BATCH_SIZE]\n",
    "    batch_images_data = []\n",
    "    batch_image_shapes = []\n",
    "    for image_path in batch_image_paths:\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image_shape = image.shape[:2]\n",
    "        image_shape = np.array(image_shape)\n",
    "        image_data = preprocess_image(image)\n",
    "        batch_images_data.append(image_data)\n",
    "        batch_image_shapes.append(image_shape)\n",
    "\n",
    "    batch_images_data = np.array(batch_images_data)\n",
    "    batch_image_shapes = np.array(batch_image_shapes)\n",
    "    batch_detections = prediction_model.predict([batch_images_data, batch_image_shapes])\n",
    "    for i, detections in enumerate(batch_detections):\n",
    "        image_path = batch_image_paths[i]\n",
    "        image = cv2.imread(image_path)\n",
    "        h, w = image.shape[:2]\n",
    "        detections = detections[detections[:, 4] > 0.0]\n",
    "        for detection in detections:\n",
    "            ymin = max(int(round(detection[0])), 0)\n",
    "            xmin = max(int(round(detection[1])), 0)\n",
    "            ymax = min(int(round(detection[2])), h - 1)\n",
    "            xmax = min(int(round(detection[3])), w - 1)\n",
    "            score = '{:.4f}'.format(detection[4])\n",
    "            class_id = int(detection[5])\n",
    "            color = colors[class_id - 1]\n",
    "            class_name = classes[class_id]\n",
    "            label = '-'.join([class_name, score])\n",
    "            ret, baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.3, 1)\n",
    "            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color, 1)\n",
    "            cv2.rectangle(image, (xmin, ymax - ret[1] - baseline), (xmin + ret[0], ymax), color, -1)\n",
    "            cv2.putText(image, label, (xmin, ymax - baseline), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "        cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow('image', image)\n",
    "        key = cv2.waitKey(0)\n",
    "        if int(key) == 121:\n",
    "            image_fname = osp.split(image_path)[-1]\n",
    "            cv2.imwrite('test/{}'.format(image_fname), image)\n",
    "\n",
    "    # spot at 10 images\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Demo of Gaussian Yolov3 (YoloG) in Real Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
