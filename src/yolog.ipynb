{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSE 5320 Neural Networks Project 2\n",
    "#### Report (with Code)\n",
    "Josias Moukpe\\\n",
    "11/29/2022\n",
    "\n",
    "#### Introduction\n",
    "Object detection is an advanced form of image classification where a neural network predicts objects in an image and points them out in bounding boxes. Object detection thus refers to the detection and localization of objects in an image that belongs to a predefined set of classes. Tasks like detection, recognition, or localization find widespread applicability in real-world scenarios such as autonomous driving, robotics, product quality assurance, etc., making object detection (also referred to as object recognition) a very important subdomain of Computer Vision. [2] We call Real-Time object detection when the objects in images can be recognized in mere milliseconds allowing for in-time reactions based on the detection. Our project will aim to build a real-time object detector to find and track objects of defined classes in images or video feeds.\n",
    "\n",
    "#### Problem\n",
    "This objective combines object classificationn and localization (bounding box regression task). To process images and capture the features, we will leverage convolutional neural networks and capture local pixel structures. We will comment on how our model performs in real-time object detection. To train our model, we will use the MS COCO dataset [1]. This dataset contains more than 200,000 labeled color images of 1.5 million object instances and 80 object categories. Each image is 640 x 480 pixels and includes various forms of annotations such as key points, captions, segmentations, and bounding boxes (which interest us). The model will take an image or batch of images and outputs the classes and bounding boxes of all objects detected in that image.\n",
    "\n",
    "#### Methodology\n",
    "To prepare the data, we downloaded the COCO 2017 from the official website, unzip the files training and validation files in a data folder. We then downloaded the annotations json  files which contain the bounding box coordinates for the objects in the image. We utilized the pycocotools library to help us load the images and the bounding box annotations in memory.Those images are then fed into the network with the bounding boxes as labels. To improve accuracy, we augment some images with random transforms such as rotation and translations. The bounding box labels are also transformed accordingly. The training is done through a generator. The dataset is split into Training, validation and testing. The hyperparameters used are the following: learning rate of 1e-3 with reduction of .1 factor when the validation loss plateauxes. A total number of epochs at 25 epochs. The architecture use was that of the Paper Gaussian Yolo V3 [3]. We trained with 32 steps per epoch to prevent the gradients from exploding within a single epoch. To handle the computational needs of the algorithm, we used a remote computer cluster from which we accessed all our resources. The link to access the remote instance is the following https://console.paperspace.com/erud1t3/notebook/r92lxtvwhlbkhcy. We use a batch size of 8 as it was the maximum batch size we could process in memory. We had many re-run with various learning rates, number of epochs, and steps per epochs. often with smaller learning rates, or higher steps per epochs, the gradients will explode leading to Nan loss values. To mitigate that we settle for a conservative 32 steps per epochs for a total of 25 epochs.\n",
    "\n",
    "#### Benchmarking\n",
    "To measure training performance, we use validation loss and we observe the results of the detector on loaded images from our remote folder. \n",
    "We can see our detector performed well on the test images and achieve an overall loss of 112 and an accuracy of  \n",
    "\n",
    "#### Conclusion\n",
    "This project was very instructive as it allows us to explore ways to scale our experiments to larger models and larger datasets. However it came at a price as it was extremely challenging to implement and run. We would like to acknowledge Xuannianz from prior work he did and from which we were able to build on top off. In conclusion, real-time object detection is a critical components of many applications today and with the added functionality of Gaussian estimate of uncertainty, the system shows better performance.\n",
    "\n",
    "\n",
    "References\\\n",
    "[1] https://cocodataset.org/#home \\\n",
    "[2] https://arxiv.org/abs/1804.02767 \\\n",
    "[3] https://arxiv.org/abs/1506.02640 \\\n",
    "[4] https://arxiv.org/abs/2207.02696 \\\n",
    "[5] https://arxiv.org/abs/1904.04620 \\\n",
    "[6] https://www.v7labs.com/blog/yolo-object-detection \\\n",
    "[7] https://github.com/xuannianz/keras-GaussianYOLOv3 \\\n",
    "[8] https://www.kaggle.com/code/aruchomu/yolo-v3-object-detection-in-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining the COCO 2017 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md  checkpoint  data  generators  models      utils\n",
      "augmentor  config      eval  logs\t test.ipynb\n",
      "annotations  coco.names  test  test2017  train2017  val2017  yolo_anchors.txt\n"
     ]
    }
   ],
   "source": [
    "# list the contents of the current \n",
    "# directory on my remote server\n",
    "!ls\n",
    "!ls \"/notebooks/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to the data directory\n",
    "# and list the contents\n",
    "# %cd \"/notebooks/data\"\n",
    "# !ls\n",
    "\n",
    "# # downloading coco (2017) dataset\n",
    "# !wget http://images.cocodataset.org/zips/train2017.zip\n",
    "# !wget http://images.cocodataset.org/zips/val2017.zip\n",
    "# !wget http://images.cocodataset.org/zips/test2017.zip\n",
    "# !wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "# !wget http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip\n",
    "# !wget http://images.cocodataset.org/annotations/image_info_test2017.zip\n",
    "\n",
    "# # unzip the files\n",
    "# !unzip train2017.zip\n",
    "# !unzip val2017.zip\n",
    "# !unzip test2017.zip\n",
    "# !unzip annotations_trainval2017.zip\n",
    "# !unzip stuff_annotations_trainval2017.zip\n",
    "# !unzip image_info_test2017.zip\n",
    "\n",
    "# # remove the zip files\n",
    "# !rm train2017.zip\n",
    "# !rm val2017.zip\n",
    "# !rm test2017.zip\n",
    "# !rm annotations_trainval2017.zip\n",
    "# !rm stuff_annotations_trainval2017.zip\n",
    "# !rm image_info_test2017.zip\n",
    "\n",
    "# navigate out of the data directory\n",
    "# and list the contents\n",
    "# %cd \"/notebooks\"\n",
    "# !ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a config directory\n",
    "# %cd \"/notebooks\"\n",
    "# %mkdir config\n",
    "# %cd config\n",
    "# !wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
    "# %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a models directory\n",
    "# %cd \"/notebooks\"\n",
    "# %mkdir models\n",
    "# %cd models\n",
    "# !wget -O yolov3.weights https://pjreddie.com/media/files/yolov3.weights\n",
    "# %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # install gluoncv to help with the dataset\n",
    "# %pip install gluoncv\n",
    "# %pip install mxnet\n",
    "# %pip install opencv-python\n",
    "# %pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "# imports \n",
    "import cv2\n",
    "import glob\n",
    "import io\n",
    "import configparser\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from random import randint, choice\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import ZeroPadding2D\n",
    "from tensorflow.keras.layers import Add\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.utils.vis_utils import plot_model as plot\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import TerminateOnNaN\n",
    "import tensorflow.keras.preprocessing.image\n",
    "from functools import reduce\n",
    "from augmentor.color import VisualEffect\n",
    "from augmentor.misc import MiscEffect\n",
    "from generators.coco import CocoGenerator\n",
    "# from tensorflow.python.framework.ops import disable_eager_execution\n",
    "# disable_eager_execution()\n",
    "# import tensorflow._api.v2.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()\n",
    "# read coco dataset\n",
    "# from gluoncv import data, utils\n",
    "# print the version of tensorflow\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# check if gpu is available and what type\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(tf.test.gpu_device_name())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset\n",
    "MS COCO 2017 is our dataset. Link to loaded dataset in our remote development compute node\n",
    "https://console.paperspace.com/erud1t3/notebook/r92lxtvwhlbkhcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the coco dataset\n",
    "# train_ds = data.COCODetection('./data/', splits=['instances_train2017'])\n",
    "# val_ds = data.COCODetection('./data/', splits=['instances_val2017'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # print the length of the dataset\n",
    "# print('Length of training dataset:', len(train_ds))\n",
    "# print('Length of validation dataset:', len(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a random image from coco dataset\n",
    "# def plot_image(image, label):\n",
    "#     '''\n",
    "#     Plots an image and its bounding boxes\n",
    "#     '''\n",
    "#     print('Image size (height, width, RGB):', image.shape)\n",
    "#     # print('Label:', label)\n",
    "#     print('shape of label:', label.shape)\n",
    "#     # plot the image\n",
    "#     bounding_boxes = label[:, :4]\n",
    "#     class_ids = label[:, 4:5]\n",
    "#     print('number of objects in the image:', bounding_boxes.shape[0])\n",
    "#     print('bounding boxes (# boxes, min x, min y, max x, max y): \\n', bounding_boxes)\n",
    "#     print('class ids (# boxes, class id): \\n', class_ids)\n",
    "#     ax = utils.viz.plot_bbox(\n",
    "#         image.asnumpy(), \n",
    "#         bounding_boxes, \n",
    "#         scores=None, \n",
    "#         labels=class_ids, \n",
    "#         class_names=train_ds.classes\n",
    "#     )\n",
    "#     plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a random image from validation dataset\n",
    "# image, label = val_ds[randint(0, len(val_ds))]\n",
    "# plot_image(image, label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working the model\n",
    "We will be building Gaussian YoloV3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the config file containing the model architecture\n",
    "def unique_config_sections(config_file):\n",
    "    '''\n",
    "    Reads the config file and returns a list of layers\n",
    "    '''\n",
    "    # open the config file\n",
    "    section_counters = defaultdict(int)\n",
    "    output_stream = io.StringIO()\n",
    "\n",
    "    with open(config_file) as fin:\n",
    "        for line in fin:\n",
    "            if line.startswith('['):\n",
    "                section = line.strip().strip('[]')\n",
    "                _section = section + '_' + str(section_counters[section])\n",
    "                section_counters[section] += 1\n",
    "                line = line.replace(section, _section)\n",
    "            output_stream.write(line)\n",
    "    output_stream.seek(0)\n",
    "\n",
    "    return output_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_SHAPE = (608, 608, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_config(config_path, output_path, weights_path, weights_only=False):\n",
    "    '''\n",
    "    Parses the config file and returns a model\n",
    "    '''\n",
    "\n",
    "    # Load weights and config.\n",
    "    print('Loading weights.')\n",
    "    weights_file = open(weights_path, 'rb')\n",
    "    major, minor, revision = np.ndarray(shape=(3,), dtype='int32', buffer=weights_file.read(12))\n",
    "    if (major * 10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
    "        seen = np.ndarray(shape=(1,), dtype='int64', buffer=weights_file.read(8))\n",
    "    else:\n",
    "        seen = np.ndarray(shape=(1,), dtype='int32', buffer=weights_file.read(4))\n",
    "    print('Weights Header: ', major, minor, revision, seen)\n",
    "\n",
    "    print('Parsing Darknet config.')\n",
    "    unique_config_file = unique_config_sections(config_path)\n",
    "    cfg_parser = configparser.ConfigParser()\n",
    "    cfg_parser.read_file(unique_config_file)\n",
    "\n",
    "    print('Creating Keras model.')\n",
    "    input_layer = Input(shape=(608, 608, 3))\n",
    "    prev_layer = input_layer\n",
    "    all_layers = []\n",
    "\n",
    "    weight_decay = float(cfg_parser['net_0']['decay']) if 'net_0' in cfg_parser.sections() else 5e-4\n",
    "    four_bytes_consumed_count = 0\n",
    "    out_index = []\n",
    "    for section in cfg_parser.sections():\n",
    "        print('Parsing section {}'.format(section))\n",
    "        if section.startswith('convolutional'):\n",
    "            filters = int(cfg_parser[section]['filters'])\n",
    "            size = int(cfg_parser[section]['size'])\n",
    "            stride = int(cfg_parser[section]['stride'])\n",
    "            pad = int(cfg_parser[section]['pad'])\n",
    "            activation = cfg_parser[section]['activation']\n",
    "            batch_normalize = 'batch_normalize' in cfg_parser[section]\n",
    "\n",
    "            padding = 'same' if pad == 1 and stride == 1 else 'valid'\n",
    "\n",
    "            # Setting weights.\n",
    "            # Darknet serializes convolutional weights as:\n",
    "            # [bias/beta, [gamma, mean, variance], conv_weights]\n",
    "            prev_layer_shape = K.int_shape(prev_layer)\n",
    "            # Note 每一个 filter 的 shape 为 (size, size, pre_layer_shape[-1])\n",
    "            # (outdim, indim, height, width)\n",
    "            weights_shape = (filters, prev_layer_shape[-1], size, size)\n",
    "\n",
    "            weights_size = np.product(weights_shape)\n",
    "            print('conv2d', 'bn' if batch_normalize else '  ', activation, weights_shape)\n",
    "\n",
    "            conv_bias = np.ndarray(\n",
    "                shape=(filters,),\n",
    "                dtype='float32',\n",
    "                buffer=weights_file.read(filters * 4))\n",
    "            four_bytes_consumed_count += filters\n",
    "            if batch_normalize:\n",
    "                bn_weights = np.ndarray(\n",
    "                    shape=(3, filters),\n",
    "                    dtype='float32',\n",
    "                    buffer=weights_file.read(filters * 12))\n",
    "                four_bytes_consumed_count += 3 * filters\n",
    "\n",
    "                bn_weight_list = [\n",
    "                    # scale gamma\n",
    "                    bn_weights[0],\n",
    "                    # shift beta\n",
    "                    conv_bias,\n",
    "                    # running mean\n",
    "                    bn_weights[1],\n",
    "                    # running var\n",
    "                    bn_weights[2]\n",
    "                ]\n",
    "            conv_weights = np.ndarray(\n",
    "                shape=weights_shape,\n",
    "                dtype='float32',\n",
    "                buffer=weights_file.read(weights_size * 4))\n",
    "            four_bytes_consumed_count += weights_size\n",
    "\n",
    "            # DarkNet conv_weights are serialized Caffe-style:\n",
    "            # (out_dim, in_dim, height, width)\n",
    "            # We would like to set these to Tensorflow order:\n",
    "            # (height, width, in_dim, out_dim)\n",
    "            conv_weights = np.transpose(conv_weights, [2, 3, 1, 0])\n",
    "            conv_weights = [conv_weights] if batch_normalize else [conv_weights, conv_bias]\n",
    "\n",
    "            # Handle activation.\n",
    "            if activation not in ('leaky', 'linear'):\n",
    "                raise ValueError('Unknown activation function `{}` in section {}'.format(activation, section))\n",
    "\n",
    "            # Create Conv2D layer\n",
    "            if stride > 1:\n",
    "                # Darknet uses left and top padding instead of 'same' mode when stride > 1\n",
    "                prev_layer = ZeroPadding2D(((1, 0), (1, 0)))(prev_layer)\n",
    "                \n",
    "            conv_layer = Conv2D(\n",
    "                filters, (size, size),\n",
    "                strides=(stride, stride),\n",
    "                kernel_regularizer=l2(weight_decay),\n",
    "                use_bias=not batch_normalize,\n",
    "                weights=conv_weights,\n",
    "                padding=padding)(prev_layer)\n",
    "\n",
    "            if batch_normalize:\n",
    "                conv_layer = (BatchNormalization(weights=bn_weight_list))(conv_layer)\n",
    "            prev_layer = conv_layer\n",
    "\n",
    "            if activation == 'linear':\n",
    "                all_layers.append(prev_layer)\n",
    "            elif activation == 'leaky':\n",
    "                act_layer = LeakyReLU(alpha=0.1)(prev_layer)\n",
    "                prev_layer = act_layer\n",
    "                all_layers.append(act_layer)\n",
    "\n",
    "        elif section.startswith('route'):\n",
    "            # concatenate layers\n",
    "            ids = [int(i) for i in cfg_parser[section]['layers'].split(',')]\n",
    "            layers = [all_layers[i] for i in ids]\n",
    "            if len(layers) > 1:\n",
    "                print('Concatenating route layers:', layers)\n",
    "                concatenate_layer = Concatenate()(layers)\n",
    "                all_layers.append(concatenate_layer)\n",
    "                prev_layer = concatenate_layer\n",
    "            else:\n",
    "                # only one layer to route\n",
    "                skip_layer = layers[0]\n",
    "                all_layers.append(skip_layer)\n",
    "                prev_layer = skip_layer\n",
    "\n",
    "        elif section.startswith('maxpool'):\n",
    "            size = int(cfg_parser[section]['size'])\n",
    "            stride = int(cfg_parser[section]['stride'])\n",
    "            all_layers.append(\n",
    "                MaxPooling2D(\n",
    "                    pool_size=(size, size),\n",
    "                    strides=(stride, stride),\n",
    "                    padding='same')(prev_layer))\n",
    "            prev_layer = all_layers[-1]\n",
    "\n",
    "        elif section.startswith('shortcut'):\n",
    "            index = int(cfg_parser[section]['from'])\n",
    "            activation = cfg_parser[section]['activation']\n",
    "            assert activation == 'linear', 'Only linear activation supported.'\n",
    "            all_layers.append(Add()([all_layers[index], prev_layer]))\n",
    "            prev_layer = all_layers[-1]\n",
    "\n",
    "        elif section.startswith('upsample'):\n",
    "            stride = int(cfg_parser[section]['stride'])\n",
    "            assert stride == 2, 'Only stride=2 supported.'\n",
    "            all_layers.append(UpSampling2D(stride)(prev_layer))\n",
    "            prev_layer = all_layers[-1]\n",
    "\n",
    "        elif section.startswith('yolo'):\n",
    "            out_index.append(len(all_layers) - 1)\n",
    "            all_layers.append(None)\n",
    "            prev_layer = all_layers[-1]\n",
    "\n",
    "        elif section.startswith('net'):\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Unsupported section header type: {}'.format(section))\n",
    "\n",
    "    # Create and save model.\n",
    "    if len(out_index) == 0:\n",
    "        out_index.append(len(all_layers) - 1)\n",
    "    model = Model(inputs=input_layer, outputs=[all_layers[i] for i in out_index])\n",
    "\n",
    "    if weights_only:\n",
    "        model.save_weights('{}'.format(output_path))\n",
    "        print('Saved Keras weights to {}'.format(output_path))\n",
    "    else:\n",
    "        model.save('{}'.format(output_path))\n",
    "        print('Saved Keras model to {}'.format(output_path))\n",
    "\n",
    "    # Check to see if all weights have been read.\n",
    "    remaining_weights = len(weights_file.read()) // 4\n",
    "    weights_file.close()\n",
    "    print('Read {} of {} from Darknet weights.'.format(four_bytes_consumed_count,\n",
    "                                                       four_bytes_consumed_count + remaining_weights))\n",
    "    if remaining_weights > 0:\n",
    "        print('Warning: {} unused weights'.format(remaining_weights))\n",
    "        # output_root = \"/notebooks/models/\"\n",
    "        # plot(model, to_file='{}.png'.format(output_root), show_shapes=True)\n",
    "        # print('Saved model plot to {}.png'.format(output_root))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights.\n",
      "Weights Header:  0 2 0 [32013312]\n",
      "Parsing Darknet config.\n",
      "Creating Keras model.\n",
      "Parsing section net_0\n",
      "Parsing section convolutional_0\n",
      "conv2d bn leaky (32, 3, 3, 3)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/keras/layers/normalization/batch_normalization.py:514: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Parsing section convolutional_1\n",
      "conv2d bn leaky (64, 32, 3, 3)\n",
      "Parsing section convolutional_2\n",
      "conv2d bn leaky (32, 64, 1, 1)\n",
      "Parsing section convolutional_3\n",
      "conv2d bn leaky (64, 32, 3, 3)\n",
      "Parsing section shortcut_0\n",
      "Parsing section convolutional_4\n",
      "conv2d bn leaky (128, 64, 3, 3)\n",
      "Parsing section convolutional_5\n",
      "conv2d bn leaky (64, 128, 1, 1)\n",
      "Parsing section convolutional_6\n",
      "conv2d bn leaky (128, 64, 3, 3)\n",
      "Parsing section shortcut_1\n",
      "Parsing section convolutional_7\n",
      "conv2d bn leaky (64, 128, 1, 1)\n",
      "Parsing section convolutional_8\n",
      "conv2d bn leaky (128, 64, 3, 3)\n",
      "Parsing section shortcut_2\n",
      "Parsing section convolutional_9\n",
      "conv2d bn leaky (256, 128, 3, 3)\n",
      "Parsing section convolutional_10\n",
      "conv2d bn leaky (128, 256, 1, 1)\n",
      "Parsing section convolutional_11\n",
      "conv2d bn leaky (256, 128, 3, 3)\n",
      "Parsing section shortcut_3\n",
      "Parsing section convolutional_12\n",
      "conv2d bn leaky (128, 256, 1, 1)\n",
      "Parsing section convolutional_13\n",
      "conv2d bn leaky (256, 128, 3, 3)\n",
      "Parsing section shortcut_4\n",
      "Parsing section convolutional_14\n",
      "conv2d bn leaky (128, 256, 1, 1)\n",
      "Parsing section convolutional_15\n",
      "conv2d bn leaky (256, 128, 3, 3)\n",
      "Parsing section shortcut_5\n",
      "Parsing section convolutional_16\n",
      "conv2d bn leaky (128, 256, 1, 1)\n",
      "Parsing section convolutional_17\n",
      "conv2d bn leaky (256, 128, 3, 3)\n",
      "Parsing section shortcut_6\n",
      "Parsing section convolutional_18\n",
      "conv2d bn leaky (128, 256, 1, 1)\n",
      "Parsing section convolutional_19\n",
      "conv2d bn leaky (256, 128, 3, 3)\n",
      "Parsing section shortcut_7\n",
      "Parsing section convolutional_20\n",
      "conv2d bn leaky (128, 256, 1, 1)\n",
      "Parsing section convolutional_21\n",
      "conv2d bn leaky (256, 128, 3, 3)\n",
      "Parsing section shortcut_8\n",
      "Parsing section convolutional_22\n",
      "conv2d bn leaky (128, 256, 1, 1)\n",
      "Parsing section convolutional_23\n",
      "conv2d bn leaky (256, 128, 3, 3)\n",
      "Parsing section shortcut_9\n",
      "Parsing section convolutional_24\n",
      "conv2d bn leaky (128, 256, 1, 1)\n",
      "Parsing section convolutional_25\n",
      "conv2d bn leaky (256, 128, 3, 3)\n",
      "Parsing section shortcut_10\n",
      "Parsing section convolutional_26\n",
      "conv2d bn leaky (512, 256, 3, 3)\n",
      "Parsing section convolutional_27\n",
      "conv2d bn leaky (256, 512, 1, 1)\n",
      "Parsing section convolutional_28\n",
      "conv2d bn leaky (512, 256, 3, 3)\n",
      "Parsing section shortcut_11\n",
      "Parsing section convolutional_29\n",
      "conv2d bn leaky (256, 512, 1, 1)\n",
      "Parsing section convolutional_30\n",
      "conv2d bn leaky (512, 256, 3, 3)\n",
      "Parsing section shortcut_12\n",
      "Parsing section convolutional_31\n",
      "conv2d bn leaky (256, 512, 1, 1)\n",
      "Parsing section convolutional_32\n",
      "conv2d bn leaky (512, 256, 3, 3)\n",
      "Parsing section shortcut_13\n",
      "Parsing section convolutional_33\n",
      "conv2d bn leaky (256, 512, 1, 1)\n",
      "Parsing section convolutional_34\n",
      "conv2d bn leaky (512, 256, 3, 3)\n",
      "Parsing section shortcut_14\n",
      "Parsing section convolutional_35\n",
      "conv2d bn leaky (256, 512, 1, 1)\n",
      "Parsing section convolutional_36\n",
      "conv2d bn leaky (512, 256, 3, 3)\n",
      "Parsing section shortcut_15\n",
      "Parsing section convolutional_37\n",
      "conv2d bn leaky (256, 512, 1, 1)\n",
      "Parsing section convolutional_38\n",
      "conv2d bn leaky (512, 256, 3, 3)\n",
      "Parsing section shortcut_16\n",
      "Parsing section convolutional_39\n",
      "conv2d bn leaky (256, 512, 1, 1)\n",
      "Parsing section convolutional_40\n",
      "conv2d bn leaky (512, 256, 3, 3)\n",
      "Parsing section shortcut_17\n",
      "Parsing section convolutional_41\n",
      "conv2d bn leaky (256, 512, 1, 1)\n",
      "Parsing section convolutional_42\n",
      "conv2d bn leaky (512, 256, 3, 3)\n",
      "Parsing section shortcut_18\n",
      "Parsing section convolutional_43\n",
      "conv2d bn leaky (1024, 512, 3, 3)\n",
      "Parsing section convolutional_44\n",
      "conv2d bn leaky (512, 1024, 1, 1)\n",
      "Parsing section convolutional_45\n",
      "conv2d bn leaky (1024, 512, 3, 3)\n",
      "Parsing section shortcut_19\n",
      "Parsing section convolutional_46\n",
      "conv2d bn leaky (512, 1024, 1, 1)\n",
      "Parsing section convolutional_47\n",
      "conv2d bn leaky (1024, 512, 3, 3)\n",
      "Parsing section shortcut_20\n",
      "Parsing section convolutional_48\n",
      "conv2d bn leaky (512, 1024, 1, 1)\n",
      "Parsing section convolutional_49\n",
      "conv2d bn leaky (1024, 512, 3, 3)\n",
      "Parsing section shortcut_21\n",
      "Parsing section convolutional_50\n",
      "conv2d bn leaky (512, 1024, 1, 1)\n",
      "Parsing section convolutional_51\n",
      "conv2d bn leaky (1024, 512, 3, 3)\n",
      "Parsing section shortcut_22\n",
      "Parsing section convolutional_52\n",
      "conv2d bn leaky (512, 1024, 1, 1)\n",
      "Parsing section convolutional_53\n",
      "conv2d bn leaky (1024, 512, 3, 3)\n",
      "Parsing section convolutional_54\n",
      "conv2d bn leaky (512, 1024, 1, 1)\n",
      "Parsing section convolutional_55\n",
      "conv2d bn leaky (1024, 512, 3, 3)\n",
      "Parsing section convolutional_56\n",
      "conv2d bn leaky (512, 1024, 1, 1)\n",
      "Parsing section convolutional_57\n",
      "conv2d bn leaky (1024, 512, 3, 3)\n",
      "Parsing section convolutional_58\n",
      "conv2d    linear (255, 1024, 1, 1)\n",
      "Parsing section yolo_0\n",
      "Parsing section route_0\n",
      "Parsing section convolutional_59\n",
      "conv2d bn leaky (256, 512, 1, 1)\n",
      "Parsing section upsample_0\n",
      "Parsing section route_1\n",
      "Concatenating route layers: [<tf.Tensor 'up_sampling2d/resize/ResizeNearestNeighbor:0' shape=(?, 38, 38, 256) dtype=float32>, <tf.Tensor 'add_18/add:0' shape=(?, 38, 38, 512) dtype=float32>]\n",
      "Parsing section convolutional_60\n",
      "conv2d bn leaky (256, 768, 1, 1)\n",
      "Parsing section convolutional_61\n",
      "conv2d bn leaky (512, 256, 3, 3)\n",
      "Parsing section convolutional_62\n",
      "conv2d bn leaky (256, 512, 1, 1)\n",
      "Parsing section convolutional_63\n",
      "conv2d bn leaky (512, 256, 3, 3)\n",
      "Parsing section convolutional_64\n",
      "conv2d bn leaky (256, 512, 1, 1)\n",
      "Parsing section convolutional_65\n",
      "conv2d bn leaky (512, 256, 3, 3)\n",
      "Parsing section convolutional_66\n",
      "conv2d    linear (255, 512, 1, 1)\n",
      "Parsing section yolo_1\n",
      "Parsing section route_2\n",
      "Parsing section convolutional_67\n",
      "conv2d bn leaky (128, 256, 1, 1)\n",
      "Parsing section upsample_1\n",
      "Parsing section route_3\n",
      "Concatenating route layers: [<tf.Tensor 'up_sampling2d_1/resize/ResizeNearestNeighbor:0' shape=(?, 76, 76, 128) dtype=float32>, <tf.Tensor 'add_10/add:0' shape=(?, 76, 76, 256) dtype=float32>]\n",
      "Parsing section convolutional_68\n",
      "conv2d bn leaky (128, 384, 1, 1)\n",
      "Parsing section convolutional_69\n",
      "conv2d bn leaky (256, 128, 3, 3)\n",
      "Parsing section convolutional_70\n",
      "conv2d bn leaky (128, 256, 1, 1)\n",
      "Parsing section convolutional_71\n",
      "conv2d bn leaky (256, 128, 3, 3)\n",
      "Parsing section convolutional_72\n",
      "conv2d bn leaky (128, 256, 1, 1)\n",
      "Parsing section convolutional_73\n",
      "conv2d bn leaky (256, 128, 3, 3)\n",
      "Parsing section convolutional_74\n",
      "conv2d    linear (255, 256, 1, 1)\n",
      "Parsing section yolo_2\n",
      "Saved Keras model to /notebooks/models/yologv3.h5\n",
      "Read 62001757 of 62001757 from Darknet weights.\n"
     ]
    }
   ],
   "source": [
    "# read the model from the config file\n",
    "config_path = '/notebooks/config/yolov3.cfg'\n",
    "weights_path = '/notebooks/config/yolov3.weights'\n",
    "output_path = '/notebooks/models/yologv3.h5'\n",
    "partial_model = parse_config(config_path, output_path=output_path, weights_path=weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_boxes_graph(y_pred_xy, y_pred_wh, input_shape, image_shape):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        y_pred_xy: (b, fh, fw, num_anchors_this_layer, 2)\n",
    "        y_pred_wh: (b, fh, fw, num_anchors_this_layer, 2)\n",
    "        input_shape: (b, 2), hw\n",
    "        image_shape: (b, 2), hw\n",
    "\n",
    "    Returns:\n",
    "        boxes: (b, fh, fw, num_anchors_this_layer, 4), (y_min, x_min, y_max, x_max)\n",
    "\n",
    "    \"\"\"\n",
    "    box_yx = y_pred_xy[..., ::-1]\n",
    "    box_hw = y_pred_wh[..., ::-1]\n",
    "    input_shape = K.cast(input_shape, K.dtype(box_yx))\n",
    "    image_shape = K.cast(image_shape, K.dtype(box_yx))\n",
    "    new_shape = K.round(image_shape * K.min(input_shape / image_shape))\n",
    "    offset = (input_shape - new_shape) / 2. / input_shape\n",
    "    scale = input_shape / new_shape\n",
    "    box_yx = (box_yx - offset) * scale\n",
    "    box_hw *= scale\n",
    "    box_mins = box_yx - (box_hw / 2.)\n",
    "    box_maxes = box_yx + (box_hw / 2.)\n",
    "    boxes = K.concatenate([\n",
    "        # y_min\n",
    "        box_mins[..., 0:1],\n",
    "        # x_min\n",
    "        box_mins[..., 1:2],\n",
    "        # y_max\n",
    "        box_maxes[..., 0:1],\n",
    "        # x_max\n",
    "        box_maxes[..., 1:2]\n",
    "    ])\n",
    "\n",
    "    # Scale boxes back to original image shape.\n",
    "    boxes *= K.concatenate([image_shape, image_shape])\n",
    "    \n",
    "    return boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_boxes_and_scores_graph(raw_y_pred, anchors, num_classes, input_shape, image_shape):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        raw_y_pred:\n",
    "        anchors: (num_anchors_this_layer, 2)\n",
    "        num_classes:\n",
    "        input_shape: (2, ) hw\n",
    "        image_shape: (batch_size, 2)\n",
    "\n",
    "    Returns:\n",
    "        boxes: (b, total_num_anchors_this_layer, 4), (y_min, x_min, y_max, x_max)\n",
    "        boxes_scores: (b, total_num_anchors_this_layer, num_classes)\n",
    "\n",
    "    \"\"\"\n",
    "    _, y_pred_box, _, _, y_pred_sigma, y_pred_confidence, y_pred_class_probs = y_pred_graph(raw_y_pred, anchors, input_shape)\n",
    "    y_pred_xy = y_pred_box[..., :2]\n",
    "    y_pred_wh = y_pred_box[..., 2:]\n",
    "    # for batch predictions\n",
    "    batch_size = K.shape(image_shape)[0]\n",
    "    input_shape = K.expand_dims(input_shape, axis=0)\n",
    "    input_shape = K.tile(input_shape, (batch_size, 1))\n",
    "    elems = (y_pred_xy, y_pred_wh, input_shape, image_shape)\n",
    "    boxes = tf.map_fn(lambda x: correct_boxes_graph(x[0], x[1], x[2], x[3]), elems=elems, fn_output_signature=tf.float32)\n",
    "    box_scores = y_pred_confidence * y_pred_class_probs * (1 - tf.reduce_mean(y_pred_sigma, axis=-1, keepdims=True))\n",
    "    boxes = tf.reshape(boxes, [batch_size, -1, 4])\n",
    "    box_scores = tf.reshape(box_scores, [batch_size, -1, num_classes])\n",
    "    \n",
    "    return boxes, box_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_iou_graph(b1, b2):\n",
    "    \"\"\"\n",
    "    Return iou tensor\n",
    "\n",
    "    Args:\n",
    "        b1 (tensor): (fh, fw, num_anchors_this_layer, 4)\n",
    "        b2 (tensor): (num_gt_boxes, 4)\n",
    "\n",
    "    Returns:\n",
    "        iou (tensor): shape=(num_b1_boxes, num_b2_boxes)\n",
    "    \"\"\"\n",
    "    # Expand dim to apply broadcasting.\n",
    "    # (fh, fw, num_anchors_this_layer, 1, 4)\n",
    "    b1 = K.expand_dims(b1, -2)\n",
    "    b1_xy = b1[..., :2]\n",
    "    b1_wh = b1[..., 2:4]\n",
    "    b1_wh_half = b1_wh / 2.\n",
    "    b1_mins = b1_xy - b1_wh_half\n",
    "    b1_maxes = b1_xy + b1_wh_half\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    # (1, num_gt_boxes, 4)\n",
    "    b2 = K.expand_dims(b2, 0)\n",
    "    b2_xy = b2[..., :2]\n",
    "    b2_wh = b2[..., 2:4]\n",
    "    b2_wh_half = b2_wh / 2.\n",
    "    b2_mins = b2_xy - b2_wh_half\n",
    "    b2_maxes = b2_xy + b2_wh_half\n",
    "\n",
    "    # (fh, fw, num_anchors_this_layer, num_b2_boxes, 2)\n",
    "    intersect_mins = K.maximum(b1_mins, b2_mins)\n",
    "    intersect_maxes = K.minimum(b1_maxes, b2_maxes)\n",
    "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    # (fh, fw, num_anchors_this_layer, num_b2_boxes)\n",
    "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    # (fh, fw, num_anchors_this_layer, 1)\n",
    "    b1_area = b1_wh[..., 0] * b1_wh[..., 1]\n",
    "    # (1, num_gt_boxes)\n",
    "    b2_area = b2_wh[..., 0] * b2_wh[..., 1]\n",
    "    iou = intersect_area / (b1_area + b2_area - intersect_area)\n",
    "    \n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_pred_graph(raw_y_pred, anchors, input_shape):\n",
    "    \"\"\"\n",
    "    Convert final layer features to bounding box parameters.\n",
    "\n",
    "    Args:\n",
    "        raw_y_pred: (b, fh, fw, num_anchors_per_layer, 2 + 2 + 1 + num_classes)\n",
    "        anchors:\n",
    "        input_shape:\n",
    "\n",
    "    Returns:\n",
    "        grid: (fh, fw, 1, 2)\n",
    "        y_pred_box: (b, fh, fw, num_anchors_this_layer, 2 + 2)\n",
    "        y_pred_delta_xy:\n",
    "        y_pred_log_wh:\n",
    "        y_pred_confidence: (b, fh, fw, num_anchors_this_layer, 1)\n",
    "        y_pred_class_probs: (b, fh, fw, num_anchors_this_layer, num_classes)\n",
    "    \"\"\"\n",
    "    num_anchors_this_layer = len(anchors)\n",
    "    # Reshape to (batch, height, width, num_anchors, box_params)\n",
    "    anchors_tensor = K.reshape(K.constant(anchors), [1, 1, 1, num_anchors_this_layer, 2])\n",
    "    grid_shape = K.shape(raw_y_pred)[1:3]\n",
    "    grid_y = K.tile(K.reshape(K.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1]), [1, grid_shape[1], 1, 1])\n",
    "    grid_x = K.tile(K.reshape(K.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]), [grid_shape[0], 1, 1, 1])\n",
    "    grid = K.concatenate([grid_x, grid_y], axis=-1)\n",
    "    grid = K.cast(grid, K.dtype(raw_y_pred))\n",
    "    y_pred_xy = (K.sigmoid(raw_y_pred[..., :2]) + grid) / K.cast(grid_shape[::-1], K.dtype(raw_y_pred))\n",
    "    y_pred_wh = K.exp(raw_y_pred[..., 2:4]) * (anchors_tensor / K.cast(input_shape[::-1], K.dtype(raw_y_pred)))\n",
    "    # (batch_size, grid_height, grid_width, num_anchors_this_layer, 4)\n",
    "    y_pred_box = K.concatenate([y_pred_xy, y_pred_wh])\n",
    "    y_pred_delta_xy = K.sigmoid(raw_y_pred[..., :2])\n",
    "    y_pred_log_wh = raw_y_pred[..., 2:4]\n",
    "    y_pred_sigma = K.sigmoid(raw_y_pred[..., 4:8])\n",
    "    y_pred_confidence = K.sigmoid(raw_y_pred[..., 8:9])\n",
    "    y_pred_class_probs = K.sigmoid(raw_y_pred[..., 9:])\n",
    "\n",
    "    return grid, y_pred_box, y_pred_delta_xy, y_pred_log_wh, y_pred_sigma, y_pred_confidence, y_pred_class_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the detection layer to the model\n",
    "class DetectionLayer(Layer):\n",
    "    def __init__(self,\n",
    "                 anchors,\n",
    "                 num_classes=20,\n",
    "                 max_boxes_per_class_per_image=20,\n",
    "                 score_threshold=.2,\n",
    "                 iou_threshold=.5,\n",
    "                 max_boxes_per_image=400,\n",
    "                 **kwargs\n",
    "                 ):\n",
    "        super(DetectionLayer, self).__init__(**kwargs)\n",
    "        self.anchors = anchors\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.max_boxes_per_class_per_image = max_boxes_per_class_per_image\n",
    "        self.max_boxes_per_image = max_boxes_per_image\n",
    "        self.num_classes = num_classes\n",
    "        self.score_threshold = score_threshold\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        yolo_outputs = inputs[:-1]\n",
    "        batch_image_shape = inputs[-1]\n",
    "        num_output_layers = len(yolo_outputs)\n",
    "        num_anchors_per_layer = len(self.anchors) // num_output_layers\n",
    "        anchor_mask = [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n",
    "        # tensor, (2, )\n",
    "        input_shape = K.shape(yolo_outputs[0])[1:3] * 32\n",
    "        grid_shapes = [K.shape(yolo_outputs[l])[1:3]\n",
    "                       for l in range(num_output_layers)]\n",
    "        boxes_all_layers = []\n",
    "        scores_all_layers = []\n",
    "        for l in range(num_output_layers):\n",
    "            yolo_output = yolo_outputs[l]\n",
    "            grid_shape = grid_shapes[l]\n",
    "            raw_y_pred = K.reshape(yolo_output,\n",
    "            [-1, grid_shape[0], grid_shape[1], num_anchors_per_layer, self.num_classes + 9])\n",
    "            boxes_this_layer, scores_this_layer = correct_boxes_and_scores_graph(raw_y_pred,\n",
    "                self.anchors[anchor_mask[l]],\n",
    "                self.num_classes,\n",
    "                input_shape,\n",
    "                batch_image_shape,\n",
    "                )\n",
    "            boxes_all_layers.append(boxes_this_layer)\n",
    "            scores_all_layers.append(scores_this_layer)\n",
    "\n",
    "        # (b, total_num_anchors_all_layers, 4)\n",
    "        boxes = K.concatenate(boxes_all_layers, axis=1)\n",
    "        # (b, total_num_anchors_all_layers, num_classes)\n",
    "        scores = K.concatenate(scores_all_layers, axis=1)\n",
    "        mask = scores >= self.score_threshold\n",
    "        max_boxes_per_class_per_image_tensor = K.constant(\n",
    "            self.max_boxes_per_class_per_image, dtype='int32')\n",
    "        max_boxes_per_image_tensor = K.constant(\n",
    "            self.max_boxes_per_image, dtype='int32')\n",
    "\n",
    "        def evaluate_batch_item(batch_item_boxes, batch_item_scores, batch_item_mask):\n",
    "            boxes_per_class = []\n",
    "            scores_per_class = []\n",
    "            class_ids_per_class = []\n",
    "            for c in range(self.num_classes):\n",
    "                class_boxes = tf.boolean_mask(\n",
    "                    batch_item_boxes, batch_item_mask[:, c])\n",
    "                # (num_keep_this_class_boxes, )\n",
    "                class_scores = tf.boolean_mask(\n",
    "                    batch_item_scores[:, c], batch_item_mask[:, c])\n",
    "                nms_keep_indices = tf.image.non_max_suppression(class_boxes,\n",
    "                                                                class_scores,\n",
    "                                                                max_boxes_per_class_per_image_tensor,\n",
    "                                                                iou_threshold=self.iou_threshold)\n",
    "                class_boxes = K.gather(class_boxes, nms_keep_indices)\n",
    "                class_scores = K.gather(class_scores, nms_keep_indices)\n",
    "                # (num_keep_this_class_boxes, )\n",
    "                class_class_ids = K.ones_like(class_scores, 'float32') * c\n",
    "                boxes_per_class.append(class_boxes)\n",
    "                scores_per_class.append(class_scores)\n",
    "                class_ids_per_class.append(class_class_ids)\n",
    "\n",
    "            batch_item_boxes = K.concatenate(boxes_per_class, axis=0)\n",
    "            batch_item_scores = K.concatenate(scores_per_class, axis=0)\n",
    "            batch_item_scores = K.expand_dims(batch_item_scores, axis=-1)\n",
    "            batch_item_class_ids = K.concatenate(class_ids_per_class, axis=0)\n",
    "            batch_item_class_ids = K.expand_dims(batch_item_class_ids, axis=-1)\n",
    "            # (num_keep_all_class_boxes, 6)\n",
    "            batch_item_predictions = K.concatenate([batch_item_boxes,\n",
    "                                                    batch_item_scores,\n",
    "                                                    batch_item_class_ids], axis=-1)\n",
    "            batch_item_num_predictions = tf.shape(batch_item_boxes)[0]\n",
    "            tf.print(batch_item_num_predictions, [batch_item_num_predictions], '\\nbatch_item_num_predictions', summarize=1000)\n",
    "            batch_item_num_pad = tf.maximum(\n",
    "                max_boxes_per_image_tensor - batch_item_num_predictions, 0)\n",
    "            padded_batch_item_predictions = tf.pad(tensor=batch_item_predictions,\n",
    "                                                   paddings=[\n",
    "                                                       [0, batch_item_num_pad],\n",
    "                                                       [0, 0]],\n",
    "                                                   mode='CONSTANT',\n",
    "                                                   constant_values=0.0)\n",
    "            return padded_batch_item_predictions\n",
    "\n",
    "        predictions = tf.map_fn(lambda x: evaluate_batch_item(x[0], x[1], x[2]),\n",
    "                                elems=(boxes, scores, mask),\n",
    "                                fn_output_signature=tf.float32,)\n",
    "\n",
    "        predictions = tf.reshape(\n",
    "            predictions, (-1, self.max_boxes_per_image, 6))\n",
    "        return predictions\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return None, self.max_boxes_per_image, 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_loss(x, mu, sigma, sigma_const=0.3):\n",
    "    pi = tf.constant(np.pi)\n",
    "    Z = (2 * pi * (sigma + sigma_const) ** 2) ** 0.5\n",
    "    probability_density = tf.exp(-0.5 * (x - mu) ** 2 / ((sigma + sigma_const) ** 2)) / Z\n",
    "    nll = -tf.math.log(probability_density + 1e-7)\n",
    "    return nll\n",
    "\n",
    "\n",
    "def yolo_loss(args, anchors, num_anchors_per_layer, num_classes, ignore_thresh=.5, print_loss=True):\n",
    "    \"\"\"\n",
    "    Return yolo_loss tensor\n",
    "\n",
    "    Args:\n",
    "        args (list): args[:num_output_layers] the output of yolo_body or tiny_yolo_body\n",
    "            args[num_output_layers:] raw_y_true\n",
    "        anchors (np.array): shape=(N, 2), wh\n",
    "        num_anchors_per_layer (int):\n",
    "        num_classes (int):\n",
    "        ignore_thresh (float): the iou threshold whether to ignore object confidence loss\n",
    "        print_loss:\n",
    "\n",
    "    Returns:\n",
    "        loss: tensor, shape=(1,)\n",
    "\n",
    "    \"\"\"\n",
    "    num_output_layers = len(anchors) // num_anchors_per_layer\n",
    "    yolo_outputs = args[:num_output_layers]\n",
    "    raw_y_trues = args[num_output_layers:]\n",
    "    anchor_masks = [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n",
    "    input_shape = K.cast(K.shape(yolo_outputs[0])[1:3] * 32, K.dtype(raw_y_trues[0]))\n",
    "    grid_shapes = [K.cast(K.shape(yolo_outputs[l])[1:3], K.dtype(raw_y_trues[0])) for l in range(num_output_layers)]\n",
    "    loss = 0\n",
    "    batch_size = K.shape(yolo_outputs[0])[0]\n",
    "    batch_size_f = K.cast(batch_size, K.dtype(yolo_outputs[0]))\n",
    "\n",
    "    # with tqdm(, total=STEPS_PER_EPOCH) as pbar:\n",
    "    for l in range(num_output_layers):\n",
    "        grid_shape = grid_shapes[l]\n",
    "        yolo_output = yolo_outputs[l]\n",
    "        raw_y_pred = K.reshape(yolo_output, [-1, grid_shape[0], grid_shape[1], num_anchors_per_layer, num_classes + 9])\n",
    "        raw_y_true = raw_y_trues[l]\n",
    "        anchor_mask = anchor_masks[l]\n",
    "        # (batch_size, grid_height, grid_width, num_anchors_this_layer, 1)\n",
    "        object_mask = raw_y_true[..., 4:5]\n",
    "        # (batch_size, grid_height, grid_width, num_anchors_this_layer, num_classes)\n",
    "        y_true_class_probs = raw_y_true[..., 5:]\n",
    "        grid, y_pred_box, y_pred_delta_xy, y_pred_log_wh, y_pred_sigma, y_pred_confidence, y_pred_class_probs = \\\n",
    "            y_pred_graph(raw_y_pred, anchors[anchor_mask], input_shape)\n",
    "        y_true_delta_xy = raw_y_true[..., :2] * grid_shapes[l][::-1] - grid\n",
    "        y_true_log_wh = K.log(raw_y_true[..., 2:4] * input_shape[::-1] / anchors[anchor_mask])\n",
    "        y_true_log_wh = K.switch(object_mask, y_true_log_wh, K.zeros_like(y_true_log_wh))\n",
    "        box_loss_scale = 2 - raw_y_true[..., 2:3] * raw_y_true[..., 3:4]\n",
    "        ignore_mask = tf.TensorArray(K.dtype(raw_y_trues[0]), size=1, dynamic_size=True)\n",
    "        object_mask_bool = K.cast(object_mask, 'bool')\n",
    "\n",
    "        def loop_body(b, ignore_mask_):\n",
    "            # (num_gt_boxes, 4)\n",
    "            gt_box = tf.boolean_mask(raw_y_true[b, ..., 0:4], object_mask_bool[b, ..., 0])\n",
    "            # (grid_height, grid_width, num_anchors_this_layer, num_gt_boxes)\n",
    "            iou = box_iou_graph(y_pred_box[b], gt_box)\n",
    "            # (grid_height, grid_width, num_anchors_this_layer)\n",
    "            best_iou = K.max(iou, axis=-1)\n",
    "            ignore_mask_ = ignore_mask_.write(b, K.cast(best_iou < ignore_thresh, K.dtype(gt_box)))\n",
    "            return b + 1, ignore_mask_\n",
    "\n",
    "        _, ignore_mask = tf.while_loop(lambda b, *largs: b < batch_size, loop_body, [0, ignore_mask])\n",
    "        # (batch_size, grid_height, grid_width, num_anchors_this_layer)\n",
    "        ignore_mask = ignore_mask.stack()\n",
    "        # (batch_size, grid_height, grid_width, num_anchors_this_layer, 1)\n",
    "        ignore_mask = K.expand_dims(ignore_mask, -1)\n",
    "\n",
    "        y_true = tf.concat([y_true_delta_xy, y_true_log_wh], axis=-1)\n",
    "        y_pred_mu = tf.concat([y_pred_delta_xy, y_pred_log_wh], axis=-1)\n",
    "        x_loss = nll_loss(y_true[..., 0:1], y_pred_mu[..., 0:1], y_pred_sigma[..., 0:1])\n",
    "        x_loss = object_mask * box_loss_scale * x_loss\n",
    "        y_loss = nll_loss(y_true[..., 1:2], y_pred_mu[..., 1:2], y_pred_sigma[..., 1:2])\n",
    "        y_loss = object_mask * box_loss_scale * y_loss\n",
    "        w_loss = nll_loss(y_true[..., 2:3], y_pred_mu[..., 2:3], y_pred_sigma[..., 2:3])\n",
    "        w_loss = object_mask * box_loss_scale * w_loss\n",
    "        h_loss = nll_loss(y_true[..., 3:4], y_pred_mu[..., 3:4], y_pred_sigma[..., 3:4])\n",
    "        h_loss = object_mask * box_loss_scale * h_loss\n",
    "        confidence_loss = object_mask * K.binary_crossentropy(object_mask, y_pred_confidence) + \\\n",
    "                        (1 - object_mask) * K.binary_crossentropy(object_mask, y_pred_confidence) * ignore_mask\n",
    "        class_loss = object_mask * K.binary_crossentropy(y_true_class_probs, y_pred_class_probs)\n",
    "        x_loss = K.sum(x_loss) / batch_size_f\n",
    "        y_loss = K.sum(y_loss) / batch_size_f\n",
    "        w_loss = K.sum(w_loss) / batch_size_f\n",
    "        h_loss = K.sum(h_loss) / batch_size_f\n",
    "        confidence_loss = K.sum(confidence_loss) / batch_size_f\n",
    "        class_loss = K.sum(class_loss) / batch_size_f\n",
    "        loss += x_loss + y_loss + w_loss + h_loss + confidence_loss + class_loss\n",
    "\n",
    "        # print the loss for debugging\n",
    "\n",
    "\n",
    "        if print_loss:\n",
    "            values = [loss, x_loss, y_loss, w_loss, h_loss, confidence_loss, class_loss, K.sum(ignore_mask)]\n",
    "            # convert to tf tensor\n",
    "            values = [tf.convert_to_tensor(value) for value in values]\n",
    "            loss = tf.print(values, output_stream=sys.stdout)\n",
    "            \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose(*funcs):\n",
    "    \"\"\"\n",
    "    Compose arbitrarily many functions, evaluated left to right.\n",
    "\n",
    "    Reference: https://mathieularose.com/function-composition-in-python/\n",
    "    \"\"\"\n",
    "    # return lambda x: reduce(lambda v, f: f(v), funcs, x)\n",
    "    if funcs:\n",
    "        return reduce(lambda f, g: lambda *args, **kwargs: g(f(*args, **kwargs)), funcs)\n",
    "    else:\n",
    "        raise ValueError('Composition of empty sequence not supported.')\n",
    "\n",
    "\n",
    "def darknet_conv2d(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    Wrapper to set Darknet parameters for Convolution2D.\n",
    "    \"\"\"\n",
    "    darknet_conv_kwargs = dict({'kernel_regularizer': l2(5e-4)})\n",
    "    darknet_conv_kwargs['padding'] = 'valid' if kwargs.get('strides') == (2, 2) else 'same'\n",
    "    darknet_conv_kwargs.update(kwargs)\n",
    "    return Conv2D(*args, **darknet_conv_kwargs)\n",
    "\n",
    "\n",
    "def darknet_conv2d_bn_leaky(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    Darknet Convolution2D followed by BatchNormalization and LeakyReLU.\n",
    "    \"\"\"\n",
    "    no_bias_kwargs = {'use_bias': False}\n",
    "    no_bias_kwargs.update(kwargs)\n",
    "    return compose(\n",
    "        darknet_conv2d(*args, **no_bias_kwargs),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1))\n",
    "\n",
    "\n",
    "def resblock_body(x, num_filters, num_blocks):\n",
    "    \"\"\"\n",
    "    A series of resblocks starting with a downsampling Convolution2D\n",
    "    \"\"\"\n",
    "    # Darknet uses left and top padding instead of 'same' mode\n",
    "    x = ZeroPadding2D(((1, 0), (1, 0)))(x)\n",
    "    x = darknet_conv2d_bn_leaky(num_filters, (3, 3), strides=(2, 2))(x)\n",
    "    for i in range(num_blocks):\n",
    "        y = compose(\n",
    "            darknet_conv2d_bn_leaky(num_filters // 2, (1, 1)),\n",
    "            darknet_conv2d_bn_leaky(num_filters, (3, 3)))(x)\n",
    "        x = Add()([x, y])\n",
    "    return x\n",
    "\n",
    "\n",
    "def darknet_body(x):\n",
    "    \"\"\"\n",
    "    Darknet body having 52 Convolution2D layers\n",
    "    1 + (1 + 1 * 2) + (1 + 2 * 2) + (1 + 8 * 2) + (1 + 8 * 2) + (1 + 4 * 2) = 1 + 3 + 5 + 17 + 17 + 9 = 52\n",
    "    \"\"\"\n",
    "    # (416, 416)\n",
    "    x = darknet_conv2d_bn_leaky(32, (3, 3))(x)\n",
    "    # (208, 208)\n",
    "    x = resblock_body(x, 64, 1)\n",
    "    # (104, 104)\n",
    "    x = resblock_body(x, 128, 2)\n",
    "    # (52, 52)\n",
    "    x = resblock_body(x, 256, 8)\n",
    "    # (26, 26)\n",
    "    x = resblock_body(x, 512, 8)\n",
    "    # (13, 13)\n",
    "    x = resblock_body(x, 1024, 4)\n",
    "    return x\n",
    "\n",
    "\n",
    "def make_last_layers(x, num_filters, out_filters):\n",
    "    \"\"\"\n",
    "    6 conv2d_bn_leaky layers followed by a conv2d layer\n",
    "    \"\"\"\n",
    "    x = compose(darknet_conv2d_bn_leaky(num_filters, (1, 1)),\n",
    "                darknet_conv2d_bn_leaky(num_filters * 2, (3, 3)),\n",
    "                darknet_conv2d_bn_leaky(num_filters, (1, 1)),\n",
    "                darknet_conv2d_bn_leaky(num_filters * 2, (3, 3)),\n",
    "                darknet_conv2d_bn_leaky(num_filters, (1, 1)))(x)\n",
    "    y = compose(darknet_conv2d_bn_leaky(num_filters * 2, (3, 3)),\n",
    "                darknet_conv2d(out_filters, (1, 1)))(x)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def yolo_body(anchors, num_classes=20, score_threshold=0.01):\n",
    "    \"\"\"\n",
    "    Create YOLO_V3 model CNN body in Keras.\n",
    "\n",
    "    Args:\n",
    "        anchors:\n",
    "        num_classes:\n",
    "        score_threshold:\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    num_anchors = len(anchors)\n",
    "    num_anchors_per_layer = num_anchors // 3\n",
    "    image_input = Input(shape=(None, None, 3), name='image_input')\n",
    "    fm_13_input = Input(shape=(None, None, num_anchors_per_layer, num_classes + 5), name='fm_13_input')\n",
    "    fm_26_input = Input(shape=(None, None, num_anchors_per_layer, num_classes + 5), name='fm_26_input')\n",
    "    fm_52_input = Input(shape=(None, None, num_anchors_per_layer, num_classes + 5), name='fm_52_input')\n",
    "    image_shape_input = Input(shape=(2,), name='image_shape_input')\n",
    "\n",
    "    darknet = Model([image_input], darknet_body(image_input))\n",
    "    \n",
    "    x, y1 = make_last_layers(darknet.output, 512, num_anchors_per_layer * (num_classes + 9))\n",
    "    x = compose(darknet_conv2d_bn_leaky(256, (1, 1)), UpSampling2D(2))(x)\n",
    "    x = Concatenate()([x, darknet.layers[152].output])\n",
    "    x, y2 = make_last_layers(x, 256, num_anchors_per_layer * (num_classes + 9))\n",
    "    x = compose(darknet_conv2d_bn_leaky(128, (1, 1)), UpSampling2D(2))(x)\n",
    "    x = Concatenate()([x, darknet.layers[92].output])\n",
    "    x, y3 = make_last_layers(x, 128, num_anchors_per_layer * (num_classes + 9))\n",
    "\n",
    "    loss = Lambda(yolo_loss,output_shape=(1,),name='yolo_loss',\n",
    "        arguments={'anchors': anchors,\n",
    "                    'num_anchors_per_layer': num_anchors_per_layer,\n",
    "                    'num_classes': num_classes,\n",
    "                    'ignore_thresh': 0.5})([y1, y2, y3, fm_13_input, fm_26_input, fm_52_input])\n",
    "                    \n",
    "    training_model = Model([image_input, fm_13_input, fm_26_input, fm_52_input], loss, name='yolo')\n",
    "\n",
    "    detections = DetectionLayer(\n",
    "        anchors, \n",
    "        num_classes=num_classes, \n",
    "        score_threshold=score_threshold, \n",
    "        name='yolo_detection')([y1, y2, y3, image_shape_input])\n",
    "\n",
    "    prediction_model = Model([image_input, image_shape_input], detections, name='yolo')\n",
    "\n",
    "    return training_model, prediction_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyprameters\n",
    "BATCH_SIZE = 8\n",
    "CONFIDENCE = 0.5\n",
    "NMS_CONF = 0.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=13.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.46s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "misc_effect = MiscEffect()\n",
    "visual_effect = VisualEffect()\n",
    "\n",
    "\n",
    "train_generator = CocoGenerator(\n",
    "    data_dir='/notebooks/data',\n",
    "    set_name='train2017',\n",
    "    # misc_effect=misc_effect,\n",
    "    # visual_effect=visual_effect,\n",
    "    anchors_path='/notebooks/data/yolo_anchors.txt',\n",
    "    multi_scale=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=608,\n",
    ")\n",
    "\n",
    "val_generator = CocoGenerator(\n",
    "    data_dir='/notebooks/data',\n",
    "    set_name='val2017',\n",
    "    shuffle_groups=False,\n",
    "    anchors_path='/notebooks/data/yolo_anchors.txt',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=608,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_classes(namesfile):\n",
    "    fp = open(namesfile, \"r\")\n",
    "    names = fp.read().split(\"\\n\")[:-1]\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "num_classes = 80\n",
    "classes = load_classes(\"./data/coco.names\")\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_anchors():\n",
    "#         \"\"\"\n",
    "#         loads the anchors from a txt file\n",
    "#         \"\"\"\n",
    "#         anchors = \"10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\"\n",
    "#         anchors = [float(x) for x in anchors.split(',')]\n",
    "#         # (N, 2), wh\n",
    "#         return np.array(anchors).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchors:  [[ 10.  13.]\n",
      " [ 16.  30.]\n",
      " [ 33.  23.]\n",
      " [ 30.  61.]\n",
      " [ 62.  45.]\n",
      " [ 59. 119.]\n",
      " [116.  90.]\n",
      " [156. 198.]\n",
      " [373. 326.]]\n"
     ]
    }
   ],
   "source": [
    "input_shape = (608, 608)\n",
    "anchors = train_generator.anchors\n",
    "num_classes = train_generator.num_classes()\n",
    "print(\"anchors: \", anchors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model, prediction_model = yolo_body(anchors, num_classes=num_classes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model, this may take a second...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "slice index -1 of dimension 0 out of bounds. for '{{node loss/yolo_loss_loss/strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_INT32, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](loss/yolo_loss_loss/Shape, loss/yolo_loss_loss/strided_slice/stack, loss/yolo_loss_loss/strided_slice/stack_1, loss/yolo_loss_loss/strided_slice/stack_2)' with input shapes: [0], [1], [1], [1] and with computed input tensors: input[1] = <-1>, input[2] = <0>, input[3] = <1>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\the_3\\OneDrive\\Desktop\\school\\fall 2022\\neural networks class\\projects\\real-time-object-detector\\src\\yolog.ipynb Cell 37\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X51sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39mload_weights(\u001b[39m\"\u001b[39m\u001b[39m/notebooks/models/yologv3.h5\u001b[39m\u001b[39m\"\u001b[39m, by_name\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, skip_mismatch\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X51sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# compile model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X51sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39;49mcompile(optimizer\u001b[39m=\u001b[39;49mAdam(learning_rate\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m), loss\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39myolo_loss\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mlambda\u001b[39;49;00m y_true, y_pred: y_pred})\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/training/tracking/base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 587\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    588\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    589\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:442\u001b[0m, in \u001b[0;36mModel.compile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m training_utils_v1\u001b[39m.\u001b[39mprepare_sample_weight_modes(\n\u001b[1;32m    439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_training_endpoints, sample_weight_mode)\n\u001b[1;32m    441\u001b[0m \u001b[39m# Creates the model loss and weighted metrics sub-graphs.\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compile_weights_loss_and_weighted_metrics()\n\u001b[1;32m    444\u001b[0m \u001b[39m# Functions for train, test and predict will\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39m# be compiled lazily when required.\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[39m# This saves time when the user is not using all functions.\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/training/tracking/base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 587\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    588\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    589\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:1525\u001b[0m, in \u001b[0;36mModel._compile_weights_loss_and_weighted_metrics\u001b[0;34m(self, sample_weights)\u001b[0m\n\u001b[1;32m   1512\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_metrics(\n\u001b[1;32m   1513\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs,\n\u001b[1;32m   1514\u001b[0m     targets\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_targets,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1517\u001b[0m     masks\u001b[39m=\u001b[39mmasks,\n\u001b[1;32m   1518\u001b[0m     return_weighted_metrics\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1520\u001b[0m \u001b[39m# Compute total loss.\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m \u001b[39m# Used to keep track of the total loss value (stateless).\u001b[39;00m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# eg., total_loss = loss_weight_1 * output_1_loss_fn(...) +\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m#                   loss_weight_2 * output_2_loss_fn(...) +\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39m#                   layer losses.\u001b[39;00m\n\u001b[0;32m-> 1525\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_total_loss(masks)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:1585\u001b[0m, in \u001b[0;36mModel._prepare_total_loss\u001b[0;34m(self, masks)\u001b[0m\n\u001b[1;32m   1582\u001b[0m     sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m mask\n\u001b[1;32m   1584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(loss_fn, \u001b[39m'\u001b[39m\u001b[39mreduction\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m-> 1585\u001b[0m   per_sample_losses \u001b[39m=\u001b[39m loss_fn\u001b[39m.\u001b[39;49mcall(y_true, y_pred)\n\u001b[1;32m   1586\u001b[0m   weighted_losses \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39mcompute_weighted_loss(\n\u001b[1;32m   1587\u001b[0m       per_sample_losses,\n\u001b[1;32m   1588\u001b[0m       sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[1;32m   1589\u001b[0m       reduction\u001b[39m=\u001b[39mlosses_utils\u001b[39m.\u001b[39mReductionV2\u001b[39m.\u001b[39mNONE)\n\u001b[1;32m   1590\u001b[0m   loss_reduction \u001b[39m=\u001b[39m loss_fn\u001b[39m.\u001b[39mreduction\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/losses.py:240\u001b[0m, in \u001b[0;36mLossFunctionWrapper.call\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39m\"\"\"Invokes the `LossFunctionWrapper` instance.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \n\u001b[1;32m    232\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39m  Loss values per sample.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mis_tensor(y_pred) \u001b[39mand\u001b[39;00m tf\u001b[39m.\u001b[39mis_tensor(y_true):\n\u001b[0;32m--> 240\u001b[0m   y_pred, y_true \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39;49msqueeze_or_expand_dimensions(y_pred, y_true)\n\u001b[1;32m    242\u001b[0m ag_fn \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mtf_convert(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn, tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mcontrol_status_ctx())\n\u001b[1;32m    243\u001b[0m \u001b[39mreturn\u001b[39;00m ag_fn(y_true, y_pred, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fn_kwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/losses_utils.py:195\u001b[0m, in \u001b[0;36msqueeze_or_expand_dimensions\u001b[0;34m(y_pred, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    192\u001b[0m rank_diff \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrank(y_pred) \u001b[39m-\u001b[39m tf\u001b[39m.\u001b[39mrank(y_true)\n\u001b[1;32m    193\u001b[0m squeeze_dims \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m: remove_squeezable_dimensions(  \u001b[39m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     y_true, y_pred)\n\u001b[0;32m--> 195\u001b[0m is_last_dim_1 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mequal(\u001b[39m1\u001b[39m, tf\u001b[39m.\u001b[39;49mshape(y_pred)[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    196\u001b[0m maybe_squeeze_dims \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m: tf\u001b[39m.\u001b[39mcond(  \u001b[39m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     is_last_dim_1, squeeze_dims, \u001b[39mlambda\u001b[39;00m: (y_true, y_pred))\n\u001b[1;32m    198\u001b[0m y_true, y_pred \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcond(\n\u001b[1;32m    199\u001b[0m     tf\u001b[39m.\u001b[39mequal(\u001b[39m1\u001b[39m, rank_diff), maybe_squeeze_dims, squeeze_dims)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py:1963\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1960\u001b[0m   c_op \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39mTF_FinishOperation(op_desc)\n\u001b[1;32m   1961\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1962\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m-> 1963\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39mmessage)\n\u001b[1;32m   1965\u001b[0m \u001b[39mreturn\u001b[39;00m c_op\n",
      "\u001b[0;31mValueError\u001b[0m: slice index -1 of dimension 0 out of bounds. for '{{node loss/yolo_loss_loss/strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_INT32, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](loss/yolo_loss_loss/Shape, loss/yolo_loss_loss/strided_slice/stack, loss/yolo_loss_loss/strided_slice/stack_1, loss/yolo_loss_loss/strided_slice/stack_2)' with input shapes: [0], [1], [1], [1] and with computed input tensors: input[1] = <-1>, input[2] = <0>, input[3] = <1>."
     ]
    }
   ],
   "source": [
    "    # create the model\n",
    "print('Loading model, this may take a second...')\n",
    "model.load_weights(\"/notebooks/models/yologv3.h5\", by_name=True, skip_mismatch=True)\n",
    "\n",
    "freeze_body = 'none'\n",
    "if freeze_body == 'darknet':\n",
    "    for i in range(185):\n",
    "        model.layers[i].trainable = False\n",
    "elif freeze_body == 'yolo':\n",
    "    for i in range(len(model.layers) - 7):\n",
    "        model.layers[i].trainable = False\n",
    "\n",
    "# compile model\n",
    "# model.compile(optimizer=Adam(learning_rate=1e-3), loss={'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3), loss={'yolo_loss': lambda y_true, y_pred: y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callbacks(training_model, prediction_model, validation_generator):\n",
    "    \"\"\"\n",
    "    Creates the callbacks to use during training.\n",
    "    Args\n",
    "        training_model: The model that is used for training.\n",
    "        prediction_model: The model that should be used for validation.\n",
    "        validation_generator: The generator for creating validation data.\n",
    "        args: parseargs args object.\n",
    "    Returns:\n",
    "        A list of callbacks used for training.\n",
    "    \"\"\"\n",
    "    callbacks = []\n",
    "\n",
    "    # tensorboard_callback = None\n",
    "\n",
    "    # if args.tensorboard_dir:\n",
    "    #     tensorboard_callback = TensorBoard(\n",
    "    #         log_dir=args.tensorboard_dir,\n",
    "    #         histogram_freq=0,\n",
    "    #         batch_size=args.batch_size,\n",
    "    #         write_graph=True,\n",
    "    #         write_grads=False,\n",
    "    #         write_images=False,\n",
    "    #         embeddings_freq=0,\n",
    "    #         embeddings_layer_names=None,\n",
    "    #         embeddings_metadata=None\n",
    "    #     )\n",
    "    #     callbacks.append(tensorboard_callback)\n",
    "\n",
    "    if validation_generator:\n",
    "        from eval.coco import Evaluate\n",
    "        # use prediction model for evaluation\n",
    "        evaluation = Evaluate(validation_generator, prediction_model)\n",
    "        # else:\n",
    "        #     from eval.pascal import Evaluate\n",
    "        #     evaluation = Evaluate(validation_generator, prediction_model, tensorboard=tensorboard_callback)\n",
    "        callbacks.append(evaluation)\n",
    "\n",
    "    # save the model\n",
    "        checkpoint = ModelCheckpoint(\n",
    "            '/notebooks/checkpoint/yologv3.h5',\n",
    "            verbose=1,\n",
    "            # save_best_only=True,\n",
    "            # monitor=\"mAP\",\n",
    "            # mode='max'\n",
    "        )\n",
    "        callbacks.append(checkpoint)\n",
    "\n",
    "    # callbacks.append(keras.callbacks.ReduceLROnPlateau(\n",
    "    #     monitor='loss',\n",
    "    #     factor=0.1,\n",
    "    #     patience=2,\n",
    "    #     verbose=1,\n",
    "    #     mode='auto',\n",
    "    #     min_delta=0.0001,\n",
    "    #     cooldown=0,\n",
    "    #     min_lr=0\n",
    "    # ))\n",
    "\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\the_3\\OneDrive\\Desktop\\school\\fall 2022\\neural networks class\\projects\\real-time-object-detector\\src\\yolog.ipynb Cell 40\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#Y111sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m callbacks \u001b[39m=\u001b[39m create_callbacks(model, prediction_model, val_generator)\n",
      "\u001b[1;32mc:\\Users\\the_3\\OneDrive\\Desktop\\school\\fall 2022\\neural networks class\\projects\\real-time-object-detector\\src\\yolog.ipynb Cell 40\u001b[0m in \u001b[0;36mcreate_callbacks\u001b[0;34m(training_model, prediction_model, validation_generator)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#Y111sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# tensorboard_callback = None\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#Y111sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#Y111sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# if args.tensorboard_dir:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#Y111sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m#     )\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#Y111sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m#     callbacks.append(tensorboard_callback)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#Y111sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mif\u001b[39;00m validation_generator:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#Y111sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39meval\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcoco\u001b[39;00m \u001b[39mimport\u001b[39;00m Evaluate\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#Y111sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39m# use prediction model for evaluation\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#Y111sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     evaluation \u001b[39m=\u001b[39m Evaluate(validation_generator, prediction_model)\n",
      "File \u001b[0;32m/notebooks/eval/coco.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgenerators\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcoco\u001b[39;00m \u001b[39mimport\u001b[39;00m CocoGenerator\n\u001b[0;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodel\u001b[39;00m \u001b[39mimport\u001b[39;00m yolo_body\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(generator, model, threshold\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m):\n\u001b[1;32m     29\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m    Use the pycocotools to evaluate a COCO model on a dataset.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39m        threshold: The score threshold to use.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "callbacks = create_callbacks(model, prediction_model, val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"yolo\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image_input (InputLayer)       [(None, None, None,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, None, None,   864         ['image_input[0][0]']            \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, None, None,   128        ['conv2d_75[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_72 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_72[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " zero_padding2d_5 (ZeroPadding2  (None, None, None,   0          ['leaky_re_lu_72[0][0]']         \n",
      " D)                             32)                                                               \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, None, None,   18432       ['zero_padding2d_5[0][0]']       \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, None, None,   256        ['conv2d_76[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_73 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_73[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, None, None,   2048        ['leaky_re_lu_73[0][0]']         \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, None, None,   128        ['conv2d_77[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_74 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_74[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, None, None,   18432       ['leaky_re_lu_74[0][0]']         \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, None, None,   256        ['conv2d_78[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_75 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_75[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, None, None,   0           ['leaky_re_lu_73[0][0]',         \n",
      "                                64)                               'leaky_re_lu_75[0][0]']         \n",
      "                                                                                                  \n",
      " zero_padding2d_6 (ZeroPadding2  (None, None, None,   0          ['add_23[0][0]']                 \n",
      " D)                             64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, None, None,   73728       ['zero_padding2d_6[0][0]']       \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, None, None,   512        ['conv2d_79[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_76 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_76[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, None, None,   8192        ['leaky_re_lu_76[0][0]']         \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, None, None,   256        ['conv2d_80[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_77 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_77[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, None, None,   73728       ['leaky_re_lu_77[0][0]']         \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, None, None,   512        ['conv2d_81[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_78 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_78[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, None, None,   0           ['leaky_re_lu_76[0][0]',         \n",
      "                                128)                              'leaky_re_lu_78[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, None, None,   8192        ['add_24[0][0]']                 \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, None, None,   256        ['conv2d_82[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " leaky_re_lu_79 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_79[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, None, None,   73728       ['leaky_re_lu_79[0][0]']         \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, None, None,   512        ['conv2d_83[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_80 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_80[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, None, None,   0           ['add_24[0][0]',                 \n",
      "                                128)                              'leaky_re_lu_80[0][0]']         \n",
      "                                                                                                  \n",
      " zero_padding2d_7 (ZeroPadding2  (None, None, None,   0          ['add_25[0][0]']                 \n",
      " D)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, None, None,   294912      ['zero_padding2d_7[0][0]']       \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, None, None,   1024       ['conv2d_84[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_81 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_81[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, None, None,   32768       ['leaky_re_lu_81[0][0]']         \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, None, None,   512        ['conv2d_85[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_82 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_82[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, None, None,   294912      ['leaky_re_lu_82[0][0]']         \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, None, None,   1024       ['conv2d_86[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_83 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_83[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, None, None,   0           ['leaky_re_lu_81[0][0]',         \n",
      "                                256)                              'leaky_re_lu_83[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, None, None,   32768       ['add_26[0][0]']                 \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, None, None,   512        ['conv2d_87[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_84 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_84[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, None, None,   294912      ['leaky_re_lu_84[0][0]']         \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, None, None,   1024       ['conv2d_88[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_85 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_85[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " add_27 (Add)                   (None, None, None,   0           ['add_26[0][0]',                 \n",
      "                                256)                              'leaky_re_lu_85[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, None, None,   32768       ['add_27[0][0]']                 \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, None, None,   512        ['conv2d_89[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_86 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_86[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, None, None,   294912      ['leaky_re_lu_86[0][0]']         \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, None, None,   1024       ['conv2d_90[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_87 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_87[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " add_28 (Add)                   (None, None, None,   0           ['add_27[0][0]',                 \n",
      "                                256)                              'leaky_re_lu_87[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, None, None,   32768       ['add_28[0][0]']                 \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, None, None,   512        ['conv2d_91[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_88 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_88[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, None, None,   294912      ['leaky_re_lu_88[0][0]']         \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, None, None,   1024       ['conv2d_92[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_89 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_89[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " add_29 (Add)                   (None, None, None,   0           ['add_28[0][0]',                 \n",
      "                                256)                              'leaky_re_lu_89[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, None, None,   32768       ['add_29[0][0]']                 \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, None, None,   512        ['conv2d_93[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_90 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_90[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)             (None, None, None,   294912      ['leaky_re_lu_90[0][0]']         \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, None, None,   1024       ['conv2d_94[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_91 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_91[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " add_30 (Add)                   (None, None, None,   0           ['add_29[0][0]',                 \n",
      "                                256)                              'leaky_re_lu_91[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)             (None, None, None,   32768       ['add_30[0][0]']                 \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, None, None,   512        ['conv2d_95[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_92 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_92[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_96 (Conv2D)             (None, None, None,   294912      ['leaky_re_lu_92[0][0]']         \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, None, None,   1024       ['conv2d_96[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_93 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_93[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " add_31 (Add)                   (None, None, None,   0           ['add_30[0][0]',                 \n",
      "                                256)                              'leaky_re_lu_93[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)             (None, None, None,   32768       ['add_31[0][0]']                 \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_94 (BatchN  (None, None, None,   512        ['conv2d_97[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_94 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_94[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)             (None, None, None,   294912      ['leaky_re_lu_94[0][0]']         \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_95 (BatchN  (None, None, None,   1024       ['conv2d_98[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_95 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_95[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " add_32 (Add)                   (None, None, None,   0           ['add_31[0][0]',                 \n",
      "                                256)                              'leaky_re_lu_95[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_99 (Conv2D)             (None, None, None,   32768       ['add_32[0][0]']                 \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_96 (BatchN  (None, None, None,   512        ['conv2d_99[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_96 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_96[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_100 (Conv2D)            (None, None, None,   294912      ['leaky_re_lu_96[0][0]']         \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_97 (BatchN  (None, None, None,   1024       ['conv2d_100[0][0]']             \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_97 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_97[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " add_33 (Add)                   (None, None, None,   0           ['add_32[0][0]',                 \n",
      "                                256)                              'leaky_re_lu_97[0][0]']         \n",
      "                                                                                                  \n",
      " zero_padding2d_8 (ZeroPadding2  (None, None, None,   0          ['add_33[0][0]']                 \n",
      " D)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_101 (Conv2D)            (None, None, None,   1179648     ['zero_padding2d_8[0][0]']       \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_98 (BatchN  (None, None, None,   2048       ['conv2d_101[0][0]']             \n",
      " ormalization)                  512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_98 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_98[0][0]'] \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_102 (Conv2D)            (None, None, None,   131072      ['leaky_re_lu_98[0][0]']         \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_99 (BatchN  (None, None, None,   1024       ['conv2d_102[0][0]']             \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_99 (LeakyReLU)     (None, None, None,   0           ['batch_normalization_99[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_103 (Conv2D)            (None, None, None,   1179648     ['leaky_re_lu_99[0][0]']         \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_100 (Batch  (None, None, None,   2048       ['conv2d_103[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_100 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_100[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " add_34 (Add)                   (None, None, None,   0           ['leaky_re_lu_98[0][0]',         \n",
      "                                512)                              'leaky_re_lu_100[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_104 (Conv2D)            (None, None, None,   131072      ['add_34[0][0]']                 \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_101 (Batch  (None, None, None,   1024       ['conv2d_104[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_101 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_101[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_105 (Conv2D)            (None, None, None,   1179648     ['leaky_re_lu_101[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_102 (Batch  (None, None, None,   2048       ['conv2d_105[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_102 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_102[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " add_35 (Add)                   (None, None, None,   0           ['add_34[0][0]',                 \n",
      "                                512)                              'leaky_re_lu_102[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_106 (Conv2D)            (None, None, None,   131072      ['add_35[0][0]']                 \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_103 (Batch  (None, None, None,   1024       ['conv2d_106[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_103 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_103[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_107 (Conv2D)            (None, None, None,   1179648     ['leaky_re_lu_103[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_104 (Batch  (None, None, None,   2048       ['conv2d_107[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_104 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_104[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " add_36 (Add)                   (None, None, None,   0           ['add_35[0][0]',                 \n",
      "                                512)                              'leaky_re_lu_104[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_108 (Conv2D)            (None, None, None,   131072      ['add_36[0][0]']                 \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_105 (Batch  (None, None, None,   1024       ['conv2d_108[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_105 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_105[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_109 (Conv2D)            (None, None, None,   1179648     ['leaky_re_lu_105[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_106 (Batch  (None, None, None,   2048       ['conv2d_109[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_106 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_106[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " add_37 (Add)                   (None, None, None,   0           ['add_36[0][0]',                 \n",
      "                                512)                              'leaky_re_lu_106[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_110 (Conv2D)            (None, None, None,   131072      ['add_37[0][0]']                 \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_107 (Batch  (None, None, None,   1024       ['conv2d_110[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_107 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_107[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_111 (Conv2D)            (None, None, None,   1179648     ['leaky_re_lu_107[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_108 (Batch  (None, None, None,   2048       ['conv2d_111[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_108 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_108[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " add_38 (Add)                   (None, None, None,   0           ['add_37[0][0]',                 \n",
      "                                512)                              'leaky_re_lu_108[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_112 (Conv2D)            (None, None, None,   131072      ['add_38[0][0]']                 \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_109 (Batch  (None, None, None,   1024       ['conv2d_112[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_109 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_109[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_113 (Conv2D)            (None, None, None,   1179648     ['leaky_re_lu_109[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_110 (Batch  (None, None, None,   2048       ['conv2d_113[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_110 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_110[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " add_39 (Add)                   (None, None, None,   0           ['add_38[0][0]',                 \n",
      "                                512)                              'leaky_re_lu_110[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_114 (Conv2D)            (None, None, None,   131072      ['add_39[0][0]']                 \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_111 (Batch  (None, None, None,   1024       ['conv2d_114[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_111 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_111[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_115 (Conv2D)            (None, None, None,   1179648     ['leaky_re_lu_111[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_112 (Batch  (None, None, None,   2048       ['conv2d_115[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_112 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_112[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " add_40 (Add)                   (None, None, None,   0           ['add_39[0][0]',                 \n",
      "                                512)                              'leaky_re_lu_112[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_116 (Conv2D)            (None, None, None,   131072      ['add_40[0][0]']                 \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_113 (Batch  (None, None, None,   1024       ['conv2d_116[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_113 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_113[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_117 (Conv2D)            (None, None, None,   1179648     ['leaky_re_lu_113[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_114 (Batch  (None, None, None,   2048       ['conv2d_117[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_114 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_114[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " add_41 (Add)                   (None, None, None,   0           ['add_40[0][0]',                 \n",
      "                                512)                              'leaky_re_lu_114[0][0]']        \n",
      "                                                                                                  \n",
      " zero_padding2d_9 (ZeroPadding2  (None, None, None,   0          ['add_41[0][0]']                 \n",
      " D)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_118 (Conv2D)            (None, None, None,   4718592     ['zero_padding2d_9[0][0]']       \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_115 (Batch  (None, None, None,   4096       ['conv2d_118[0][0]']             \n",
      " Normalization)                 1024)                                                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_115 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_115[0][0]']\n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv2d_119 (Conv2D)            (None, None, None,   524288      ['leaky_re_lu_115[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_116 (Batch  (None, None, None,   2048       ['conv2d_119[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_116 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_116[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_120 (Conv2D)            (None, None, None,   4718592     ['leaky_re_lu_116[0][0]']        \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_117 (Batch  (None, None, None,   4096       ['conv2d_120[0][0]']             \n",
      " Normalization)                 1024)                                                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_117 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_117[0][0]']\n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " add_42 (Add)                   (None, None, None,   0           ['leaky_re_lu_115[0][0]',        \n",
      "                                1024)                             'leaky_re_lu_117[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_121 (Conv2D)            (None, None, None,   524288      ['add_42[0][0]']                 \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_118 (Batch  (None, None, None,   2048       ['conv2d_121[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_118 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_118[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_122 (Conv2D)            (None, None, None,   4718592     ['leaky_re_lu_118[0][0]']        \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_119 (Batch  (None, None, None,   4096       ['conv2d_122[0][0]']             \n",
      " Normalization)                 1024)                                                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_119 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_119[0][0]']\n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " add_43 (Add)                   (None, None, None,   0           ['add_42[0][0]',                 \n",
      "                                1024)                             'leaky_re_lu_119[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_123 (Conv2D)            (None, None, None,   524288      ['add_43[0][0]']                 \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_120 (Batch  (None, None, None,   2048       ['conv2d_123[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_120 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_120[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_124 (Conv2D)            (None, None, None,   4718592     ['leaky_re_lu_120[0][0]']        \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_121 (Batch  (None, None, None,   4096       ['conv2d_124[0][0]']             \n",
      " Normalization)                 1024)                                                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_121 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_121[0][0]']\n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " add_44 (Add)                   (None, None, None,   0           ['add_43[0][0]',                 \n",
      "                                1024)                             'leaky_re_lu_121[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_125 (Conv2D)            (None, None, None,   524288      ['add_44[0][0]']                 \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_122 (Batch  (None, None, None,   2048       ['conv2d_125[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_122 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_122[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_126 (Conv2D)            (None, None, None,   4718592     ['leaky_re_lu_122[0][0]']        \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_123 (Batch  (None, None, None,   4096       ['conv2d_126[0][0]']             \n",
      " Normalization)                 1024)                                                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_123 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_123[0][0]']\n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " add_45 (Add)                   (None, None, None,   0           ['add_44[0][0]',                 \n",
      "                                1024)                             'leaky_re_lu_123[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)            (None, None, None,   524288      ['add_45[0][0]']                 \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_124 (Batch  (None, None, None,   2048       ['conv2d_127[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_124 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_124[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)            (None, None, None,   4718592     ['leaky_re_lu_124[0][0]']        \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_125 (Batch  (None, None, None,   4096       ['conv2d_128[0][0]']             \n",
      " Normalization)                 1024)                                                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_125 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_125[0][0]']\n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv2d_129 (Conv2D)            (None, None, None,   524288      ['leaky_re_lu_125[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_126 (Batch  (None, None, None,   2048       ['conv2d_129[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_126 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_126[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_130 (Conv2D)            (None, None, None,   4718592     ['leaky_re_lu_126[0][0]']        \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_127 (Batch  (None, None, None,   4096       ['conv2d_130[0][0]']             \n",
      " Normalization)                 1024)                                                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_127 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_127[0][0]']\n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv2d_131 (Conv2D)            (None, None, None,   524288      ['leaky_re_lu_127[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_128 (Batch  (None, None, None,   2048       ['conv2d_131[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_128 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_128[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_134 (Conv2D)            (None, None, None,   131072      ['leaky_re_lu_128[0][0]']        \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_130 (Batch  (None, None, None,   1024       ['conv2d_134[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_130 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_130[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, None, None,   0          ['leaky_re_lu_130[0][0]']        \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, None, None,   0           ['up_sampling2d_2[0][0]',        \n",
      "                                768)                              'add_41[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_135 (Conv2D)            (None, None, None,   196608      ['concatenate_2[0][0]']          \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_131 (Batch  (None, None, None,   1024       ['conv2d_135[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_131 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_131[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_136 (Conv2D)            (None, None, None,   1179648     ['leaky_re_lu_131[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_132 (Batch  (None, None, None,   2048       ['conv2d_136[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_132 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_132[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_137 (Conv2D)            (None, None, None,   131072      ['leaky_re_lu_132[0][0]']        \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_133 (Batch  (None, None, None,   1024       ['conv2d_137[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_133 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_133[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_138 (Conv2D)            (None, None, None,   1179648     ['leaky_re_lu_133[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_134 (Batch  (None, None, None,   2048       ['conv2d_138[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_134 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_134[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_139 (Conv2D)            (None, None, None,   131072      ['leaky_re_lu_134[0][0]']        \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_135 (Batch  (None, None, None,   1024       ['conv2d_139[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_135 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_135[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_142 (Conv2D)            (None, None, None,   32768       ['leaky_re_lu_135[0][0]']        \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_137 (Batch  (None, None, None,   512        ['conv2d_142[0][0]']             \n",
      " Normalization)                 128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_137 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_137[0][0]']\n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, None, None,   0          ['leaky_re_lu_137[0][0]']        \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, None, None,   0           ['up_sampling2d_3[0][0]',        \n",
      "                                384)                              'add_33[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_143 (Conv2D)            (None, None, None,   49152       ['concatenate_3[0][0]']          \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_138 (Batch  (None, None, None,   512        ['conv2d_143[0][0]']             \n",
      " Normalization)                 128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_138 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_138[0][0]']\n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_144 (Conv2D)            (None, None, None,   294912      ['leaky_re_lu_138[0][0]']        \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_139 (Batch  (None, None, None,   1024       ['conv2d_144[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_139 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_139[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_145 (Conv2D)            (None, None, None,   32768       ['leaky_re_lu_139[0][0]']        \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_140 (Batch  (None, None, None,   512        ['conv2d_145[0][0]']             \n",
      " Normalization)                 128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_140 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_140[0][0]']\n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_146 (Conv2D)            (None, None, None,   294912      ['leaky_re_lu_140[0][0]']        \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_141 (Batch  (None, None, None,   1024       ['conv2d_146[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_141 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_141[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_147 (Conv2D)            (None, None, None,   32768       ['leaky_re_lu_141[0][0]']        \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_142 (Batch  (None, None, None,   512        ['conv2d_147[0][0]']             \n",
      " Normalization)                 128)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_142 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_142[0][0]']\n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_132 (Conv2D)            (None, None, None,   4718592     ['leaky_re_lu_128[0][0]']        \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv2d_140 (Conv2D)            (None, None, None,   1179648     ['leaky_re_lu_135[0][0]']        \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv2d_148 (Conv2D)            (None, None, None,   294912      ['leaky_re_lu_142[0][0]']        \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_129 (Batch  (None, None, None,   4096       ['conv2d_132[0][0]']             \n",
      " Normalization)                 1024)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_136 (Batch  (None, None, None,   2048       ['conv2d_140[0][0]']             \n",
      " Normalization)                 512)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_143 (Batch  (None, None, None,   1024       ['conv2d_148[0][0]']             \n",
      " Normalization)                 256)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_129 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_129[0][0]']\n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_136 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_136[0][0]']\n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " leaky_re_lu_143 (LeakyReLU)    (None, None, None,   0           ['batch_normalization_143[0][0]']\n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_133 (Conv2D)            (None, None, None,   273675      ['leaky_re_lu_129[0][0]']        \n",
      "                                267)                                                              \n",
      "                                                                                                  \n",
      " conv2d_141 (Conv2D)            (None, None, None,   136971      ['leaky_re_lu_136[0][0]']        \n",
      "                                267)                                                              \n",
      "                                                                                                  \n",
      " conv2d_149 (Conv2D)            (None, None, None,   68619       ['leaky_re_lu_143[0][0]']        \n",
      "                                267)                                                              \n",
      "                                                                                                  \n",
      " fm_13_input (InputLayer)       [(None, None, None,  0           []                               \n",
      "                                 3, 85)]                                                          \n",
      "                                                                                                  \n",
      " fm_26_input (InputLayer)       [(None, None, None,  0           []                               \n",
      "                                 3, 85)]                                                          \n",
      "                                                                                                  \n",
      " fm_52_input (InputLayer)       [(None, None, None,  0           []                               \n",
      "                                 3, 85)]                                                          \n",
      "                                                                                                  \n",
      " yolo_loss (Lambda)             ()                   0           ['conv2d_133[0][0]',             \n",
      "                                                                  'conv2d_141[0][0]',             \n",
      "                                                                  'conv2d_149[0][0]',             \n",
      "                                                                  'fm_13_input[0][0]',            \n",
      "                                                                  'fm_26_input[0][0]',            \n",
      "                                                                  'fm_52_input[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 62,023,297\n",
      "Trainable params: 61,970,689\n",
      "Non-trainable params: 52,608\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the callbacks\n",
    "# logging = TensorBoard(log_dir='/notebooks/logs')\n",
    "# checkpoint = ModelCheckpoint('/notebooks/checkpoint/yologv3.h5', monitor='val_loss', save_best_only=True, mode='min')\n",
    "# reduce_on_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, mode='min', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=6, verbose=1, mode='min')\n",
    "\n",
    "\n",
    "# callbacks = [\n",
    "#     checkpoint,\n",
    "#     reduce_on_plateau,\n",
    "#     # early_stopping\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEPS_PER_EPOCH = len(train_generator)\n",
    "# STEPS_PER_EPOCH = 500   \n",
    "EPOCHS = 25\n",
    "MULTI_PROCESSING = False\n",
    "MAX_QUEUE_SIZE = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def draw_boxes(image, boxes, classes=classes):\n",
    "#     '''Draws bounding boxes on the image'''\n",
    "#     labels = boxes['labels']\n",
    "#     boxes = boxes['bboxes']\n",
    "#     for i in range(len(boxes)):\n",
    "#         box = boxes[i]\n",
    "#         label = labels[i]\n",
    "#         cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), (255, 0, 0), 2)\n",
    "#         cv2.putText(image, classes[label], (box[0], box[1]), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # display first image in training set with bounding boxes\n",
    "# image = train_generator.load_image(0)\n",
    "# boxes = train_generator.load_annotations(0)\n",
    "# # print(boxes)\n",
    "# # draw_boxes(image, boxes, classes=classes)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session():\n",
    "    \"\"\"\n",
    "    Construct a modified tf session.\n",
    "    \"\"\"\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.compat.v1.Session(config=config)\n",
    "\n",
    "tf.compat.v1.keras.backend.set_session(get_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 01:40:36.196927: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] layout failed: INVALID_ARGUMENT: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/32 [==============>...............] - ETA: 7s - loss: 7581.9297"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:180: UserWarning: Image with id 2029 (shape (640, 427, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 2029 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/32 [=====================>........] - ETA: 3s - loss: 5929.5708"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/generators/common.py:230: UserWarning: Image with id 54243 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 4782.6167"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 01:40:58.919027: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] layout failed: INVALID_ARGUMENT: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
      "2022-12-12 01:40:58.935399: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] remapper failed: INVALID_ARGUMENT: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
      "2022-12-12 01:40:59.110548: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] remapper failed: INVALID_ARGUMENT: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 2078 (shape (640, 418, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 2078 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 2191 (shape (640, 426, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 2191 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 2326 (shape (640, 427, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 2326 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 3616 (shape (640, 429, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 3616 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 4089 (shape (500, 336, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 4089 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 2532 (shape (640, 479, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 2532 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 25 (shape (640, 480, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 25 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 2285 (shape (640, 480, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 2285 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 2525 (shape (640, 480, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 2525 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 2833 (shape (640, 480, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 2833 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 3361 (shape (500, 375, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 3361 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 3740 (shape (640, 480, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 3740 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 3858 (shape (500, 375, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 3858 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 4576 (shape (640, 480, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 4576 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 4098 (shape (640, 523, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 4098 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 29 (shape (640, 634, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 29 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 3958 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 160 (shape (375, 500, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 160 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 403 (shape (375, 500, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 403 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 438 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 438 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 1041 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 1041 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 1171 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 1556 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 1562 (shape (375, 500, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 1556 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 1562 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 1563 (shape (375, 500, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 1563 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 1675 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 1675 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 1906 (shape (375, 500, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 1906 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 2837 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 2837 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 2973 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 2973 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 3746 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 4099 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 4099 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 4460 (shape (480, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 4460 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 3488 (shape (374, 500, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 3488 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 2839 (shape (338, 500, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 2839 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 278 (shape (335, 500, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 278 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 1300 (shape (428, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 1300 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 4459 (shape (428, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 4459 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 1558 (shape (427, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 1558 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 1680 (shape (427, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 1680 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 3748 (shape (427, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 3748 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 4091 (shape (427, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 4091 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n",
      "/notebooks/generators/common.py:180: UserWarning: Image with id 4824 (shape (427, 640, 3)) contains no valid boxes before transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes before transform'.format(\n",
      "/notebooks/generators/common.py:230: UserWarning: Image with id 4824 (shape (608, 608, 3)) contains no valid boxes after transform\n",
      "  warnings.warn('Image with id {} (shape {}) contains no valid boxes after transform'.format(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\the_3\\OneDrive\\Desktop\\school\\fall 2022\\neural networks class\\projects\\real-time-object-detector\\src\\yolog.ipynb Cell 44\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X61sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# start training\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X61sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m H \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X61sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_generator, y \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X61sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m steps_per_epoch\u001b[39m=\u001b[39;49mSTEPS_PER_EPOCH,\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X61sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m epochs\u001b[39m=\u001b[39;49mEPOCHS,\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X61sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X61sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X61sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# callbacks=callbacks,\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X61sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# workers=WORKERS,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X61sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# use_multiprocessing=MULTI_PROCESSING,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X61sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# max_queue_size=MAX_QUEUE_SIZE,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X61sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m validation_data\u001b[39m=\u001b[39;49mval_generator,\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X61sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m validation_steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(val_generator),\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X61sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X61sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#X61sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py:1445\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1432\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[1;32m   1433\u001b[0m       x\u001b[39m=\u001b[39mval_x,\n\u001b[1;32m   1434\u001b[0m       y\u001b[39m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1443\u001b[0m       model\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m   1444\u001b[0m       steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution)\n\u001b[0;32m-> 1445\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[1;32m   1446\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[1;32m   1447\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[1;32m   1448\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[1;32m   1449\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[1;32m   1450\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   1451\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1452\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1453\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1454\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1455\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1456\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1457\u001b[0m val_logs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m   1458\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py:1756\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1754\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1755\u001b[0m   callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 1756\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[1;32m   1757\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1758\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    955\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    # start training\n",
    "H = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks,\n",
    "    # workers=WORKERS,\n",
    "    # use_multiprocessing=MULTI_PROCESSING,\n",
    "    # max_queue_size=MAX_QUEUE_SIZE,\n",
    "    validation_data=val_generator,\n",
    "    # validation_steps=len(val_generator),\n",
    "    initial_epoch=0\n",
    ")\n",
    "\n",
    "# H = model.fit(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=STEPS_PER_EPOCH,\n",
    "#     initial_epoch=0,\n",
    "#     epochs=EPOCHS,\n",
    "#     verbose=1,\n",
    "#     callbacks=callbacks,\n",
    "#     workers=WORKERS,\n",
    "#     use_multiprocessing=MULTI_PROCESSING,\n",
    "#     max_queue_size=MAX_QUEUE_SIZE,\n",
    "#     validation_data=val_generator\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('/notebooks/models/yologv3_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training history\n",
    "def plot_results(history, epochs=EPOCHS):\n",
    "    '''\n",
    "        This function plots the training history\n",
    "        input:\n",
    "            - history: the training history\n",
    "        output:\n",
    "            - None\n",
    "    '''\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, epochs), history['loss'], label = 'train_loss')\n",
    "    plt.plot(np.arange(0, epochs), history['val_loss'], label = 'val_loss')\n",
    "    # plt.plot(np.arange(0, epochs), history['accuracy'], label = 'train_acc')\n",
    "    # plt.plot(np.arange(0, epochs), history['val_accuracy'], label = 'val_acc')\n",
    "        \n",
    "    # add labels and legend\n",
    "    plt.title('Training Loss and Accuracy')\n",
    "    plt.xlabel('Epoch #')\n",
    "    plt.ylabel('Loss/Accuracy')\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training history\n",
    "plot_results(H.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import glob\n",
    "from utils import get_anchors, get_classes, preprocess_image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.framework.ops import disable_eager_execution\n",
    "# disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, name, contours=None):\n",
    "    image = image.astype(np.uint8)\n",
    "    # cv2.namedWindow(name, cv2.WINDOW_NORMAL)\n",
    "    if contours is not None:\n",
    "        if isinstance(contours, list):\n",
    "            cv2.drawContours(image, contours, -1, (0, 0, 255), 2)\n",
    "        else:\n",
    "            cv2.drawContours(image, [contours], -1, (0, 0, 255), 2)\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 6\n"
     ]
    }
   ],
   "source": [
    "# inference\n",
    "model, prediction_model = yolo_body(anchors=anchors, score_threshold=0.1)\n",
    "# model.load_weights('/notebooks/models/yologv3_final.h5')\n",
    "model.load_weights('/notebooks/checkpoint/yologv3.h5', by_name=True)\n",
    "BATCH_SIZE = 1\n",
    "image_paths = glob.glob('/notebooks/data/test/*.jpg')\n",
    "num_images = len(image_paths)\n",
    "print('Number of images: {}'.format(num_images))\n",
    "colors = [np.random.randint(0, 256, 3).tolist() for i in range(num_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot assign value to variable ' conv2d_133/kernel:0': Shape mismatch.The variable shape (1, 1, 1024, 267), and the assigned value shape (255, 1024, 1, 1) are incompatible.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\the_3\\OneDrive\\Desktop\\school\\fall 2022\\neural networks class\\projects\\real-time-object-detector\\src\\yolog.ipynb Cell 50\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#Y103sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# load best weights\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#Y103sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mload_weights(\u001b[39m'\u001b[39;49m\u001b[39m/notebooks/models/yologv3.h5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/backend.py:4028\u001b[0m, in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   4026\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[1;32m   4027\u001b[0m   \u001b[39mfor\u001b[39;00m x, value \u001b[39min\u001b[39;00m tuples:\n\u001b[0;32m-> 4028\u001b[0m     x\u001b[39m.\u001b[39;49massign(np\u001b[39m.\u001b[39;49masarray(value, dtype\u001b[39m=\u001b[39;49mdtype_numpy(x)))\n\u001b[1;32m   4029\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4030\u001b[0m   \u001b[39mwith\u001b[39;00m get_graph()\u001b[39m.\u001b[39mas_default():\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot assign value to variable ' conv2d_133/kernel:0': Shape mismatch.The variable shape (1, 1, 1024, 267), and the assigned value shape (255, 1024, 1, 1) are incompatible."
     ]
    }
   ],
   "source": [
    "# # load best weights\n",
    "# model.load_weights('/notebooks/models/yologv3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Calling `Model.predict` in graph mode is not supported when the `Model` instance was constructed with eager mode enabled. Please construct your `Model` instance in graph mode or call `Model.predict` with eager mode enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\the_3\\OneDrive\\Desktop\\school\\fall 2022\\neural networks class\\projects\\real-time-object-detector\\src\\yolog.ipynb Cell 53\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#Y101sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m batch_images_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(batch_images_data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#Y101sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m batch_image_shapes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(batch_image_shapes)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#Y101sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m batch_detections \u001b[39m=\u001b[39m prediction_model\u001b[39m.\u001b[39;49mpredict([batch_images_data, batch_image_shapes])\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#Y101sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, detections \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(batch_detections):\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Users/the_3/OneDrive/Desktop/school/fall%202022/neural%20networks%20class/projects/real-time-object-detector/src/yolog.ipynb#Y101sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     image_path \u001b[39m=\u001b[39m batch_image_paths[i]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/version_utils.py:128\u001b[0m, in \u001b[0;36mdisallow_legacy_graph\u001b[0;34m(cls_name, method_name)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[1;32m    123\u001b[0m   error_msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    124\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCalling `\u001b[39m\u001b[39m{\u001b[39;00mcls_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmethod_name\u001b[39m}\u001b[39;00m\u001b[39m` in graph mode is not supported \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwhen the `\u001b[39m\u001b[39m{\u001b[39;00mcls_name\u001b[39m}\u001b[39;00m\u001b[39m` instance was constructed with eager mode \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39menabled. Please construct your `\u001b[39m\u001b[39m{\u001b[39;00mcls_name\u001b[39m}\u001b[39;00m\u001b[39m` instance in graph mode or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m call `\u001b[39m\u001b[39m{\u001b[39;00mcls_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmethod_name\u001b[39m}\u001b[39;00m\u001b[39m` with eager mode enabled.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 128\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(error_msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Calling `Model.predict` in graph mode is not supported when the `Model` instance was constructed with eager mode enabled. Please construct your `Model` instance in graph mode or call `Model.predict` with eager mode enabled."
     ]
    }
   ],
   "source": [
    "for i in range(0, num_images, BATCH_SIZE):\n",
    "    if i + BATCH_SIZE > num_images:\n",
    "        batch_image_paths = image_paths[i:]\n",
    "    else:\n",
    "        batch_image_paths = image_paths[i:i + BATCH_SIZE]\n",
    "    batch_images_data = []\n",
    "    batch_image_shapes = []\n",
    "    for image_path in batch_image_paths:\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image_shape = image.shape[:2]\n",
    "        image_shape = np.array(image_shape)\n",
    "        image_data = preprocess_image(image)\n",
    "        batch_images_data.append(image_data)\n",
    "        batch_image_shapes.append(image_shape)\n",
    "\n",
    "    batch_images_data = np.array(batch_images_data)\n",
    "    batch_image_shapes = np.array(batch_image_shapes)\n",
    "    batch_detections = prediction_model.predict([batch_images_data, batch_image_shapes])\n",
    "    for i, detections in enumerate(batch_detections):\n",
    "        image_path = batch_image_paths[i]\n",
    "        image = cv2.imread(image_path)\n",
    "        h, w = image.shape[:2]\n",
    "        detections = detections[detections[:, 4] > 0.0]\n",
    "        for detection in detections:\n",
    "            ymin = max(int(round(detection[0])), 0)\n",
    "            xmin = max(int(round(detection[1])), 0)\n",
    "            ymax = min(int(round(detection[2])), h - 1)\n",
    "            xmax = min(int(round(detection[3])), w - 1)\n",
    "            score = '{:.4f}'.format(detection[4])\n",
    "            class_id = int(detection[5])\n",
    "            color = colors[class_id - 1]\n",
    "            class_name = classes[class_id]\n",
    "            label = '-'.join([class_name, score])\n",
    "            ret, baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.3, 1)\n",
    "            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color, 1)\n",
    "            cv2.rectangle(image, (xmin, ymax - ret[1] - baseline), (xmin + ret[0], ymax), color, -1)\n",
    "            cv2.putText(image, label, (xmin, ymax - baseline), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "\n",
    "        # plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        plt.imshow(image)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Demo of Gaussian Yolov3 (YoloG) in Real Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
