{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSE 5320 Neural Networks Project 2\n",
    "#### Report (with Code)\n",
    "Josias Moukpe\\\n",
    "11/18/2022\n",
    "\n",
    "#### Introduction\n",
    "Object detection is an advanced form of image classification where a neural network predicts objects in an image and points them out in bounding boxes. Object detection thus refers to the detection and localization of objects in an image that belongs to a predefined set of classes. Tasks like detection, recognition, or localization find widespread applicability in real-world scenarios such as autonomous driving, robotics, product quality assurance, etc., making object detection (also referred to as object recognition) a very important subdomain of Computer Vision. [2] We call Real-Time object detection when the objects in images can be recognized in mere milliseconds allowing for in-time reactions based on the detection. Our project will aim to build a real-time object detector to find and track objects of defined classes in images or video feeds.\n",
    "\n",
    "#### Problem\n",
    "This objective combines object classificationn and localization (bounding box regression task). To process images and capture the features, we will leverage convolutional neural networks and capture local pixel structures. We will comment on how our model performs in real-time object detection. To train our model, we will use the MS COCO dataset [1]. This dataset contains more than 200,000 labeled color images of 1.5 million object instances and 80 object categories. Each image is 640 x 480 pixels and includes various forms of annotations such as key points, captions, segmentations, and bounding boxes (which interest us). The model will take an image or batch of images and outputs the classes and bounding boxes of all objects detected in that image.\n",
    "\n",
    "#### Methodology\n",
    "To prepare the data, we .\n",
    "\n",
    "#### Benchmarking\n",
    "To measure training performance, we \n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "\n",
    "\n",
    "References\\\n",
    "[1] https://cocodataset.org/#home\n",
    "[2] https://www.v7labs.com/blog/yolo-object-detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining the COCO 2017 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md  data  dev.ipynb\n",
      "/notebooks/data\n"
     ]
    }
   ],
   "source": [
    "# list the contents of the current \n",
    "# directory on my remote server\n",
    "!ls\n",
    "%cd \"/notebooks/data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-19 03:20:27--  http://images.cocodataset.org/zips/train2017.zip\n",
      "Resolving images.cocodataset.org (images.cocodataset.org)... 54.231.133.57, 3.5.19.134, 52.217.198.161, ...\n",
      "Connecting to images.cocodataset.org (images.cocodataset.org)|54.231.133.57|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19336861798 (18G) [application/zip]\n",
      "Saving to: ‘train2017.zip’\n",
      "\n",
      "train2017.zip       100%[===================>]  18.01G  5.74MB/s    in 52m 10s \n",
      "\n",
      "2022-11-19 04:12:37 (5.89 MB/s) - ‘train2017.zip’ saved [19336861798/19336861798]\n",
      "\n",
      "--2022-11-19 04:12:38--  http://images.cocodataset.org/zips/val2017.zip\n",
      "Resolving images.cocodataset.org (images.cocodataset.org)... 52.217.132.25, 52.217.229.137, 52.216.233.75, ...\n",
      "Connecting to images.cocodataset.org (images.cocodataset.org)|52.217.132.25|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 815585330 (778M) [application/zip]\n",
      "Saving to: ‘val2017.zip’\n",
      "\n",
      "val2017.zip         100%[===================>] 777.80M  5.50MB/s    in 2m 13s  \n",
      "\n",
      "2022-11-19 04:14:51 (5.85 MB/s) - ‘val2017.zip’ saved [815585330/815585330]\n",
      "\n",
      "--2022-11-19 04:14:52--  http://images.cocodataset.org/zips/test2017.zip\n",
      "Resolving images.cocodataset.org (images.cocodataset.org)... 52.217.199.249, 52.216.111.35, 52.216.129.235, ...\n",
      "Connecting to images.cocodataset.org (images.cocodataset.org)|52.217.199.249|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6646970404 (6.2G) [application/zip]\n",
      "Saving to: ‘test2017.zip’\n",
      "\n",
      "test2017.zip        100%[===================>]   6.19G  7.13MB/s    in 17m 37s \n",
      "\n",
      "2022-11-19 04:32:29 (6.00 MB/s) - ‘test2017.zip’ saved [6646970404/6646970404]\n",
      "\n",
      "--2022-11-19 04:32:29--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
      "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.37.241, 52.216.248.116, 52.216.132.83, ...\n",
      "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.37.241|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 252907541 (241M) [application/zip]\n",
      "Saving to: ‘annotations_trainval2017.zip’\n",
      "\n",
      "annotations_trainva 100%[===================>] 241.19M  5.55MB/s    in 39s     \n",
      "\n",
      "2022-11-19 04:33:09 (6.18 MB/s) - ‘annotations_trainval2017.zip’ saved [252907541/252907541]\n",
      "\n",
      "--2022-11-19 04:33:09--  http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip\n",
      "Resolving images.cocodataset.org (images.cocodataset.org)... 54.231.137.169, 52.217.102.220, 52.216.44.249, ...\n",
      "Connecting to images.cocodataset.org (images.cocodataset.org)|54.231.137.169|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1148688564 (1.1G) [application/zip]\n",
      "Saving to: ‘stuff_annotations_trainval2017.zip’\n",
      "\n",
      "s_trainval2017.zip   20%[===>                ] 227.46M  5.85MB/s    eta 2m 24s "
     ]
    }
   ],
   "source": [
    "# downloading coco (2017) dataset\n",
    "!wget http://images.cocodataset.org/zips/train2017.zip\n",
    "!wget http://images.cocodataset.org/zips/val2017.zip\n",
    "!wget http://images.cocodataset.org/zips/test2017.zip\n",
    "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "!wget http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip\n",
    "!wget http://images.cocodataset.org/annotations/image_info_test2017.zip\n",
    "\n",
    "# unzip the files\n",
    "!unzip train2017.zip\n",
    "!unzip val2017.zip\n",
    "!unzip test2017.zip\n",
    "!unzip annotations_trainval2017.zip\n",
    "!unzip stuff_annotations_trainval2017.zip\n",
    "!unzip image_info_test2017.zip\n",
    "\n",
    "# remove the zip files\n",
    "!rm train2017.zip\n",
    "!rm val2017.zip\n",
    "!rm test2017.zip\n",
    "!rm annotations_trainval2017.zip\n",
    "!rm stuff_annotations_trainval2017.zip\n",
    "!rm image_info_test2017.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# install gluoncv to help with the dataset\n",
    "%pip install gluoncv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# imports \n",
    "from gluoncv import data, utils\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import opencv as cv2\n",
    "from random import randint\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorboard\n",
    "\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# check if gpu is available\n",
    "numGPUs = len(tf.config.experimental.list_physical_devices('GPU'))\n",
    "\n",
    "print('Num GPUs Available: ', numGPUs)\n",
    "\n",
    "if numGPUs > 0:\n",
    "    print(tf.test.gpu_device_name())\n",
    "    for device in device_lib.list_local_devices():\n",
    "        print(device.physical_device_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# loading the coco dataset\n",
    "train_ds = data.COCODetection(splits=['instances_train2017'])\n",
    "val_ds = data.COCODetection(splits=['instances_val2017'])\n",
    "# test_ds = data.COCODetection(splits=['test2017']) # TODO: figure this out \n",
    "\n",
    "# print the length of the dataset\n",
    "print('Length of training dataset:', len(train_ds))\n",
    "print('Length of validation dataset:', len(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# plot a random image in the dataset\n",
    "image, label = train_ds[randint(0, len(train_ds))]\n",
    "print('Image size (height, width, RGB):', image.shape)\n",
    "print('Label:', label)\n",
    "# plot the image\n",
    "bounding_boxes = label[:, :4]\n",
    "class_ids = label[:, 4:5]\n",
    "print('number of objects in the image:', bounding_boxes.shape[0])\n",
    "print('bounding boxes (# boxes, min x, min y, max x, max y): \\n', bounding_boxes)\n",
    "print('class ids (# boxes, class id): \\n', class_ids)\n",
    "ax = utils.viz.plot_bbox(image.asnumpy(), bounding_boxes, scores=None, labels=class_ids, class_names=train_ds.classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
